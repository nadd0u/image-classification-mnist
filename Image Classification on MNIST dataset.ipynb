{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Introduction. \n",
    "Our project tackles the problem of character classification in natural handwritten images. Recognition of handwritten digits is difficult because of the high variability in writing style, context of the number, different writing devices and culture. This leads to numbers of different size and slant made with strokes that vary in width and shape. We employ a fully connected (dense) neural network with a single hidden layer to classfiy grayscale images of handwritten digits (28 pixels by 28 pixels) from the MNIST dataset, into their 10 categories (0 to 9). \n",
    "\n",
    "The paper is divided into two parts. In the first section we explore a single paramater of the model, it's nodes. In the second section we explore the affect of input data's size on model speed and performance.  \n",
    "\n",
    "#### Experimenting with Nodes\n",
    "A classic hyperparameter in deep learning algorithms, the number of hidden units is key to regulate the representational capacity of a model. By tuning the number of nodes in our hidden layer we hope to uncover the best dense neural network model with one hidden layer. We take this experiment further and try to explore what the nodes in the hidden layer are detecting by examining their activation values. \n",
    "\n",
    "Experiments 1 - 3, classify the MNIST images using dense neural networks with one hidden layer. Eperiment 1 has a hidden layer with one node, the number of nodes increase progressively until the results converge on a \"best\" model in Experiment 3.\n",
    "\n",
    "#### Experimenting with Dimensionality\n",
    "\n",
    "Experiments 4 & 5, train the best model we found in the previous section on input data that has been compressed through dimension reduction. Experiment 4 uses Principal Component Analysis to reduce the dimensions of the input data. Experiment 5 uses random forests to select features. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# METHODOLOGY\n",
    "## Tensorflow\n",
    "TensorFlow is a software library or framework, designed by the Google team to implement machine\n",
    "learning and deep learning concepts. It combines the computational algebra of\n",
    "optimization techniques for easy calculation of many mathematical expressions Tensorflow is an\n",
    "open source library created by the Google Brain Trust for heavy computational work, geared towards\n",
    "machine learning and deep learning tasks. Tensor Flow is built on c, c++ making it very fast while it\n",
    "is available for use via Python, C++, Haskell, Java and Go API depending upon the type of work.\n",
    "It created data graph flows for each model, where a graph consists of two units – a tensor and\n",
    "a node.\n",
    " Tensor: A tensor is any dimensional array which is not single dimensional.\n",
    " Node: A node is a mathematical computation that is being worked at the moment to give the\n",
    "desired result.\n",
    "A data graph flow essentially maps the flow of information via the interchange between these two\n",
    "components. As the graph is completed, the model is executed for the output.\n",
    "\n",
    "\n",
    "## MNIST Dataset\n",
    "\n",
    "The MNIST (Modified National Institute of Standards and Technology) dataset, is a set of 70,000 images of digits handwritten by high school students and employees of the US Census Bureau. Every MNIST data point has two parts: an image of a handwritten digit and its corresponding label (0-9). Digit images are 28x28 and gray scaled. The set is divided into a training set of 60,000 images and a test set of 10,000. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation \n",
    "\n",
    "## Data preparation\n",
    "The MNIST dataset comes prepackaged as part of tf.Keras. The mnist.load_data() command loads these datasets (and the corresponding labels) as a set of four Numpy arrays. The 70,000 images are divided into a set of 60,000 training images and 10,000 test images. Our images are encoded as Numpy arrays, and the labels are an array of digits, ranging from 0 to 9. There is a one-to-one correspondence between the images and the labels. The model learns from the training set: _train_images_ and _train_labels_. The model is tested on the test set:  _test_images_ and _test_labels_.\n",
    "\n",
    "### Reshaping the Data \n",
    "\n",
    "The images are reshaped into the shape that the network expects, and scaled so that all values fall between 0-1. Training images are stored in an array of shape (60000, 28, 28) of type uint8 with values in the 0-255 interval. The images are reshaped into a float32 array of shape (60000, 28 * 28) with values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training image shape before processing: (55000, 784), test image shape before processing: (10000, 784)\n",
      "training label shape before processing: (55000,), test label shape before processing: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'training image shape before processing: {train_images.shape}, test image shape before processing: {test_images.shape}') \n",
    "print(f'training label shape before processing: {train_labels.shape}, test label shape before processing: {test_labels.shape}') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training image shape after processing: (60000, 784), test image shape after processing: (10000, 784)\n",
      "training label shape after processing: (60000,), test label shape after processing: (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "print(f'training image shape after processing: {train_images.shape}, test image shape after processing: {test_images.shape}') \n",
    "print(f'training label shape after processing: {train_labels.shape}, test label shape after processing: {test_labels.shape}') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation Sets\n",
    "The training data is seperated into a training and validation set. Each category in the training set contains 750 images, and the validation set contains the remaining images from each label. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation dataset: (5000, 784), training dataset: (50000, 784)\n"
     ]
    }
   ],
   "source": [
    "val_images, train_images = train_images[:5000], train_images[5000:] \n",
    "val_labels, train_labels = train_labels[:5000], train_labels[5000:]\n",
    "\n",
    "print(f'validation dataset: {val_images.shape}, training dataset: {train_images.shape}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation of Label Data\n",
    "Since we will be using sparse_categorical_crossentropy as the loss function we do not need to use to convert the class vector of labels into binary matrix representation.\n",
    "\n",
    "\n",
    "## Model Structure  \n",
    "The training set, stored in *val_images, train_images*, serves as the input layer to our network. The input layer is forward propogated through a hidden layer to the output layer, which outputs a predicted category. Forward propagation is the process by which the input node is multiplied by a random weight and activated according to an activation function before moving on to the next layer. \n",
    "\n",
    "#### Layers\n",
    "Each layer is made up of nodes. The nodes take in information in a numerical form. The information is presented as an activation value (or weight) where each node is given a number. The higher the number, the greater the activation. \n",
    "When optimized through backpropogation, the nodes in a hidden layer should filter the input data in a way that extracts a representation that helps categorize the numbers. \n",
    "\n",
    "All of our networks have one input layer, one hidden layer, and one output layer. \n",
    "1. Input Layer: We specify the image size, which, in this case, is 28-by-28. These numbers correspond to the height and width of the image. \n",
    "2. Hidden Layer: a Fully Connected layer in which the neurons connect to all the neurons in the preceding layer. This layer combines the pixels from the input image in a way that identifies a larger pattern. \n",
    "3. Output Layer: a fully connected layer combining the features to classify the images. Therefore, the OutputSize parameter in the last fully connected layer is equal to the number of classes in the target data. In this example, the output size is 10, corresponding to the 10 classes. Use fullyConnectedLayer to create a fully connected layer.\n",
    "\n",
    "#### Activation Functions\n",
    "Based on the connection strength (weights) and activation function, the weights pass to the next node. The nodes sum the weights they receive (it calculates the weighted sum) and modifies that sum based on its activation function. \n",
    "The activation function is a “gate” in between the input feeding the current node and its output going to the next layer. It tells the node whether is should pass along a signal or not. It could be a step function that turns the neuron output on and off, depending on a rule or it could be a transformation that maps the input signals into output signals that are needed for the neural network to function.\n",
    "\n",
    "All of our networks use the following activations:\n",
    "1. ReLU Activation (hidden layer): the simplest non-linear activation function, it performs well in most applications and is the default activation function when working on a new neural network problem. The function is as follows: if the input to the function is below zero, the output returns zero, and if the input is positive, the output is equal to the input.\n",
    "2. Softmax activation (output layer): normalizes the output of the fully connected layer. It is applied to the output layer to ensure the output values are in the range of 0 and 1 and may be used as predicted probabilities. A 10-way \"softmax\" layer will return an array of 10 probability scores (summing to 1). Each score will be the probability that the current digit image belongs to one of our 10 digit classes.\n",
    "\n",
    "\n",
    "Our networks differ only in their number of nodes in their hidden layers. A graphic representation and summary of each model's architecture is below: \n",
    "\n",
    "### Architecture of Model 1\n",
    "We begin with the simplest neural network, one hidden layer and one node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(1, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"mnist_model_1hnode.png\", show_shapes=True) # plot a graph of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 1)                 785       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                20        \n",
      "=================================================================\n",
      "Total params: 805\n",
      "Trainable params: 805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture of Model 2: \n",
    "One more node is added to our hidden layer for model 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Dense(2, activation='relu', input_shape=(28 * 28,)))\n",
    "model2.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model2, \"mnist_model_2hnode.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 2)                 1570      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                30        \n",
      "=================================================================\n",
      "Total params: 1,600\n",
      "Trainable params: 1,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture of Model 3 \n",
    "\n",
    "By experimenting with the number of nodes in the hidden layer, we are tuning our model; making adjustments to the parameter until we find its optimal value. An alternative to manually increasing the number of nodes one by one and comparing their results, is to use a library that automatically searches for the optimal parameter. \n",
    "\n",
    "#### Automatic Parameter Selection with GridSearchCV \n",
    "GridSearchCV implements the usual estimator API; when “fitting” a model to a dataset all the possible combinations of parameter values are evaluated and the best combination is kept. A cross validation process is performed in order to determine the hyper parameter value set which provides the best accuracy levels. GridSearchCV's param_grid parameter allows us to dictate our parameter and the range of values for that parameter. \n",
    "\n",
    "We first consider the performance of models with hidden nodes ranging from 1 to 1001. The parameters of this gridsearch are outputed below:\n",
    "\n",
    "param_grid = {'n_neurons': range(1,100)} param_grid and found that 20 hidden nodes provided the best model with a test accuracy of 95.99%.\n",
    "\n",
    "We also tried multiples of 100 from 100 up to 900. Running the test and found the 500 nodes gave the best result with an accuracy of 99.68%. We demonstrate this latter.\n",
    "\n",
    "* Note: GridSearch took 14 hours to run so in order to save time running the report I commented out that part of the code and hard coded a model with the results fom the search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=2, learning_rate=0.001, input_shape=(28 * 28,)):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    optimizer = keras.optimizers.RMSprop(lr=learning_rate)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer,  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New we a create a KerasClassifier object, the class is an implementation of the scikit-learn classifier API for Keras. It is actually a thin wrapper around the model that is built using our build_model function.\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "keras_clf = KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': range(1, 101)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_neurons': range(1,101)}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] n_neurons=1 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 4s 100us/sample - loss: 2.0639 - acc: 0.1888 - val_loss: 1.9654 - val_acc: 0.2234\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 1.9198 - acc: 0.2520 - val_loss: 1.8944 - val_acc: 0.2588\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 1.8645 - acc: 0.2781 - val_loss: 1.8523 - val_acc: 0.3048\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 3s 74us/sample - loss: 1.8249 - acc: 0.2944 - val_loss: 1.8315 - val_acc: 0.3078\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 3s 85us/sample - loss: 1.7911 - acc: 0.2770 - val_loss: 1.7870 - val_acc: 0.2790\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 5s 126us/sample - loss: 1.7612 - acc: 0.2685 - val_loss: 1.7609 - val_acc: 0.2660\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 3s 76us/sample - loss: 1.7360 - acc: 0.2686 - val_loss: 1.7379 - val_acc: 0.2762\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 1.7137 - acc: 0.2989 - val_loss: 1.7150 - val_acc: 0.3196\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 3s 90us/sample - loss: 1.6918 - acc: 0.3199 - val_loss: 1.6935 - val_acc: 0.3238\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 3s 83us/sample - loss: 1.6720 - acc: 0.3289 - val_loss: 1.6758 - val_acc: 0.3318\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 1.6541 - acc: 0.3334 - val_loss: 1.6559 - val_acc: 0.3362\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 3s 88us/sample - loss: 1.6400 - acc: 0.3360 - val_loss: 1.6465 - val_acc: 0.3396\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 3s 89us/sample - loss: 1.6286 - acc: 0.3429 - val_loss: 1.6332 - val_acc: 0.3514\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 1.6191 - acc: 0.3463 - val_loss: 1.6260 - val_acc: 0.3524\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 1.6105 - acc: 0.3499 - val_loss: 1.6200 - val_acc: 0.3466\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 1.6045 - acc: 0.3506 - val_loss: 1.6101 - val_acc: 0.3582\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 1.5987 - acc: 0.3516 - val_loss: 1.6034 - val_acc: 0.3560\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 1.5933 - acc: 0.3513 - val_loss: 1.5990 - val_acc: 0.3524\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 1.5888 - acc: 0.3507 - val_loss: 1.5974 - val_acc: 0.3414\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 3s 90us/sample - loss: 1.5847 - acc: 0.3467 - val_loss: 1.5970 - val_acc: 0.3490\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 1.5807 - acc: 0.3484 - val_loss: 1.5892 - val_acc: 0.3432\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 3s 93us/sample - loss: 1.5778 - acc: 0.3442 - val_loss: 1.5819 - val_acc: 0.3402\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 2s 66us/sample - loss: 1.5741 - acc: 0.3417 - val_loss: 1.5844 - val_acc: 0.3408\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 3s 78us/sample - loss: 1.5707 - acc: 0.3402 - val_loss: 1.5823 - val_acc: 0.3370\n",
      "18334/18334 [==============================] - 1s 47us/sample - loss: 1.6020 - acc: 0.3363\n",
      "[CV] ...................................... n_neurons=1, total= 1.1min\n",
      "[CV] n_neurons=1 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.0768 - acc: 0.1847 - val_loss: 1.8868 - val_acc: 0.2254\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 1.8306 - acc: 0.2344 - val_loss: 1.7638 - val_acc: 0.2564\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.7487 - acc: 0.2748 - val_loss: 1.7076 - val_acc: 0.3054\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.7047 - acc: 0.3206 - val_loss: 1.6745 - val_acc: 0.3286\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 1.6752 - acc: 0.3413 - val_loss: 1.6486 - val_acc: 0.3462\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 3s 93us/sample - loss: 1.6530 - acc: 0.3535 - val_loss: 1.6297 - val_acc: 0.3664\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 3s 92us/sample - loss: 1.6352 - acc: 0.3644 - val_loss: 1.6155 - val_acc: 0.3818\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.6180 - acc: 0.3721 - val_loss: 1.6104 - val_acc: 0.3828\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 3s 92us/sample - loss: 1.6028 - acc: 0.3806 - val_loss: 1.5883 - val_acc: 0.3896\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 3s 90us/sample - loss: 1.5898 - acc: 0.3820 - val_loss: 1.5825 - val_acc: 0.3924\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 1.5772 - acc: 0.3866 - val_loss: 1.5718 - val_acc: 0.3982\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 3s 77us/sample - loss: 1.5673 - acc: 0.3895 - val_loss: 1.5625 - val_acc: 0.4006\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 65us/sample - loss: 1.5593 - acc: 0.3926 - val_loss: 1.5536 - val_acc: 0.4114\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 1.5531 - acc: 0.3941 - val_loss: 1.5568 - val_acc: 0.4042\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 3s 71us/sample - loss: 1.5488 - acc: 0.3987 - val_loss: 1.5428 - val_acc: 0.4126\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 1.5447 - acc: 0.3970 - val_loss: 1.5491 - val_acc: 0.4106\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 1.5411 - acc: 0.3993 - val_loss: 1.5389 - val_acc: 0.4110\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 1.5383 - acc: 0.4022 - val_loss: 1.5381 - val_acc: 0.4170\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 1.5357 - acc: 0.4036 - val_loss: 1.5389 - val_acc: 0.4208\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 3s 85us/sample - loss: 1.5338 - acc: 0.4055 - val_loss: 1.5373 - val_acc: 0.4128\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 1.5326 - acc: 0.4058 - val_loss: 1.5398 - val_acc: 0.4128\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.5297 - acc: 0.4044 - val_loss: 1.5362 - val_acc: 0.4204\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 3s 82us/sample - loss: 1.5288 - acc: 0.4082 - val_loss: 1.5344 - val_acc: 0.4174\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 1.5276 - acc: 0.4061 - val_loss: 1.5320 - val_acc: 0.4172\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 1.5264 - acc: 0.4075 - val_loss: 1.5352 - val_acc: 0.4156\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 3s 76us/sample - loss: 1.5242 - acc: 0.4082 - val_loss: 1.5392 - val_acc: 0.4098\n",
      "18333/18333 [==============================] - 1s 40us/sample - loss: 1.5385 - acc: 0.4033\n",
      "[CV] ...................................... n_neurons=1, total= 1.3min\n",
      "[CV] n_neurons=1 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 111us/sample - loss: 2.0172 - acc: 0.2071 - val_loss: 1.9146 - val_acc: 0.2350\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 1.8625 - acc: 0.2420 - val_loss: 1.8285 - val_acc: 0.2400\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.7985 - acc: 0.2654 - val_loss: 1.7832 - val_acc: 0.2454\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 1.7582 - acc: 0.2882 - val_loss: 1.7435 - val_acc: 0.3044\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 1.7281 - acc: 0.3013 - val_loss: 1.7187 - val_acc: 0.2654\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 1.7089 - acc: 0.3054 - val_loss: 1.7028 - val_acc: 0.2754\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.6956 - acc: 0.3122 - val_loss: 1.6923 - val_acc: 0.3262\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.6870 - acc: 0.3185 - val_loss: 1.6851 - val_acc: 0.3270\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 3s 83us/sample - loss: 1.6797 - acc: 0.3227 - val_loss: 1.6799 - val_acc: 0.3218\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.6745 - acc: 0.3295 - val_loss: 1.6752 - val_acc: 0.3266\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 1.6706 - acc: 0.3307 - val_loss: 1.6698 - val_acc: 0.3296\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.6668 - acc: 0.3337 - val_loss: 1.6678 - val_acc: 0.3342\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.6632 - acc: 0.3382 - val_loss: 1.6660 - val_acc: 0.3386\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 1.6603 - acc: 0.3389 - val_loss: 1.6640 - val_acc: 0.3330\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 1.6569 - acc: 0.3458 - val_loss: 1.6603 - val_acc: 0.3340\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 3s 84us/sample - loss: 1.6551 - acc: 0.3494 - val_loss: 1.6651 - val_acc: 0.3348\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 3s 90us/sample - loss: 1.6520 - acc: 0.3550 - val_loss: 1.6543 - val_acc: 0.3576\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 3s 91us/sample - loss: 1.6493 - acc: 0.3579 - val_loss: 1.6502 - val_acc: 0.3562\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 1.6450 - acc: 0.3619 - val_loss: 1.6467 - val_acc: 0.3616\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 1.6416 - acc: 0.3645 - val_loss: 1.6432 - val_acc: 0.3694\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 1.6368 - acc: 0.3690 - val_loss: 1.6392 - val_acc: 0.3746\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 1.6314 - acc: 0.3672 - val_loss: 1.6331 - val_acc: 0.3738\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 1.6282 - acc: 0.3700 - val_loss: 1.6299 - val_acc: 0.3684\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 3s 81us/sample - loss: 1.6248 - acc: 0.3700 - val_loss: 1.6356 - val_acc: 0.3522\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 1.6230 - acc: 0.3675 - val_loss: 1.6281 - val_acc: 0.3610\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 1.6208 - acc: 0.3694 - val_loss: 1.6266 - val_acc: 0.3680\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 1.6194 - acc: 0.3721 - val_loss: 1.6295 - val_acc: 0.3680\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 1.6183 - acc: 0.3699 - val_loss: 1.6215 - val_acc: 0.3646\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 1.6177 - acc: 0.3685 - val_loss: 1.6331 - val_acc: 0.3546\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.6164 - acc: 0.3716 - val_loss: 1.6238 - val_acc: 0.3662\n",
      "18333/18333 [==============================] - 1s 48us/sample - loss: 1.6205 - acc: 0.3596\n",
      "[CV] ...................................... n_neurons=1, total= 1.8min\n",
      "[CV] n_neurons=2 .....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 6s 153us/sample - loss: 1.7700 - acc: 0.3552 - val_loss: 1.5365 - val_acc: 0.4100\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 5s 132us/sample - loss: 1.4532 - acc: 0.4360 - val_loss: 1.3538 - val_acc: 0.4770\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 3s 87us/sample - loss: 1.3429 - acc: 0.4766 - val_loss: 1.2873 - val_acc: 0.5020\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 4s 100us/sample - loss: 1.2914 - acc: 0.4917 - val_loss: 1.2509 - val_acc: 0.5012\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 4s 97us/sample - loss: 1.2559 - acc: 0.5046 - val_loss: 1.2192 - val_acc: 0.5282\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 4s 97us/sample - loss: 1.2272 - acc: 0.5214 - val_loss: 1.1887 - val_acc: 0.5406\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 4s 104us/sample - loss: 1.2002 - acc: 0.5371 - val_loss: 1.1682 - val_acc: 0.5526\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 4s 113us/sample - loss: 1.1771 - acc: 0.5546 - val_loss: 1.1425 - val_acc: 0.5834\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 4s 105us/sample - loss: 1.1534 - acc: 0.5807 - val_loss: 1.1179 - val_acc: 0.6024\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 3s 95us/sample - loss: 1.1341 - acc: 0.6018 - val_loss: 1.1023 - val_acc: 0.6290\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 4s 96us/sample - loss: 1.1128 - acc: 0.6249 - val_loss: 1.0884 - val_acc: 0.6324\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 4s 99us/sample - loss: 1.0946 - acc: 0.6340 - val_loss: 1.0721 - val_acc: 0.6476\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 3s 93us/sample - loss: 1.0821 - acc: 0.6370 - val_loss: 1.0595 - val_acc: 0.6500\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 4s 106us/sample - loss: 1.0736 - acc: 0.6370 - val_loss: 1.0528 - val_acc: 0.6452\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 3s 86us/sample - loss: 1.0688 - acc: 0.6370 - val_loss: 1.0472 - val_acc: 0.6522\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 3s 87us/sample - loss: 1.0648 - acc: 0.6390 - val_loss: 1.0578 - val_acc: 0.6466\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 3s 91us/sample - loss: 1.0615 - acc: 0.6410 - val_loss: 1.0457 - val_acc: 0.6544\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 4s 98us/sample - loss: 1.0592 - acc: 0.6412 - val_loss: 1.0461 - val_acc: 0.6486\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 3s 82us/sample - loss: 1.0571 - acc: 0.6397 - val_loss: 1.0393 - val_acc: 0.6574\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 3s 87us/sample - loss: 1.0552 - acc: 0.6425 - val_loss: 1.0478 - val_acc: 0.6534\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 3s 88us/sample - loss: 1.0532 - acc: 0.6417 - val_loss: 1.0449 - val_acc: 0.6478\n",
      "18334/18334 [==============================] - 1s 42us/sample - loss: 1.0991 - acc: 0.6224\n",
      "[CV] ...................................... n_neurons=2, total= 1.3min\n",
      "[CV] n_neurons=2 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 5s 129us/sample - loss: 1.6403 - acc: 0.4452 - val_loss: 1.4318 - val_acc: 0.5316\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 1.3358 - acc: 0.5612 - val_loss: 1.2722 - val_acc: 0.5872\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 1.2174 - acc: 0.6044 - val_loss: 1.1913 - val_acc: 0.6188\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.1514 - acc: 0.6274 - val_loss: 1.1532 - val_acc: 0.6346\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 3s 92us/sample - loss: 1.1138 - acc: 0.6387 - val_loss: 1.1229 - val_acc: 0.6502\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 1.0928 - acc: 0.6477 - val_loss: 1.1051 - val_acc: 0.6556\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 1.0784 - acc: 0.6501 - val_loss: 1.0959 - val_acc: 0.6606\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 1.0679 - acc: 0.6544 - val_loss: 1.0883 - val_acc: 0.6702\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 1.0603 - acc: 0.6578 - val_loss: 1.0870 - val_acc: 0.6642\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 1.0530 - acc: 0.6593 - val_loss: 1.0883 - val_acc: 0.6600\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 1.0469 - acc: 0.6620 - val_loss: 1.0732 - val_acc: 0.6794\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 113us/sample - loss: 1.0423 - acc: 0.6643 - val_loss: 1.0683 - val_acc: 0.6826\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.0378 - acc: 0.6651 - val_loss: 1.0632 - val_acc: 0.6868\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 1.0336 - acc: 0.6677 - val_loss: 1.0669 - val_acc: 0.6728\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 1.0309 - acc: 0.6677 - val_loss: 1.0604 - val_acc: 0.6828\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 3s 85us/sample - loss: 1.0272 - acc: 0.6687 - val_loss: 1.0604 - val_acc: 0.6814\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 1.0246 - acc: 0.6706 - val_loss: 1.0575 - val_acc: 0.6770\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 114us/sample - loss: 1.0232 - acc: 0.6731 - val_loss: 1.0598 - val_acc: 0.6842\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 1.0207 - acc: 0.6730 - val_loss: 1.0542 - val_acc: 0.6842\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 1.0193 - acc: 0.6735 - val_loss: 1.0554 - val_acc: 0.6846\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.0174 - acc: 0.6749 - val_loss: 1.0552 - val_acc: 0.6942\n",
      "18333/18333 [==============================] - 1s 45us/sample - loss: 1.0598 - acc: 0.6720\n",
      "[CV] ...................................... n_neurons=2, total= 1.3min\n",
      "[CV] n_neurons=2 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 122us/sample - loss: 1.6264 - acc: 0.4008 - val_loss: 1.3539 - val_acc: 0.5400\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.2723 - acc: 0.5519 - val_loss: 1.1848 - val_acc: 0.6066\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 115us/sample - loss: 1.1564 - acc: 0.5978 - val_loss: 1.1132 - val_acc: 0.6390\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 1.0920 - acc: 0.6297 - val_loss: 1.0539 - val_acc: 0.6622\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 1.0516 - acc: 0.6479 - val_loss: 1.0246 - val_acc: 0.6728\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 1.0281 - acc: 0.6606 - val_loss: 1.0066 - val_acc: 0.6896\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 3s 91us/sample - loss: 1.0122 - acc: 0.6687 - val_loss: 0.9972 - val_acc: 0.6918\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 3s 90us/sample - loss: 1.0007 - acc: 0.6764 - val_loss: 0.9915 - val_acc: 0.6920\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 3s 91us/sample - loss: 0.9922 - acc: 0.6817 - val_loss: 0.9842 - val_acc: 0.6966\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.9853 - acc: 0.6828 - val_loss: 0.9781 - val_acc: 0.7026\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 3s 93us/sample - loss: 0.9805 - acc: 0.6864 - val_loss: 0.9761 - val_acc: 0.7024\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 3s 85us/sample - loss: 0.9759 - acc: 0.6876 - val_loss: 0.9735 - val_acc: 0.7070\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 3s 85us/sample - loss: 0.9724 - acc: 0.6887 - val_loss: 0.9698 - val_acc: 0.7062\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 0.9691 - acc: 0.6889 - val_loss: 0.9706 - val_acc: 0.7096\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 3s 92us/sample - loss: 0.9658 - acc: 0.6927 - val_loss: 0.9701 - val_acc: 0.7116\n",
      "18333/18333 [==============================] - 1s 46us/sample - loss: 0.9577 - acc: 0.6974\n",
      "[CV] ...................................... n_neurons=2, total=  56.0s\n",
      "[CV] n_neurons=3 .....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 4s 96us/sample - loss: 1.4766 - acc: 0.5098 - val_loss: 1.1349 - val_acc: 0.6290\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 4s 97us/sample - loss: 1.0606 - acc: 0.6589 - val_loss: 0.9729 - val_acc: 0.6912\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 3s 82us/sample - loss: 0.9445 - acc: 0.7062 - val_loss: 0.9011 - val_acc: 0.7230\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 4s 96us/sample - loss: 0.8874 - acc: 0.7250 - val_loss: 0.8650 - val_acc: 0.7320\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 4s 101us/sample - loss: 0.8557 - acc: 0.7322 - val_loss: 0.8406 - val_acc: 0.7440\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 3s 85us/sample - loss: 0.8347 - acc: 0.7393 - val_loss: 0.8232 - val_acc: 0.7476\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 3s 88us/sample - loss: 0.8179 - acc: 0.7431 - val_loss: 0.8122 - val_acc: 0.7492\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 3s 90us/sample - loss: 0.8058 - acc: 0.7455 - val_loss: 0.8029 - val_acc: 0.7556\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 4s 103us/sample - loss: 0.7956 - acc: 0.7508 - val_loss: 0.7969 - val_acc: 0.7568\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 3s 94us/sample - loss: 0.7869 - acc: 0.7526 - val_loss: 0.7927 - val_acc: 0.7598\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 4s 105us/sample - loss: 0.7790 - acc: 0.7559 - val_loss: 0.7894 - val_acc: 0.7534\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 3s 88us/sample - loss: 0.7726 - acc: 0.7577 - val_loss: 0.7846 - val_acc: 0.7666\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 0.7667 - acc: 0.7608 - val_loss: 0.7755 - val_acc: 0.7714\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 4s 98us/sample - loss: 0.7602 - acc: 0.7640 - val_loss: 0.7671 - val_acc: 0.7726\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 3s 89us/sample - loss: 0.7554 - acc: 0.7656 - val_loss: 0.7658 - val_acc: 0.7764\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 3s 92us/sample - loss: 0.7506 - acc: 0.7681 - val_loss: 0.7641 - val_acc: 0.7782\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 4s 95us/sample - loss: 0.7465 - acc: 0.7705 - val_loss: 0.7603 - val_acc: 0.7836\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 3s 94us/sample - loss: 0.7428 - acc: 0.7726 - val_loss: 0.7561 - val_acc: 0.7810\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 4s 96us/sample - loss: 0.7390 - acc: 0.7748 - val_loss: 0.7538 - val_acc: 0.7886\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 0.7364 - acc: 0.7771 - val_loss: 0.7452 - val_acc: 0.7848\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 4s 97us/sample - loss: 0.7331 - acc: 0.7779 - val_loss: 0.7488 - val_acc: 0.7910\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 3s 90us/sample - loss: 0.7309 - acc: 0.7794 - val_loss: 0.7515 - val_acc: 0.7866\n",
      "18334/18334 [==============================] - 1s 42us/sample - loss: 0.7859 - acc: 0.7613\n",
      "[CV] ...................................... n_neurons=3, total= 1.3min\n",
      "[CV] n_neurons=3 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 1.4281 - acc: 0.5232 - val_loss: 1.1020 - val_acc: 0.6282\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 0.9381 - acc: 0.7319 - val_loss: 0.8219 - val_acc: 0.7702\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 113us/sample - loss: 0.7889 - acc: 0.7775 - val_loss: 0.7558 - val_acc: 0.7846\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 0.7438 - acc: 0.7896 - val_loss: 0.7246 - val_acc: 0.7978\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 0.7235 - acc: 0.7950 - val_loss: 0.7124 - val_acc: 0.8048\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 3s 91us/sample - loss: 0.7121 - acc: 0.7978 - val_loss: 0.7014 - val_acc: 0.8026\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 112us/sample - loss: 0.7037 - acc: 0.8002 - val_loss: 0.7017 - val_acc: 0.8034\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 0.6981 - acc: 0.8030 - val_loss: 0.6956 - val_acc: 0.8092\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 0.6936 - acc: 0.8028 - val_loss: 0.6945 - val_acc: 0.8080\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 65us/sample - loss: 0.6906 - acc: 0.8046 - val_loss: 0.6922 - val_acc: 0.8110\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 68us/sample - loss: 0.6873 - acc: 0.8039 - val_loss: 0.6923 - val_acc: 0.8126\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 65us/sample - loss: 0.6848 - acc: 0.8058 - val_loss: 0.6952 - val_acc: 0.8118\n",
      "18333/18333 [==============================] - 1s 32us/sample - loss: 0.7363 - acc: 0.7929\n",
      "[CV] ...................................... n_neurons=3, total=  41.5s\n",
      "[CV] n_neurons=3 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 82us/sample - loss: 1.4936 - acc: 0.4662 - val_loss: 1.1243 - val_acc: 0.6488\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 64us/sample - loss: 1.0050 - acc: 0.6647 - val_loss: 0.8830 - val_acc: 0.7064\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 3s 72us/sample - loss: 0.8632 - acc: 0.7103 - val_loss: 0.7821 - val_acc: 0.7592\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 3s 73us/sample - loss: 0.7888 - acc: 0.7530 - val_loss: 0.7335 - val_acc: 0.7810\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.7476 - acc: 0.7690 - val_loss: 0.7056 - val_acc: 0.7874\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 3s 82us/sample - loss: 0.7205 - acc: 0.7801 - val_loss: 0.6824 - val_acc: 0.7942\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 0.7013 - acc: 0.7873 - val_loss: 0.6745 - val_acc: 0.8020\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 3s 78us/sample - loss: 0.6865 - acc: 0.7957 - val_loss: 0.6646 - val_acc: 0.8038\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 132us/sample - loss: 0.6751 - acc: 0.8010 - val_loss: 0.6604 - val_acc: 0.8104\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 3s 81us/sample - loss: 0.6664 - acc: 0.8043 - val_loss: 0.6559 - val_acc: 0.8126\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 3s 75us/sample - loss: 0.6602 - acc: 0.8075 - val_loss: 0.6544 - val_acc: 0.8116\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 3s 74us/sample - loss: 0.6550 - acc: 0.8093 - val_loss: 0.6462 - val_acc: 0.8162\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 3s 71us/sample - loss: 0.6502 - acc: 0.8107 - val_loss: 0.6453 - val_acc: 0.8132\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 3s 70us/sample - loss: 0.6457 - acc: 0.8126 - val_loss: 0.6446 - val_acc: 0.8192\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 3s 69us/sample - loss: 0.6431 - acc: 0.8123 - val_loss: 0.6493 - val_acc: 0.8146\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 66us/sample - loss: 0.6396 - acc: 0.8136 - val_loss: 0.6399 - val_acc: 0.8188\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 3s 69us/sample - loss: 0.6377 - acc: 0.8161 - val_loss: 0.6402 - val_acc: 0.8174\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.6357 - acc: 0.8152 - val_loss: 0.6355 - val_acc: 0.8206\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 64us/sample - loss: 0.6339 - acc: 0.8161 - val_loss: 0.6416 - val_acc: 0.8178\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.6322 - acc: 0.8169 - val_loss: 0.6440 - val_acc: 0.8138\n",
      "18333/18333 [==============================] - 1s 32us/sample - loss: 0.6350 - acc: 0.8093\n",
      "[CV] ...................................... n_neurons=3, total=  57.9s\n",
      "[CV] n_neurons=4 .....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 86us/sample - loss: 1.2089 - acc: 0.5983 - val_loss: 0.8258 - val_acc: 0.7526\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 67us/sample - loss: 0.7700 - acc: 0.7666 - val_loss: 0.7117 - val_acc: 0.7940\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 3s 71us/sample - loss: 0.6943 - acc: 0.7924 - val_loss: 0.6641 - val_acc: 0.8098\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 3s 73us/sample - loss: 0.6523 - acc: 0.8050 - val_loss: 0.6305 - val_acc: 0.8240\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 3s 69us/sample - loss: 0.6220 - acc: 0.8156 - val_loss: 0.6127 - val_acc: 0.8252\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 67us/sample - loss: 0.5985 - acc: 0.8230 - val_loss: 0.5912 - val_acc: 0.8348\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 66us/sample - loss: 0.5797 - acc: 0.8293 - val_loss: 0.5769 - val_acc: 0.8396\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 66us/sample - loss: 0.5604 - acc: 0.8353 - val_loss: 0.5588 - val_acc: 0.8466\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 65us/sample - loss: 0.5431 - acc: 0.8418 - val_loss: 0.5478 - val_acc: 0.8444\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 66us/sample - loss: 0.5274 - acc: 0.8485 - val_loss: 0.5392 - val_acc: 0.8500\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 3s 71us/sample - loss: 0.5171 - acc: 0.8517 - val_loss: 0.5298 - val_acc: 0.8542\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 3s 68us/sample - loss: 0.5102 - acc: 0.8549 - val_loss: 0.5239 - val_acc: 0.8560\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 66us/sample - loss: 0.5049 - acc: 0.8581 - val_loss: 0.5172 - val_acc: 0.8598\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 63us/sample - loss: 0.5010 - acc: 0.8593 - val_loss: 0.5130 - val_acc: 0.8626\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 68us/sample - loss: 0.4966 - acc: 0.8631 - val_loss: 0.5124 - val_acc: 0.8628\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 66us/sample - loss: 0.4934 - acc: 0.8631 - val_loss: 0.5155 - val_acc: 0.8584\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 66us/sample - loss: 0.4915 - acc: 0.8639 - val_loss: 0.5086 - val_acc: 0.8644\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 67us/sample - loss: 0.4897 - acc: 0.8652 - val_loss: 0.5048 - val_acc: 0.8632\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 66us/sample - loss: 0.4882 - acc: 0.8658 - val_loss: 0.5092 - val_acc: 0.8618\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 2s 67us/sample - loss: 0.4874 - acc: 0.8663 - val_loss: 0.5055 - val_acc: 0.8640\n",
      "18334/18334 [==============================] - 1s 43us/sample - loss: 0.5291 - acc: 0.8542\n",
      "[CV] ...................................... n_neurons=4, total=  51.6s\n",
      "[CV] n_neurons=4 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 1.3397 - acc: 0.5612 - val_loss: 0.9255 - val_acc: 0.7042\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 3s 69us/sample - loss: 0.7773 - acc: 0.7710 - val_loss: 0.6677 - val_acc: 0.8130\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 3s 71us/sample - loss: 0.6384 - acc: 0.8167 - val_loss: 0.6014 - val_acc: 0.8336\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 3s 76us/sample - loss: 0.5884 - acc: 0.8310 - val_loss: 0.5728 - val_acc: 0.8424\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.5612 - acc: 0.8400 - val_loss: 0.5494 - val_acc: 0.8488\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 3s 77us/sample - loss: 0.5442 - acc: 0.8449 - val_loss: 0.5381 - val_acc: 0.8520\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 0.5335 - acc: 0.8478 - val_loss: 0.5298 - val_acc: 0.8550\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 119us/sample - loss: 0.5253 - acc: 0.8504 - val_loss: 0.5267 - val_acc: 0.8558\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 122us/sample - loss: 0.5198 - acc: 0.8519 - val_loss: 0.5203 - val_acc: 0.8586\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 120us/sample - loss: 0.5151 - acc: 0.8541 - val_loss: 0.5164 - val_acc: 0.8586\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 118us/sample - loss: 0.5107 - acc: 0.8547 - val_loss: 0.5171 - val_acc: 0.8538\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 0.5070 - acc: 0.8562 - val_loss: 0.5117 - val_acc: 0.8606\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 0.5046 - acc: 0.8550 - val_loss: 0.5141 - val_acc: 0.8618\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 111us/sample - loss: 0.5022 - acc: 0.8578 - val_loss: 0.5212 - val_acc: 0.8606\n",
      "18333/18333 [==============================] - 1s 53us/sample - loss: 0.5589 - acc: 0.8462\n",
      "[CV] ...................................... n_neurons=4, total=  51.9s\n",
      "[CV] n_neurons=4 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 5s 129us/sample - loss: 1.1108 - acc: 0.6471 - val_loss: 0.7270 - val_acc: 0.7870\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 111us/sample - loss: 0.6900 - acc: 0.8004 - val_loss: 0.6150 - val_acc: 0.8322\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 127us/sample - loss: 0.6133 - acc: 0.8276 - val_loss: 0.5690 - val_acc: 0.8468\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 0.5780 - acc: 0.8387 - val_loss: 0.5587 - val_acc: 0.8450\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 0.5575 - acc: 0.8431 - val_loss: 0.5375 - val_acc: 0.8528\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 3s 93us/sample - loss: 0.5445 - acc: 0.8474 - val_loss: 0.5290 - val_acc: 0.8526\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.5357 - acc: 0.8498 - val_loss: 0.5263 - val_acc: 0.8516\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 114us/sample - loss: 0.5282 - acc: 0.8518 - val_loss: 0.5320 - val_acc: 0.8542\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 113us/sample - loss: 0.5234 - acc: 0.8547 - val_loss: 0.5140 - val_acc: 0.8560\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 115us/sample - loss: 0.5173 - acc: 0.8546 - val_loss: 0.5128 - val_acc: 0.8598\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 0.5137 - acc: 0.8567 - val_loss: 0.5195 - val_acc: 0.8534\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 0.5099 - acc: 0.8568 - val_loss: 0.5086 - val_acc: 0.8554\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.5066 - acc: 0.8587 - val_loss: 0.5058 - val_acc: 0.8586\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 0.5039 - acc: 0.8603 - val_loss: 0.5167 - val_acc: 0.8570\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 0.5014 - acc: 0.8593 - val_loss: 0.5112 - val_acc: 0.8586\n",
      "18333/18333 [==============================] - 1s 56us/sample - loss: 0.5042 - acc: 0.8583\n",
      "[CV] ...................................... n_neurons=4, total= 1.0min\n",
      "[CV] n_neurons=5 .....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 5s 133us/sample - loss: 1.1375 - acc: 0.6319 - val_loss: 0.6631 - val_acc: 0.8094\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 4s 103us/sample - loss: 0.5596 - acc: 0.8394 - val_loss: 0.4750 - val_acc: 0.8700\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 4s 99us/sample - loss: 0.4663 - acc: 0.8682 - val_loss: 0.4255 - val_acc: 0.8830\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 4s 98us/sample - loss: 0.4319 - acc: 0.8790 - val_loss: 0.4068 - val_acc: 0.8892\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 4s 111us/sample - loss: 0.4137 - acc: 0.8838 - val_loss: 0.3977 - val_acc: 0.8952\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 4s 105us/sample - loss: 0.4004 - acc: 0.8877 - val_loss: 0.3885 - val_acc: 0.8960\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 4s 115us/sample - loss: 0.3913 - acc: 0.8912 - val_loss: 0.3807 - val_acc: 0.8976\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.3842 - acc: 0.8942 - val_loss: 0.3784 - val_acc: 0.8964\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 4s 100us/sample - loss: 0.3782 - acc: 0.8950 - val_loss: 0.3823 - val_acc: 0.8984\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 4s 111us/sample - loss: 0.3739 - acc: 0.8965 - val_loss: 0.3750 - val_acc: 0.9008\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 4s 117us/sample - loss: 0.3698 - acc: 0.8976 - val_loss: 0.3722 - val_acc: 0.8994acc: 0.8\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 4s 113us/sample - loss: 0.3669 - acc: 0.8994 - val_loss: 0.3696 - val_acc: 0.8994\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 4s 119us/sample - loss: 0.3635 - acc: 0.8996 - val_loss: 0.3726 - val_acc: 0.9002\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 4s 122us/sample - loss: 0.3619 - acc: 0.9003 - val_loss: 0.3706 - val_acc: 0.9012\n",
      "18334/18334 [==============================] - 1s 63us/sample - loss: 0.4006 - acc: 0.8924\n",
      "[CV] ...................................... n_neurons=5, total=  59.1s\n",
      "[CV] n_neurons=5 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 5s 129us/sample - loss: 0.9381 - acc: 0.7118 - val_loss: 0.5954 - val_acc: 0.8186\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 128us/sample - loss: 0.5681 - acc: 0.8230 - val_loss: 0.5286 - val_acc: 0.8400\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 112us/sample - loss: 0.5221 - acc: 0.8406 - val_loss: 0.4907 - val_acc: 0.8566\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 0.4891 - acc: 0.8573 - val_loss: 0.4634 - val_acc: 0.8688\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.4613 - acc: 0.8673 - val_loss: 0.4480 - val_acc: 0.8698\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.4412 - acc: 0.8752 - val_loss: 0.4353 - val_acc: 0.8826\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.4275 - acc: 0.8797 - val_loss: 0.4160 - val_acc: 0.8822\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 116us/sample - loss: 0.4167 - acc: 0.8836 - val_loss: 0.4097 - val_acc: 0.8874\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 119us/sample - loss: 0.4093 - acc: 0.8858 - val_loss: 0.4119 - val_acc: 0.8870\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.4024 - acc: 0.8890 - val_loss: 0.4026 - val_acc: 0.8886\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 0.3974 - acc: 0.8899 - val_loss: 0.4012 - val_acc: 0.8908\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 0.3937 - acc: 0.8921 - val_loss: 0.3993 - val_acc: 0.8852\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.3906 - acc: 0.8921 - val_loss: 0.3982 - val_acc: 0.8896\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 117us/sample - loss: 0.3869 - acc: 0.8931 - val_loss: 0.3934 - val_acc: 0.8902\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 116us/sample - loss: 0.3849 - acc: 0.8939 - val_loss: 0.3927 - val_acc: 0.8940\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 4s 121us/sample - loss: 0.3820 - acc: 0.8947 - val_loss: 0.3918 - val_acc: 0.8922\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 0.3803 - acc: 0.8952 - val_loss: 0.3932 - val_acc: 0.8936\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 0.3791 - acc: 0.8954 - val_loss: 0.3915 - val_acc: 0.8932\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.3766 - acc: 0.8957 - val_loss: 0.3887 - val_acc: 0.8960\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.3763 - acc: 0.8975 - val_loss: 0.3954 - val_acc: 0.8926\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 0.3741 - acc: 0.8980 - val_loss: 0.3872 - val_acc: 0.8938\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.3736 - acc: 0.8983 - val_loss: 0.3923 - val_acc: 0.8940\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 4s 111us/sample - loss: 0.3720 - acc: 0.8987 - val_loss: 0.3867 - val_acc: 0.8956\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 4s 114us/sample - loss: 0.3718 - acc: 0.8982 - val_loss: 0.3886 - val_acc: 0.8944\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 0.3706 - acc: 0.8999 - val_loss: 0.3874 - val_acc: 0.8946\n",
      "18333/18333 [==============================] - 1s 51us/sample - loss: 0.4360 - acc: 0.8839\n",
      "[CV] ...................................... n_neurons=5, total= 1.7min\n",
      "[CV] n_neurons=5 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 5s 123us/sample - loss: 0.8983 - acc: 0.7156 - val_loss: 0.5292 - val_acc: 0.8588\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 114us/sample - loss: 0.4990 - acc: 0.8570 - val_loss: 0.4431 - val_acc: 0.8764\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 0.4514 - acc: 0.8721 - val_loss: 0.4232 - val_acc: 0.8866\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 0.4318 - acc: 0.8787 - val_loss: 0.4070 - val_acc: 0.8872\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 121us/sample - loss: 0.4209 - acc: 0.8824 - val_loss: 0.4005 - val_acc: 0.8958\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 125us/sample - loss: 0.4124 - acc: 0.8858 - val_loss: 0.3994 - val_acc: 0.8938\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 116us/sample - loss: 0.4064 - acc: 0.8864 - val_loss: 0.4001 - val_acc: 0.8926\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.4015 - acc: 0.8893 - val_loss: 0.3928 - val_acc: 0.8906\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 0.3974 - acc: 0.8904 - val_loss: 0.3905 - val_acc: 0.8970\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.3941 - acc: 0.8908 - val_loss: 0.3858 - val_acc: 0.9002\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 5s 124us/sample - loss: 0.3905 - acc: 0.8923 - val_loss: 0.3895 - val_acc: 0.8956\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 5s 127us/sample - loss: 0.3876 - acc: 0.8938 - val_loss: 0.3877 - val_acc: 0.8926\n",
      "18333/18333 [==============================] - 1s 66us/sample - loss: 0.3829 - acc: 0.8890\n",
      "[CV] ...................................... n_neurons=5, total=  52.7s\n",
      "[CV] n_neurons=6 .....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 5s 135us/sample - loss: 0.9180 - acc: 0.7075 - val_loss: 0.5651 - val_acc: 0.8266\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 4s 105us/sample - loss: 0.5347 - acc: 0.8411 - val_loss: 0.4951 - val_acc: 0.8528\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 0.4765 - acc: 0.8592 - val_loss: 0.4568 - val_acc: 0.8696\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 5s 125us/sample - loss: 0.4423 - acc: 0.8710 - val_loss: 0.4300 - val_acc: 0.8792\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 4s 104us/sample - loss: 0.4163 - acc: 0.8797 - val_loss: 0.4133 - val_acc: 0.8814\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 4s 113us/sample - loss: 0.3969 - acc: 0.8879 - val_loss: 0.3900 - val_acc: 0.8894\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 4s 120us/sample - loss: 0.3828 - acc: 0.8932 - val_loss: 0.3819 - val_acc: 0.8984\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 0.3716 - acc: 0.8964 - val_loss: 0.3683 - val_acc: 0.8994\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 0.3631 - acc: 0.8995 - val_loss: 0.3688 - val_acc: 0.8970\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 4s 105us/sample - loss: 0.3548 - acc: 0.9012 - val_loss: 0.3584 - val_acc: 0.9022\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 4s 105us/sample - loss: 0.3491 - acc: 0.9028 - val_loss: 0.3527 - val_acc: 0.9018\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 0.3443 - acc: 0.9040 - val_loss: 0.3495 - val_acc: 0.9032\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 4s 106us/sample - loss: 0.3402 - acc: 0.9059 - val_loss: 0.3510 - val_acc: 0.9070\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 5s 126us/sample - loss: 0.3364 - acc: 0.9069 - val_loss: 0.3562 - val_acc: 0.9018\n",
      "18334/18334 [==============================] - 1s 64us/sample - loss: 0.3896 - acc: 0.8945\n",
      "[CV] ...................................... n_neurons=6, total=  59.2s\n",
      "[CV] n_neurons=6 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 5s 140us/sample - loss: 0.8189 - acc: 0.7544 - val_loss: 0.4834 - val_acc: 0.8670\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 0.4492 - acc: 0.8723 - val_loss: 0.3963 - val_acc: 0.8938\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.3971 - acc: 0.8859 - val_loss: 0.3709 - val_acc: 0.8980\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.3698 - acc: 0.8938 - val_loss: 0.3562 - val_acc: 0.9036\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 124us/sample - loss: 0.3537 - acc: 0.8990 - val_loss: 0.3425 - val_acc: 0.9052\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 0.3416 - acc: 0.9019 - val_loss: 0.3384 - val_acc: 0.9056\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.3313 - acc: 0.9050 - val_loss: 0.3310 - val_acc: 0.9082\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 126us/sample - loss: 0.3246 - acc: 0.9074 - val_loss: 0.3327 - val_acc: 0.9088\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.3183 - acc: 0.9091 - val_loss: 0.3287 - val_acc: 0.9080\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 118us/sample - loss: 0.3123 - acc: 0.9117 - val_loss: 0.3272 - val_acc: 0.9058\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 113us/sample - loss: 0.3083 - acc: 0.9129 - val_loss: 0.3209 - val_acc: 0.9092\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 0.3049 - acc: 0.9140 - val_loss: 0.3234 - val_acc: 0.9116\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 0.3016 - acc: 0.9159 - val_loss: 0.3192 - val_acc: 0.9110\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.2983 - acc: 0.9170 - val_loss: 0.3253 - val_acc: 0.9112\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.2965 - acc: 0.9172 - val_loss: 0.3194 - val_acc: 0.9096\n",
      "18333/18333 [==============================] - 1s 58us/sample - loss: 0.3496 - acc: 0.9033\n",
      "[CV] ...................................... n_neurons=6, total= 1.0min\n",
      "[CV] n_neurons=6 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 121us/sample - loss: 0.8180 - acc: 0.7563 - val_loss: 0.4944 - val_acc: 0.8644\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.4724 - acc: 0.8627 - val_loss: 0.4041 - val_acc: 0.8936\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 120us/sample - loss: 0.4117 - acc: 0.8847 - val_loss: 0.3738 - val_acc: 0.9002\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 0.3806 - acc: 0.8945 - val_loss: 0.3549 - val_acc: 0.9080\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 0.3611 - acc: 0.9002 - val_loss: 0.3442 - val_acc: 0.9036\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.3479 - acc: 0.9048 - val_loss: 0.3379 - val_acc: 0.9086\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.3397 - acc: 0.9071 - val_loss: 0.3315 - val_acc: 0.9092\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 116us/sample - loss: 0.3332 - acc: 0.9089 - val_loss: 0.3237 - val_acc: 0.9118\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.3284 - acc: 0.9107 - val_loss: 0.3239 - val_acc: 0.9130\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.3244 - acc: 0.9107 - val_loss: 0.3209 - val_acc: 0.9152\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.3212 - acc: 0.9114 - val_loss: 0.3178 - val_acc: 0.9154\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.3185 - acc: 0.9130 - val_loss: 0.3192 - val_acc: 0.9132\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.3166 - acc: 0.9139 - val_loss: 0.3136 - val_acc: 0.9152\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.3148 - acc: 0.9144 - val_loss: 0.3267 - val_acc: 0.9104\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.3133 - acc: 0.9139 - val_loss: 0.3124 - val_acc: 0.9170\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.3121 - acc: 0.9147 - val_loss: 0.3122 - val_acc: 0.9172\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 4s 113us/sample - loss: 0.3110 - acc: 0.9163 - val_loss: 0.3185 - val_acc: 0.9124\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 112us/sample - loss: 0.3096 - acc: 0.9148 - val_loss: 0.3181 - val_acc: 0.9160\n",
      "18333/18333 [==============================] - 1s 54us/sample - loss: 0.3316 - acc: 0.9066\n",
      "[CV] ...................................... n_neurons=6, total= 1.2min\n",
      "[CV] n_neurons=7 .....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 4s 122us/sample - loss: 0.8702 - acc: 0.7398 - val_loss: 0.4714 - val_acc: 0.8730\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 4s 120us/sample - loss: 0.4269 - acc: 0.8810 - val_loss: 0.3853 - val_acc: 0.8962\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 4s 115us/sample - loss: 0.3732 - acc: 0.8958 - val_loss: 0.3595 - val_acc: 0.9028\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 4s 110us/sample - loss: 0.3468 - acc: 0.9025 - val_loss: 0.3392 - val_acc: 0.9052\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 4s 105us/sample - loss: 0.3288 - acc: 0.9071 - val_loss: 0.3267 - val_acc: 0.9110\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 4s 106us/sample - loss: 0.3157 - acc: 0.9115 - val_loss: 0.3119 - val_acc: 0.9166\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.3050 - acc: 0.9133 - val_loss: 0.3083 - val_acc: 0.9134\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 4s 109us/sample - loss: 0.2983 - acc: 0.9160 - val_loss: 0.3050 - val_acc: 0.9136\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 4s 105us/sample - loss: 0.2924 - acc: 0.9187 - val_loss: 0.3099 - val_acc: 0.9146\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 0.2882 - acc: 0.9191 - val_loss: 0.3100 - val_acc: 0.9116\n",
      "18334/18334 [==============================] - 1s 56us/sample - loss: 0.3392 - acc: 0.9079\n",
      "[CV] ...................................... n_neurons=7, total=  42.5s\n",
      "[CV] n_neurons=7 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 5s 133us/sample - loss: 0.8304 - acc: 0.7574 - val_loss: 0.4296 - val_acc: 0.8798\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.4007 - acc: 0.8838 - val_loss: 0.3528 - val_acc: 0.9006\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 113us/sample - loss: 0.3520 - acc: 0.9007 - val_loss: 0.3368 - val_acc: 0.9066\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 122us/sample - loss: 0.3315 - acc: 0.9074 - val_loss: 0.3219 - val_acc: 0.9126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.3187 - acc: 0.9122 - val_loss: 0.3214 - val_acc: 0.9110\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 113us/sample - loss: 0.3105 - acc: 0.9145 - val_loss: 0.3140 - val_acc: 0.9156\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 120us/sample - loss: 0.3046 - acc: 0.9170 - val_loss: 0.3061 - val_acc: 0.9200\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 117us/sample - loss: 0.2993 - acc: 0.9177 - val_loss: 0.3070 - val_acc: 0.9190\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 124us/sample - loss: 0.2941 - acc: 0.9196 - val_loss: 0.3111 - val_acc: 0.9144\n",
      "18333/18333 [==============================] - 1s 65us/sample - loss: 0.3371 - acc: 0.9085\n",
      "[CV] ...................................... n_neurons=7, total=  41.2s\n",
      "[CV] n_neurons=7 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 5s 127us/sample - loss: 0.8034 - acc: 0.7555 - val_loss: 0.4560 - val_acc: 0.8738\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 115us/sample - loss: 0.4381 - acc: 0.8709 - val_loss: 0.3844 - val_acc: 0.8926\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.3889 - acc: 0.8877 - val_loss: 0.3542 - val_acc: 0.8996\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 122us/sample - loss: 0.3605 - acc: 0.8965 - val_loss: 0.3337 - val_acc: 0.9068\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 124us/sample - loss: 0.3401 - acc: 0.9024 - val_loss: 0.3256 - val_acc: 0.9082\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.3271 - acc: 0.9073 - val_loss: 0.3132 - val_acc: 0.9120\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 129us/sample - loss: 0.3160 - acc: 0.9112 - val_loss: 0.3066 - val_acc: 0.9140\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 119us/sample - loss: 0.3094 - acc: 0.9135 - val_loss: 0.3025 - val_acc: 0.9140\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.3041 - acc: 0.9141 - val_loss: 0.2998 - val_acc: 0.9134\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 135us/sample - loss: 0.2991 - acc: 0.9150 - val_loss: 0.3030 - val_acc: 0.9134\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 122us/sample - loss: 0.2946 - acc: 0.9170 - val_loss: 0.2980 - val_acc: 0.9162\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 5s 125us/sample - loss: 0.2929 - acc: 0.9171 - val_loss: 0.3075 - val_acc: 0.9152\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 122us/sample - loss: 0.2900 - acc: 0.9196 - val_loss: 0.2991 - val_acc: 0.9150\n",
      "18333/18333 [==============================] - 1s 60us/sample - loss: 0.3089 - acc: 0.9141\n",
      "[CV] ...................................... n_neurons=7, total=  59.9s\n",
      "[CV] n_neurons=8 .....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 5s 133us/sample - loss: 0.6462 - acc: 0.8184 - val_loss: 0.3675 - val_acc: 0.9018\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 5s 132us/sample - loss: 0.3559 - acc: 0.8981 - val_loss: 0.3244 - val_acc: 0.9108\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 4s 114us/sample - loss: 0.3239 - acc: 0.9071 - val_loss: 0.3077 - val_acc: 0.9142\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 4s 111us/sample - loss: 0.3084 - acc: 0.9129 - val_loss: 0.2964 - val_acc: 0.9192\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 4s 122us/sample - loss: 0.2992 - acc: 0.9149 - val_loss: 0.2923 - val_acc: 0.9204\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 5s 135us/sample - loss: 0.2923 - acc: 0.9183 - val_loss: 0.2951 - val_acc: 0.9206\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 5s 125us/sample - loss: 0.2877 - acc: 0.9195 - val_loss: 0.2890 - val_acc: 0.9210\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 4s 117us/sample - loss: 0.2820 - acc: 0.9223 - val_loss: 0.2888 - val_acc: 0.9218\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 5s 127us/sample - loss: 0.2791 - acc: 0.9225 - val_loss: 0.2876 - val_acc: 0.9234\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 5s 128us/sample - loss: 0.2754 - acc: 0.9227 - val_loss: 0.2890 - val_acc: 0.9202\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 5s 137us/sample - loss: 0.2725 - acc: 0.9239 - val_loss: 0.2904 - val_acc: 0.9206\n",
      "18334/18334 [==============================] - 1s 69us/sample - loss: 0.3252 - acc: 0.9105\n",
      "[CV] ...................................... n_neurons=8, total=  53.2s\n",
      "[CV] n_neurons=8 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 5s 136us/sample - loss: 0.7221 - acc: 0.7911 - val_loss: 0.3839 - val_acc: 0.8976\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 111us/sample - loss: 0.3559 - acc: 0.9000 - val_loss: 0.3201 - val_acc: 0.9156\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.3157 - acc: 0.9110 - val_loss: 0.2940 - val_acc: 0.9196\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 127us/sample - loss: 0.2987 - acc: 0.9163 - val_loss: 0.2831 - val_acc: 0.9212\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.2897 - acc: 0.9187 - val_loss: 0.2811 - val_acc: 0.9200\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 0.2829 - acc: 0.9218 - val_loss: 0.2784 - val_acc: 0.9236\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 126us/sample - loss: 0.2774 - acc: 0.9233 - val_loss: 0.2766 - val_acc: 0.9232\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 153us/sample - loss: 0.2730 - acc: 0.9257 - val_loss: 0.2713 - val_acc: 0.9244\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 122us/sample - loss: 0.2677 - acc: 0.9271 - val_loss: 0.2764 - val_acc: 0.9258\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 136us/sample - loss: 0.2655 - acc: 0.9287 - val_loss: 0.2743 - val_acc: 0.9254\n",
      "18333/18333 [==============================] - 1s 75us/sample - loss: 0.3140 - acc: 0.9150\n",
      "[CV] ...................................... n_neurons=8, total=  48.9s\n",
      "[CV] n_neurons=8 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 0.6890 - acc: 0.7933 - val_loss: 0.3819 - val_acc: 0.8900\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 119us/sample - loss: 0.3652 - acc: 0.8978 - val_loss: 0.3220 - val_acc: 0.9044\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 115us/sample - loss: 0.3298 - acc: 0.9081 - val_loss: 0.3071 - val_acc: 0.9120\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 135us/sample - loss: 0.3118 - acc: 0.9122 - val_loss: 0.2988 - val_acc: 0.9148\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 119us/sample - loss: 0.3004 - acc: 0.9170 - val_loss: 0.2977 - val_acc: 0.9172\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 115us/sample - loss: 0.2915 - acc: 0.9200 - val_loss: 0.2894 - val_acc: 0.9190\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 111us/sample - loss: 0.2847 - acc: 0.9210 - val_loss: 0.2885 - val_acc: 0.9174\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.2791 - acc: 0.9230 - val_loss: 0.2800 - val_acc: 0.9238\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 132us/sample - loss: 0.2745 - acc: 0.9243 - val_loss: 0.2800 - val_acc: 0.9218\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 114us/sample - loss: 0.2713 - acc: 0.9259 - val_loss: 0.2744 - val_acc: 0.9264\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 114us/sample - loss: 0.2684 - acc: 0.9258 - val_loss: 0.2779 - val_acc: 0.9232\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.2666 - acc: 0.9279 - val_loss: 0.2781 - val_acc: 0.9228\n",
      "18333/18333 [==============================] - 1s 58us/sample - loss: 0.2866 - acc: 0.9213\n",
      "[CV] ...................................... n_neurons=8, total=  54.7s\n",
      "[CV] n_neurons=9 .....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 5s 133us/sample - loss: 0.5994 - acc: 0.8341 - val_loss: 0.3525 - val_acc: 0.9020\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 4s 113us/sample - loss: 0.3404 - acc: 0.9026 - val_loss: 0.3112 - val_acc: 0.9138\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 4s 118us/sample - loss: 0.3106 - acc: 0.9113 - val_loss: 0.2955 - val_acc: 0.9172\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 5s 126us/sample - loss: 0.2977 - acc: 0.9163 - val_loss: 0.2883 - val_acc: 0.9206\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 5s 124us/sample - loss: 0.2893 - acc: 0.9190 - val_loss: 0.2867 - val_acc: 0.9188\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 4s 117us/sample - loss: 0.2828 - acc: 0.9213 - val_loss: 0.2847 - val_acc: 0.9194\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 4s 112us/sample - loss: 0.2795 - acc: 0.9223 - val_loss: 0.2887 - val_acc: 0.9210\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 4s 117us/sample - loss: 0.2755 - acc: 0.9242 - val_loss: 0.2831 - val_acc: 0.9192\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 4s 118us/sample - loss: 0.2717 - acc: 0.9245 - val_loss: 0.2805 - val_acc: 0.9242\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 5s 123us/sample - loss: 0.2696 - acc: 0.9269 - val_loss: 0.2920 - val_acc: 0.9202\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 4s 119us/sample - loss: 0.2675 - acc: 0.9260 - val_loss: 0.2867 - val_acc: 0.9228\n",
      "18334/18334 [==============================] - 1s 61us/sample - loss: 0.3156 - acc: 0.9141\n",
      "[CV] ...................................... n_neurons=9, total=  50.7s\n",
      "[CV] n_neurons=9 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 6s 167us/sample - loss: 0.6711 - acc: 0.8066 - val_loss: 0.3554 - val_acc: 0.8974\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 132us/sample - loss: 0.3442 - acc: 0.9008 - val_loss: 0.2977 - val_acc: 0.9164\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 124us/sample - loss: 0.3073 - acc: 0.9118 - val_loss: 0.2834 - val_acc: 0.9212\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 121us/sample - loss: 0.2895 - acc: 0.9195 - val_loss: 0.2724 - val_acc: 0.9238\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 131us/sample - loss: 0.2781 - acc: 0.9227 - val_loss: 0.2741 - val_acc: 0.9250\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 132us/sample - loss: 0.2701 - acc: 0.9255 - val_loss: 0.2640 - val_acc: 0.9278\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 118us/sample - loss: 0.2644 - acc: 0.9282 - val_loss: 0.2628 - val_acc: 0.9264\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 114us/sample - loss: 0.2599 - acc: 0.9286 - val_loss: 0.2621 - val_acc: 0.9282\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 118us/sample - loss: 0.2555 - acc: 0.9306 - val_loss: 0.2643 - val_acc: 0.9258\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 140us/sample - loss: 0.2529 - acc: 0.9317 - val_loss: 0.2641 - val_acc: 0.9270\n",
      "18333/18333 [==============================] - 1s 78us/sample - loss: 0.3003 - acc: 0.9192\n",
      "[CV] ...................................... n_neurons=9, total=  50.3s\n",
      "[CV] n_neurons=9 .....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 7s 180us/sample - loss: 0.6801 - acc: 0.8006 - val_loss: 0.3499 - val_acc: 0.9044\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.3454 - acc: 0.9023 - val_loss: 0.3052 - val_acc: 0.9130\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 6s 154us/sample - loss: 0.3098 - acc: 0.9133 - val_loss: 0.2819 - val_acc: 0.9204\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 149us/sample - loss: 0.2908 - acc: 0.9178 - val_loss: 0.2791 - val_acc: 0.9236\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.2797 - acc: 0.9215 - val_loss: 0.2724 - val_acc: 0.9224\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 136us/sample - loss: 0.2715 - acc: 0.9231 - val_loss: 0.2634 - val_acc: 0.9270\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.2647 - acc: 0.9260 - val_loss: 0.2646 - val_acc: 0.9240\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 137us/sample - loss: 0.2594 - acc: 0.9276 - val_loss: 0.2624 - val_acc: 0.9272\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 148us/sample - loss: 0.2542 - acc: 0.9295 - val_loss: 0.2608 - val_acc: 0.9264\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 137us/sample - loss: 0.2501 - acc: 0.9306 - val_loss: 0.2592 - val_acc: 0.9270\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 6s 153us/sample - loss: 0.2467 - acc: 0.9302 - val_loss: 0.2602 - val_acc: 0.9286\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 5s 133us/sample - loss: 0.2434 - acc: 0.9322 - val_loss: 0.2509 - val_acc: 0.9282\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 5s 130us/sample - loss: 0.2393 - acc: 0.9330 - val_loss: 0.2606 - val_acc: 0.9284\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 5s 145us/sample - loss: 0.2365 - acc: 0.9349 - val_loss: 0.2537 - val_acc: 0.9292\n",
      "18333/18333 [==============================] - 1s 75us/sample - loss: 0.2713 - acc: 0.92650s - loss: 0.2984 -\n",
      "[CV] ...................................... n_neurons=9, total= 1.3min\n",
      "[CV] n_neurons=10 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 5s 145us/sample - loss: 0.5814 - acc: 0.8408 - val_loss: 0.3187 - val_acc: 0.9092\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 4s 111us/sample - loss: 0.3121 - acc: 0.9112 - val_loss: 0.2837 - val_acc: 0.9178\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 4s 121us/sample - loss: 0.2817 - acc: 0.9187 - val_loss: 0.2553 - val_acc: 0.9290\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 4s 111us/sample - loss: 0.2659 - acc: 0.9234 - val_loss: 0.2490 - val_acc: 0.9282\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 4s 112us/sample - loss: 0.2539 - acc: 0.9272 - val_loss: 0.2481 - val_acc: 0.9302\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 5s 123us/sample - loss: 0.2459 - acc: 0.9288 - val_loss: 0.2370 - val_acc: 0.9298\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 4s 117us/sample - loss: 0.2397 - acc: 0.9324 - val_loss: 0.2337 - val_acc: 0.9308\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 4s 111us/sample - loss: 0.2333 - acc: 0.9334 - val_loss: 0.2301 - val_acc: 0.9344\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 4s 112us/sample - loss: 0.2287 - acc: 0.9359 - val_loss: 0.2397 - val_acc: 0.9314\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 5s 128us/sample - loss: 0.2251 - acc: 0.9366 - val_loss: 0.2308 - val_acc: 0.9350\n",
      "18334/18334 [==============================] - 1s 59us/sample - loss: 0.2694 - acc: 0.9254\n",
      "[CV] ..................................... n_neurons=10, total=  46.3s\n",
      "[CV] n_neurons=10 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 0.6616 - acc: 0.8139 - val_loss: 0.3502 - val_acc: 0.9010\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 126us/sample - loss: 0.3276 - acc: 0.9066 - val_loss: 0.2899 - val_acc: 0.9184\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.2873 - acc: 0.9198 - val_loss: 0.2695 - val_acc: 0.9220\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 121us/sample - loss: 0.2659 - acc: 0.9264 - val_loss: 0.2562 - val_acc: 0.9280\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.2527 - acc: 0.9304 - val_loss: 0.2511 - val_acc: 0.9282\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.2437 - acc: 0.9336 - val_loss: 0.2459 - val_acc: 0.9288\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 0.2370 - acc: 0.9353 - val_loss: 0.2419 - val_acc: 0.9356\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 150us/sample - loss: 0.2316 - acc: 0.9379 - val_loss: 0.2410 - val_acc: 0.9358\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 126us/sample - loss: 0.2270 - acc: 0.9382 - val_loss: 0.2344 - val_acc: 0.9370\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 124us/sample - loss: 0.2232 - acc: 0.9399 - val_loss: 0.2475 - val_acc: 0.9344\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 5s 130us/sample - loss: 0.2206 - acc: 0.9409 - val_loss: 0.2395 - val_acc: 0.9352\n",
      "18333/18333 [==============================] - 1s 77us/sample - loss: 0.2717 - acc: 0.9266\n",
      "[CV] ..................................... n_neurons=10, total=  57.2s\n",
      "[CV] n_neurons=10 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 6s 174us/sample - loss: 0.6710 - acc: 0.8098 - val_loss: 0.3424 - val_acc: 0.9056\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.3282 - acc: 0.9055 - val_loss: 0.2842 - val_acc: 0.9218\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 124us/sample - loss: 0.2906 - acc: 0.9172 - val_loss: 0.2703 - val_acc: 0.9232\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 0.2755 - acc: 0.9213 - val_loss: 0.2584 - val_acc: 0.9276\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 131us/sample - loss: 0.2649 - acc: 0.9247 - val_loss: 0.2579 - val_acc: 0.9272\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 142us/sample - loss: 0.2579 - acc: 0.9264 - val_loss: 0.2577 - val_acc: 0.9278\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 150us/sample - loss: 0.2520 - acc: 0.9291 - val_loss: 0.2508 - val_acc: 0.9310\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 140us/sample - loss: 0.2473 - acc: 0.9303 - val_loss: 0.2486 - val_acc: 0.9286\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.2441 - acc: 0.9300 - val_loss: 0.2553 - val_acc: 0.9310\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 6s 170us/sample - loss: 0.2400 - acc: 0.9326 - val_loss: 0.2517 - val_acc: 0.9290\n",
      "18333/18333 [==============================] - 1s 71us/sample - loss: 0.2690 - acc: 0.9264\n",
      "[CV] ..................................... n_neurons=10, total=  56.1s\n",
      "[CV] n_neurons=11 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 7s 190us/sample - loss: 0.6099 - acc: 0.8300 - val_loss: 0.3250 - val_acc: 0.9128\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 5s 130us/sample - loss: 0.3143 - acc: 0.9111 - val_loss: 0.2752 - val_acc: 0.9228\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 5s 134us/sample - loss: 0.2774 - acc: 0.9230 - val_loss: 0.2521 - val_acc: 0.9336\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 5s 124us/sample - loss: 0.2577 - acc: 0.9290 - val_loss: 0.2539 - val_acc: 0.9330\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 5s 130us/sample - loss: 0.2447 - acc: 0.9327 - val_loss: 0.2403 - val_acc: 0.9378\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 5s 123us/sample - loss: 0.2350 - acc: 0.9351 - val_loss: 0.2399 - val_acc: 0.9346\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 6s 161us/sample - loss: 0.2279 - acc: 0.9371 - val_loss: 0.2358 - val_acc: 0.9402\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 6s 156us/sample - loss: 0.2214 - acc: 0.9394 - val_loss: 0.2356 - val_acc: 0.9392\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 5s 141us/sample - loss: 0.2155 - acc: 0.9411 - val_loss: 0.2288 - val_acc: 0.9418\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 5s 138us/sample - loss: 0.2116 - acc: 0.9422 - val_loss: 0.2301 - val_acc: 0.9412\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 5s 124us/sample - loss: 0.2077 - acc: 0.9440 - val_loss: 0.2292 - val_acc: 0.9428\n",
      "18334/18334 [==============================] - 1s 68us/sample - loss: 0.2580 - acc: 0.9312\n",
      "[CV] ..................................... n_neurons=11, total= 1.0min\n",
      "[CV] n_neurons=11 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 7s 193us/sample - loss: 0.6841 - acc: 0.8094 - val_loss: 0.3600 - val_acc: 0.9054\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 155us/sample - loss: 0.3245 - acc: 0.9064 - val_loss: 0.2942 - val_acc: 0.9210\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 124us/sample - loss: 0.2763 - acc: 0.9216 - val_loss: 0.2635 - val_acc: 0.9270\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 122us/sample - loss: 0.2555 - acc: 0.9269 - val_loss: 0.2582 - val_acc: 0.9250\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 124us/sample - loss: 0.2428 - acc: 0.9309 - val_loss: 0.2398 - val_acc: 0.9348\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 125us/sample - loss: 0.2335 - acc: 0.9341 - val_loss: 0.2334 - val_acc: 0.9372\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 121us/sample - loss: 0.2270 - acc: 0.9367 - val_loss: 0.2304 - val_acc: 0.9392\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 122us/sample - loss: 0.2221 - acc: 0.9380 - val_loss: 0.2343 - val_acc: 0.9400\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 121us/sample - loss: 0.2181 - acc: 0.9395 - val_loss: 0.2305 - val_acc: 0.9382\n",
      "18333/18333 [==============================] - 1s 69us/sample - loss: 0.2540 - acc: 0.9280\n",
      "[CV] ..................................... n_neurons=11, total=  47.2s\n",
      "[CV] n_neurons=11 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.5858 - acc: 0.8325 - val_loss: 0.3151 - val_acc: 0.9090\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 122us/sample - loss: 0.3159 - acc: 0.9088 - val_loss: 0.2734 - val_acc: 0.9214\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 122us/sample - loss: 0.2828 - acc: 0.9187 - val_loss: 0.2616 - val_acc: 0.9220\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 123us/sample - loss: 0.2642 - acc: 0.9240 - val_loss: 0.2514 - val_acc: 0.9266\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 125us/sample - loss: 0.2517 - acc: 0.9280 - val_loss: 0.2424 - val_acc: 0.9324\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 122us/sample - loss: 0.2429 - acc: 0.9308 - val_loss: 0.2377 - val_acc: 0.9322\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 124us/sample - loss: 0.2365 - acc: 0.9333 - val_loss: 0.2335 - val_acc: 0.9326\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 125us/sample - loss: 0.2307 - acc: 0.9342 - val_loss: 0.2351 - val_acc: 0.9364\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 124us/sample - loss: 0.2268 - acc: 0.9353 - val_loss: 0.2429 - val_acc: 0.9312\n",
      "18333/18333 [==============================] - 1s 66us/sample - loss: 0.2623 - acc: 0.9258\n",
      "[CV] ..................................... n_neurons=11, total=  44.1s\n",
      "[CV] n_neurons=12 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 6s 155us/sample - loss: 0.5479 - acc: 0.8483 - val_loss: 0.3034 - val_acc: 0.9168\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 7s 183us/sample - loss: 0.2875 - acc: 0.9167 - val_loss: 0.2562 - val_acc: 0.9264\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 5s 132us/sample - loss: 0.2543 - acc: 0.9266 - val_loss: 0.2346 - val_acc: 0.9330\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 5s 128us/sample - loss: 0.2354 - acc: 0.9320 - val_loss: 0.2204 - val_acc: 0.9360\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 5s 129us/sample - loss: 0.2221 - acc: 0.9365 - val_loss: 0.2100 - val_acc: 0.9422\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 5s 134us/sample - loss: 0.2132 - acc: 0.9392 - val_loss: 0.2070 - val_acc: 0.9396\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 5s 127us/sample - loss: 0.2066 - acc: 0.9413 - val_loss: 0.2041 - val_acc: 0.9428\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 6s 158us/sample - loss: 0.2004 - acc: 0.9430 - val_loss: 0.2016 - val_acc: 0.9422\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 5s 144us/sample - loss: 0.1953 - acc: 0.9443 - val_loss: 0.2015 - val_acc: 0.9464\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 6s 157us/sample - loss: 0.1909 - acc: 0.9451 - val_loss: 0.2046 - val_acc: 0.9444\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 5s 148us/sample - loss: 0.1879 - acc: 0.9470 - val_loss: 0.2046 - val_acc: 0.9424\n",
      "18334/18334 [==============================] - 2s 83us/sample - loss: 0.2401 - acc: 0.9342\n",
      "[CV] ..................................... n_neurons=12, total= 1.0min\n",
      "[CV] n_neurons=12 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 6s 176us/sample - loss: 0.6161 - acc: 0.8231 - val_loss: 0.3301 - val_acc: 0.9008\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 131us/sample - loss: 0.3116 - acc: 0.9122 - val_loss: 0.2804 - val_acc: 0.9186\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 126us/sample - loss: 0.2762 - acc: 0.9232 - val_loss: 0.2595 - val_acc: 0.9232\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 131us/sample - loss: 0.2537 - acc: 0.9297 - val_loss: 0.2434 - val_acc: 0.9304\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.2369 - acc: 0.9341 - val_loss: 0.2413 - val_acc: 0.9332\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 132us/sample - loss: 0.2244 - acc: 0.9391 - val_loss: 0.2237 - val_acc: 0.9364\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 149us/sample - loss: 0.2152 - acc: 0.9407 - val_loss: 0.2194 - val_acc: 0.9416\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 148us/sample - loss: 0.2085 - acc: 0.9432 - val_loss: 0.2233 - val_acc: 0.9394\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.2020 - acc: 0.9445 - val_loss: 0.2140 - val_acc: 0.9396\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.1976 - acc: 0.9452 - val_loss: 0.2125 - val_acc: 0.9408\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 5s 136us/sample - loss: 0.1930 - acc: 0.9468 - val_loss: 0.2135 - val_acc: 0.9390\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 5s 136us/sample - loss: 0.1886 - acc: 0.9483 - val_loss: 0.2120 - val_acc: 0.9430\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 5s 145us/sample - loss: 0.1848 - acc: 0.9493 - val_loss: 0.2153 - val_acc: 0.9436\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 5s 137us/sample - loss: 0.1822 - acc: 0.9493 - val_loss: 0.2143 - val_acc: 0.9426\n",
      "18333/18333 [==============================] - 2s 86us/sample - loss: 0.2341 - acc: 0.9348\n",
      "[CV] ..................................... n_neurons=12, total= 1.3min\n",
      "[CV] n_neurons=12 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 7s 192us/sample - loss: 0.5558 - acc: 0.8457 - val_loss: 0.3128 - val_acc: 0.9118\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.3162 - acc: 0.9090 - val_loss: 0.2730 - val_acc: 0.9202\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 0.2873 - acc: 0.9186 - val_loss: 0.2617 - val_acc: 0.9258\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.2721 - acc: 0.9239 - val_loss: 0.2527 - val_acc: 0.9296\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.2604 - acc: 0.9260 - val_loss: 0.2479 - val_acc: 0.9302\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 6s 152us/sample - loss: 0.2500 - acc: 0.9299 - val_loss: 0.2461 - val_acc: 0.9324\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.2419 - acc: 0.9320 - val_loss: 0.2387 - val_acc: 0.9332\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 161us/sample - loss: 0.2356 - acc: 0.9337 - val_loss: 0.2386 - val_acc: 0.9338\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 6s 161us/sample - loss: 0.2290 - acc: 0.9356 - val_loss: 0.2445 - val_acc: 0.9358\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 6s 151us/sample - loss: 0.2228 - acc: 0.9380 - val_loss: 0.2333 - val_acc: 0.9364\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 6s 150us/sample - loss: 0.2189 - acc: 0.9392 - val_loss: 0.2357 - val_acc: 0.9356\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.2145 - acc: 0.9397 - val_loss: 0.2335 - val_acc: 0.9372\n",
      "18333/18333 [==============================] - 1s 80us/sample - loss: 0.2528 - acc: 0.9304\n",
      "[CV] ..................................... n_neurons=12, total= 1.2min\n",
      "[CV] n_neurons=13 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 7s 186us/sample - loss: 0.5522 - acc: 0.8455 - val_loss: 0.3150 - val_acc: 0.9118\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 5s 136us/sample - loss: 0.2973 - acc: 0.9147 - val_loss: 0.2679 - val_acc: 0.9254\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 5s 139us/sample - loss: 0.2614 - acc: 0.9257 - val_loss: 0.2447 - val_acc: 0.9302\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 4s 121us/sample - loss: 0.2408 - acc: 0.9311 - val_loss: 0.2344 - val_acc: 0.9320\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 5s 127us/sample - loss: 0.2281 - acc: 0.9354 - val_loss: 0.2334 - val_acc: 0.9346\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 5s 141us/sample - loss: 0.2199 - acc: 0.9377 - val_loss: 0.2331 - val_acc: 0.9324\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 5s 135us/sample - loss: 0.2128 - acc: 0.9406 - val_loss: 0.2214 - val_acc: 0.9400\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 5s 128us/sample - loss: 0.2070 - acc: 0.9431 - val_loss: 0.2201 - val_acc: 0.9368\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 5s 130us/sample - loss: 0.2012 - acc: 0.9438 - val_loss: 0.2223 - val_acc: 0.9360\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 5s 131us/sample - loss: 0.1978 - acc: 0.9447 - val_loss: 0.2213 - val_acc: 0.9406\n",
      "18334/18334 [==============================] - 1s 69us/sample - loss: 0.2488 - acc: 0.9315\n",
      "[CV] ..................................... n_neurons=13, total=  53.7s\n",
      "[CV] n_neurons=13 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 6s 160us/sample - loss: 0.5426 - acc: 0.8493 - val_loss: 0.3146 - val_acc: 0.9116\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 0.2998 - acc: 0.9153 - val_loss: 0.2730 - val_acc: 0.9230\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 131us/sample - loss: 0.2678 - acc: 0.9246 - val_loss: 0.2712 - val_acc: 0.9214\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 130us/sample - loss: 0.2493 - acc: 0.9299 - val_loss: 0.2538 - val_acc: 0.9250\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 133us/sample - loss: 0.2358 - acc: 0.9348 - val_loss: 0.2393 - val_acc: 0.9322\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 128us/sample - loss: 0.2249 - acc: 0.9375 - val_loss: 0.2362 - val_acc: 0.9334\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 133us/sample - loss: 0.2167 - acc: 0.9399 - val_loss: 0.2248 - val_acc: 0.9382\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 0.2094 - acc: 0.9420 - val_loss: 0.2250 - val_acc: 0.9390\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 137us/sample - loss: 0.2041 - acc: 0.9437 - val_loss: 0.2250 - val_acc: 0.9384\n",
      "18333/18333 [==============================] - 1s 82us/sample - loss: 0.2532 - acc: 0.9297\n",
      "[CV] ..................................... n_neurons=13, total=  48.6s\n",
      "[CV] n_neurons=13 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 6s 172us/sample - loss: 0.5759 - acc: 0.8390 - val_loss: 0.3125 - val_acc: 0.9090\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 137us/sample - loss: 0.2986 - acc: 0.9143 - val_loss: 0.2579 - val_acc: 0.9244\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 142us/sample - loss: 0.2557 - acc: 0.9264 - val_loss: 0.2337 - val_acc: 0.9308\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.2323 - acc: 0.9332 - val_loss: 0.2179 - val_acc: 0.9338\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 6s 150us/sample - loss: 0.2159 - acc: 0.9368 - val_loss: 0.2108 - val_acc: 0.9378\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 6s 174us/sample - loss: 0.2052 - acc: 0.9404 - val_loss: 0.2013 - val_acc: 0.9414\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 135us/sample - loss: 0.1976 - acc: 0.9435 - val_loss: 0.2027 - val_acc: 0.9394\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 133us/sample - loss: 0.1903 - acc: 0.9451 - val_loss: 0.1964 - val_acc: 0.9474\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 6s 158us/sample - loss: 0.1849 - acc: 0.9461 - val_loss: 0.1926 - val_acc: 0.9438\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.1811 - acc: 0.9484 - val_loss: 0.1886 - val_acc: 0.9484\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 5s 135us/sample - loss: 0.1768 - acc: 0.9494 - val_loss: 0.1925 - val_acc: 0.9490\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.1743 - acc: 0.9502 - val_loss: 0.1914 - val_acc: 0.9496\n",
      "18333/18333 [==============================] - 1s 81us/sample - loss: 0.2229 - acc: 0.9413\n",
      "[CV] ..................................... n_neurons=13, total= 1.2min\n",
      "[CV] n_neurons=14 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 7s 189us/sample - loss: 0.5242 - acc: 0.8529 - val_loss: 0.2997 - val_acc: 0.9148\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 6s 161us/sample - loss: 0.2881 - acc: 0.9167 - val_loss: 0.2620 - val_acc: 0.9258\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 6s 151us/sample - loss: 0.2530 - acc: 0.9267 - val_loss: 0.2417 - val_acc: 0.9328\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 6s 151us/sample - loss: 0.2329 - acc: 0.9330 - val_loss: 0.2307 - val_acc: 0.9366\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 5s 142us/sample - loss: 0.2200 - acc: 0.9371 - val_loss: 0.2216 - val_acc: 0.9394\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 5s 141us/sample - loss: 0.2095 - acc: 0.9402 - val_loss: 0.2152 - val_acc: 0.9414\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 5s 142us/sample - loss: 0.2021 - acc: 0.9432 - val_loss: 0.2115 - val_acc: 0.9446\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 6s 162us/sample - loss: 0.1961 - acc: 0.9454 - val_loss: 0.2191 - val_acc: 0.9408\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 6s 151us/sample - loss: 0.1902 - acc: 0.9454 - val_loss: 0.2123 - val_acc: 0.9446\n",
      "18334/18334 [==============================] - 2s 93us/sample - loss: 0.2343 - acc: 0.9356\n",
      "[CV] ..................................... n_neurons=14, total=  54.5s\n",
      "[CV] n_neurons=14 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 7s 180us/sample - loss: 0.5357 - acc: 0.8525 - val_loss: 0.2984 - val_acc: 0.9168\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 154us/sample - loss: 0.2849 - acc: 0.9190 - val_loss: 0.2529 - val_acc: 0.9290\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.2549 - acc: 0.9269 - val_loss: 0.2418 - val_acc: 0.9326\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 6s 153us/sample - loss: 0.2387 - acc: 0.9334 - val_loss: 0.2304 - val_acc: 0.9336\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 6s 150us/sample - loss: 0.2257 - acc: 0.9368 - val_loss: 0.2346 - val_acc: 0.9358\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 6s 152us/sample - loss: 0.2161 - acc: 0.9396 - val_loss: 0.2235 - val_acc: 0.9348\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 6s 163us/sample - loss: 0.2084 - acc: 0.9416 - val_loss: 0.2131 - val_acc: 0.9400\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.2029 - acc: 0.9437 - val_loss: 0.2135 - val_acc: 0.9412\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 6s 154us/sample - loss: 0.1979 - acc: 0.9451 - val_loss: 0.2137 - val_acc: 0.9430\n",
      "18333/18333 [==============================] - 1s 76us/sample - loss: 0.2473 - acc: 0.9288\n",
      "[CV] ..................................... n_neurons=14, total=  54.9s\n",
      "[CV] n_neurons=14 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.5429 - acc: 0.8471 - val_loss: 0.3023 - val_acc: 0.9148\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.2920 - acc: 0.9169 - val_loss: 0.2572 - val_acc: 0.9290\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 140us/sample - loss: 0.2593 - acc: 0.9264 - val_loss: 0.2425 - val_acc: 0.9300\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 149us/sample - loss: 0.2400 - acc: 0.9311 - val_loss: 0.2274 - val_acc: 0.9370\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 140us/sample - loss: 0.2282 - acc: 0.9349 - val_loss: 0.2258 - val_acc: 0.9372\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 136us/sample - loss: 0.2185 - acc: 0.9377 - val_loss: 0.2178 - val_acc: 0.9394\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.2099 - acc: 0.9396 - val_loss: 0.2234 - val_acc: 0.9340\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.2035 - acc: 0.9422 - val_loss: 0.2123 - val_acc: 0.9378\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 0.1981 - acc: 0.9443 - val_loss: 0.2132 - val_acc: 0.9368\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 140us/sample - loss: 0.1927 - acc: 0.9453 - val_loss: 0.2092 - val_acc: 0.9388\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 5s 145us/sample - loss: 0.1864 - acc: 0.9472 - val_loss: 0.2140 - val_acc: 0.9394\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.1828 - acc: 0.9482 - val_loss: 0.2052 - val_acc: 0.9416\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 6s 167us/sample - loss: 0.1796 - acc: 0.9494 - val_loss: 0.2078 - val_acc: 0.9418\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 5s 135us/sample - loss: 0.1751 - acc: 0.9506 - val_loss: 0.2070 - val_acc: 0.9410\n",
      "18333/18333 [==============================] - 1s 73us/sample - loss: 0.2216 - acc: 0.9375\n",
      "[CV] ..................................... n_neurons=14, total= 1.3min\n",
      "[CV] n_neurons=15 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 6s 176us/sample - loss: 0.5431 - acc: 0.8496 - val_loss: 0.3076 - val_acc: 0.9112\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 5s 136us/sample - loss: 0.2967 - acc: 0.9134 - val_loss: 0.2633 - val_acc: 0.9268\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 5s 135us/sample - loss: 0.2616 - acc: 0.9243 - val_loss: 0.2491 - val_acc: 0.9286\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 5s 134us/sample - loss: 0.2410 - acc: 0.9308 - val_loss: 0.2339 - val_acc: 0.9326\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 5s 134us/sample - loss: 0.2251 - acc: 0.9368 - val_loss: 0.2251 - val_acc: 0.9350\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 5s 133us/sample - loss: 0.2141 - acc: 0.9391 - val_loss: 0.2198 - val_acc: 0.9354\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 5s 135us/sample - loss: 0.2052 - acc: 0.9424 - val_loss: 0.2131 - val_acc: 0.9398\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 5s 136us/sample - loss: 0.1971 - acc: 0.9440 - val_loss: 0.2146 - val_acc: 0.9408\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 5s 133us/sample - loss: 0.1914 - acc: 0.9459 - val_loss: 0.2085 - val_acc: 0.9424\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 5s 134us/sample - loss: 0.1860 - acc: 0.9482 - val_loss: 0.2063 - val_acc: 0.9448\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 5s 136us/sample - loss: 0.1813 - acc: 0.9485 - val_loss: 0.2136 - val_acc: 0.9420\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 5s 137us/sample - loss: 0.1769 - acc: 0.9508 - val_loss: 0.2080 - val_acc: 0.9432\n",
      "18334/18334 [==============================] - 1s 75us/sample - loss: 0.2286 - acc: 0.93950s - loss: 0.2286 - acc: 0.9\n",
      "[CV] ..................................... n_neurons=15, total= 1.1min\n",
      "[CV] n_neurons=15 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 6s 163us/sample - loss: 0.5287 - acc: 0.8569 - val_loss: 0.2962 - val_acc: 0.9168\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.2869 - acc: 0.9189 - val_loss: 0.2601 - val_acc: 0.9242\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 136us/sample - loss: 0.2565 - acc: 0.9283 - val_loss: 0.2539 - val_acc: 0.9280\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 135us/sample - loss: 0.2398 - acc: 0.9325 - val_loss: 0.2396 - val_acc: 0.9336\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 137us/sample - loss: 0.2274 - acc: 0.9365 - val_loss: 0.2288 - val_acc: 0.9336\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 135us/sample - loss: 0.2172 - acc: 0.9404 - val_loss: 0.2438 - val_acc: 0.9336\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 135us/sample - loss: 0.2094 - acc: 0.9426 - val_loss: 0.2291 - val_acc: 0.9378\n",
      "18333/18333 [==============================] - 1s 77us/sample - loss: 0.2540 - acc: 0.9306\n",
      "[CV] ..................................... n_neurons=15, total=  39.4s\n",
      "[CV] n_neurons=15 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.5738 - acc: 0.8381 - val_loss: 0.2988 - val_acc: 0.9150\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 132us/sample - loss: 0.2937 - acc: 0.9164 - val_loss: 0.2562 - val_acc: 0.9244\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 136us/sample - loss: 0.2564 - acc: 0.9268 - val_loss: 0.2272 - val_acc: 0.9348\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 136us/sample - loss: 0.2366 - acc: 0.9342 - val_loss: 0.2156 - val_acc: 0.9388\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 136us/sample - loss: 0.2229 - acc: 0.9379 - val_loss: 0.2130 - val_acc: 0.9362\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 135us/sample - loss: 0.2129 - acc: 0.9403 - val_loss: 0.2025 - val_acc: 0.9404\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 136us/sample - loss: 0.2051 - acc: 0.9430 - val_loss: 0.2105 - val_acc: 0.9436\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 0.1983 - acc: 0.9442 - val_loss: 0.1986 - val_acc: 0.9464\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 0.1932 - acc: 0.9455 - val_loss: 0.1947 - val_acc: 0.9472\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 137us/sample - loss: 0.1885 - acc: 0.9471 - val_loss: 0.2021 - val_acc: 0.9464\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 0.1855 - acc: 0.9483 - val_loss: 0.2001 - val_acc: 0.9484\n",
      "18333/18333 [==============================] - 1s 76us/sample - loss: 0.2258 - acc: 0.9408\n",
      "[CV] ..................................... n_neurons=15, total=  59.0s\n",
      "[CV] n_neurons=16 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 6s 169us/sample - loss: 0.5130 - acc: 0.8579 - val_loss: 0.2965 - val_acc: 0.9158\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 5s 134us/sample - loss: 0.2899 - acc: 0.9170 - val_loss: 0.2608 - val_acc: 0.9212\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 5s 139us/sample - loss: 0.2586 - acc: 0.9267 - val_loss: 0.2482 - val_acc: 0.9284\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 5s 146us/sample - loss: 0.2382 - acc: 0.9315 - val_loss: 0.2307 - val_acc: 0.9362\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 5s 139us/sample - loss: 0.2220 - acc: 0.9361 - val_loss: 0.2275 - val_acc: 0.9348\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 5s 139us/sample - loss: 0.2097 - acc: 0.9410 - val_loss: 0.2172 - val_acc: 0.9368\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 5s 137us/sample - loss: 0.1997 - acc: 0.9436 - val_loss: 0.2154 - val_acc: 0.9390\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 5s 137us/sample - loss: 0.1921 - acc: 0.9452 - val_loss: 0.2079 - val_acc: 0.9402\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 5s 136us/sample - loss: 0.1841 - acc: 0.9471 - val_loss: 0.2116 - val_acc: 0.9398\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 5s 137us/sample - loss: 0.1778 - acc: 0.9495 - val_loss: 0.2030 - val_acc: 0.9408\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 5s 137us/sample - loss: 0.1712 - acc: 0.9506 - val_loss: 0.2040 - val_acc: 0.9408\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 5s 135us/sample - loss: 0.1654 - acc: 0.9532 - val_loss: 0.2011 - val_acc: 0.9434\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 5s 136us/sample - loss: 0.1614 - acc: 0.9544 - val_loss: 0.2019 - val_acc: 0.9418\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 5s 138us/sample - loss: 0.1569 - acc: 0.9554 - val_loss: 0.1976 - val_acc: 0.9452\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 5s 135us/sample - loss: 0.1529 - acc: 0.9569 - val_loss: 0.2031 - val_acc: 0.9444\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 5s 137us/sample - loss: 0.1492 - acc: 0.9576 - val_loss: 0.1990 - val_acc: 0.9452\n",
      "18334/18334 [==============================] - 1s 72us/sample - loss: 0.2283 - acc: 0.9397\n",
      "[CV] ..................................... n_neurons=16, total= 1.4min\n",
      "[CV] n_neurons=16 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 6s 166us/sample - loss: 0.5100 - acc: 0.8597 - val_loss: 0.2909 - val_acc: 0.9168\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 0.2752 - acc: 0.9230 - val_loss: 0.2452 - val_acc: 0.9314\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 137us/sample - loss: 0.2384 - acc: 0.9340 - val_loss: 0.2261 - val_acc: 0.9398\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 138us/sample - loss: 0.2172 - acc: 0.9393 - val_loss: 0.2096 - val_acc: 0.9432\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.2025 - acc: 0.9437 - val_loss: 0.2038 - val_acc: 0.9440\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.1923 - acc: 0.9463 - val_loss: 0.1996 - val_acc: 0.9458\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.1826 - acc: 0.9489 - val_loss: 0.1951 - val_acc: 0.9466\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.1744 - acc: 0.9510 - val_loss: 0.1930 - val_acc: 0.9472\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 137us/sample - loss: 0.1684 - acc: 0.9535 - val_loss: 0.2009 - val_acc: 0.9460\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 137us/sample - loss: 0.1630 - acc: 0.9544 - val_loss: 0.1959 - val_acc: 0.9462\n",
      "18333/18333 [==============================] - 1s 75us/sample - loss: 0.2250 - acc: 0.9386\n",
      "[CV] ..................................... n_neurons=16, total=  54.9s\n",
      "[CV] n_neurons=16 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 6s 174us/sample - loss: 0.5287 - acc: 0.8550 - val_loss: 0.2853 - val_acc: 0.9218\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.2855 - acc: 0.9179 - val_loss: 0.2432 - val_acc: 0.9344\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 0.2494 - acc: 0.9290 - val_loss: 0.2258 - val_acc: 0.9382\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.2252 - acc: 0.9357 - val_loss: 0.2082 - val_acc: 0.9388\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 145us/sample - loss: 0.2078 - acc: 0.9413 - val_loss: 0.2009 - val_acc: 0.9434\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.1960 - acc: 0.9453 - val_loss: 0.1941 - val_acc: 0.9448\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 145us/sample - loss: 0.1861 - acc: 0.9482 - val_loss: 0.1887 - val_acc: 0.9466\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.1780 - acc: 0.9498 - val_loss: 0.1848 - val_acc: 0.9490\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 142us/sample - loss: 0.1708 - acc: 0.9523 - val_loss: 0.1822 - val_acc: 0.9498\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 142us/sample - loss: 0.1652 - acc: 0.9541 - val_loss: 0.1870 - val_acc: 0.9474\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.1604 - acc: 0.9548 - val_loss: 0.1865 - val_acc: 0.9502\n",
      "18333/18333 [==============================] - 2s 83us/sample - loss: 0.2077 - acc: 0.9451\n",
      "[CV] ..................................... n_neurons=16, total= 1.0min\n",
      "[CV] n_neurons=17 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 6s 172us/sample - loss: 0.5052 - acc: 0.8608 - val_loss: 0.2835 - val_acc: 0.9166\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 6s 157us/sample - loss: 0.2700 - acc: 0.9228 - val_loss: 0.2343 - val_acc: 0.9350\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 5s 144us/sample - loss: 0.2320 - acc: 0.9323 - val_loss: 0.2142 - val_acc: 0.9380\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 5s 143us/sample - loss: 0.2092 - acc: 0.9397 - val_loss: 0.2066 - val_acc: 0.9402\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 6s 151us/sample - loss: 0.1954 - acc: 0.9439 - val_loss: 0.1949 - val_acc: 0.9436\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 5s 146us/sample - loss: 0.1843 - acc: 0.9468 - val_loss: 0.1917 - val_acc: 0.9462\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 5s 146us/sample - loss: 0.1755 - acc: 0.9493 - val_loss: 0.1903 - val_acc: 0.9436\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 5s 142us/sample - loss: 0.1686 - acc: 0.9524 - val_loss: 0.1851 - val_acc: 0.9476\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 5s 144us/sample - loss: 0.1634 - acc: 0.9533 - val_loss: 0.1847 - val_acc: 0.9480\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 5s 145us/sample - loss: 0.1585 - acc: 0.9555 - val_loss: 0.1803 - val_acc: 0.9508\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 6s 164us/sample - loss: 0.1530 - acc: 0.9572 - val_loss: 0.1805 - val_acc: 0.9486\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 6s 154us/sample - loss: 0.1489 - acc: 0.9589 - val_loss: 0.1891 - val_acc: 0.9494\n",
      "18334/18334 [==============================] - 1s 79us/sample - loss: 0.2143 - acc: 0.9405\n",
      "[CV] ..................................... n_neurons=17, total= 1.2min\n",
      "[CV] n_neurons=17 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 7s 194us/sample - loss: 0.5082 - acc: 0.8604 - val_loss: 0.2858 - val_acc: 0.9196\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.2739 - acc: 0.9231 - val_loss: 0.2395 - val_acc: 0.9312\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 149us/sample - loss: 0.2417 - acc: 0.9322 - val_loss: 0.2240 - val_acc: 0.9356\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.2205 - acc: 0.9386 - val_loss: 0.2134 - val_acc: 0.9396\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.2058 - acc: 0.9428 - val_loss: 0.2151 - val_acc: 0.9396\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.1957 - acc: 0.9447 - val_loss: 0.2066 - val_acc: 0.9446- ETA: 1s - loss:\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.1876 - acc: 0.9488 - val_loss: 0.1924 - val_acc: 0.9454\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 142us/sample - loss: 0.1799 - acc: 0.9503 - val_loss: 0.1895 - val_acc: 0.9462\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 131us/sample - loss: 0.1738 - acc: 0.9512 - val_loss: 0.1960 - val_acc: 0.9428\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 145us/sample - loss: 0.1687 - acc: 0.9534 - val_loss: 0.1876 - val_acc: 0.9470\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 0.1637 - acc: 0.9552 - val_loss: 0.1899 - val_acc: 0.9468\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.1603 - acc: 0.9560 - val_loss: 0.1888 - val_acc: 0.9468\n",
      "18333/18333 [==============================] - 1s 75us/sample - loss: 0.2208 - acc: 0.9403\n",
      "[CV] ..................................... n_neurons=17, total= 1.2min\n",
      "[CV] n_neurons=17 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 6s 174us/sample - loss: 0.5097 - acc: 0.8573 - val_loss: 0.2935 - val_acc: 0.9148\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 140us/sample - loss: 0.2840 - acc: 0.9180 - val_loss: 0.2472 - val_acc: 0.9310\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 0.2495 - acc: 0.9290 - val_loss: 0.2354 - val_acc: 0.9346\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 0.2318 - acc: 0.9337 - val_loss: 0.2219 - val_acc: 0.9358\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.2194 - acc: 0.9386 - val_loss: 0.2151 - val_acc: 0.9402\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 0.2095 - acc: 0.9406 - val_loss: 0.2080 - val_acc: 0.9416\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.2027 - acc: 0.9437 - val_loss: 0.2146 - val_acc: 0.9384\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.1957 - acc: 0.9445 - val_loss: 0.2074 - val_acc: 0.9414\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 0.1909 - acc: 0.9469 - val_loss: 0.2070 - val_acc: 0.9450\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.1851 - acc: 0.9491 - val_loss: 0.2038 - val_acc: 0.9424\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 0.1815 - acc: 0.9502 - val_loss: 0.2080 - val_acc: 0.9424\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.1780 - acc: 0.9515 - val_loss: 0.2039 - val_acc: 0.9430\n",
      "18333/18333 [==============================] - 1s 77us/sample - loss: 0.2253 - acc: 0.9390\n",
      "[CV] ..................................... n_neurons=17, total= 1.1min\n",
      "[CV] n_neurons=18 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 7s 180us/sample - loss: 0.5146 - acc: 0.8552 - val_loss: 0.2773 - val_acc: 0.9218\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 5s 145us/sample - loss: 0.2651 - acc: 0.9232 - val_loss: 0.2449 - val_acc: 0.9334\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 5s 146us/sample - loss: 0.2249 - acc: 0.9349 - val_loss: 0.2071 - val_acc: 0.9426\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 5s 146us/sample - loss: 0.2020 - acc: 0.9405 - val_loss: 0.1864 - val_acc: 0.9496\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 5s 145us/sample - loss: 0.1869 - acc: 0.9461 - val_loss: 0.1833 - val_acc: 0.9488\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 5s 145us/sample - loss: 0.1763 - acc: 0.9497 - val_loss: 0.1790 - val_acc: 0.9472\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 5s 144us/sample - loss: 0.1677 - acc: 0.9514 - val_loss: 0.1733 - val_acc: 0.9500\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 5s 145us/sample - loss: 0.1604 - acc: 0.9546 - val_loss: 0.1738 - val_acc: 0.9518\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 5s 148us/sample - loss: 0.1555 - acc: 0.9561 - val_loss: 0.1672 - val_acc: 0.9536\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 6s 161us/sample - loss: 0.1498 - acc: 0.9570 - val_loss: 0.1693 - val_acc: 0.9536\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 5s 127us/sample - loss: 0.1457 - acc: 0.9595 - val_loss: 0.1720 - val_acc: 0.9534\n",
      "18334/18334 [==============================] - 1s 65us/sample - loss: 0.2015 - acc: 0.9447\n",
      "[CV] ..................................... n_neurons=18, total= 1.1min\n",
      "[CV] n_neurons=18 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 6s 160us/sample - loss: 0.5065 - acc: 0.8591 - val_loss: 0.2801 - val_acc: 0.9172\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 127us/sample - loss: 0.2617 - acc: 0.9248 - val_loss: 0.2315 - val_acc: 0.9360 0.2665 - acc: 0.92 - ETA: 0s - loss: 0.266\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 127us/sample - loss: 0.2221 - acc: 0.9371 - val_loss: 0.2127 - val_acc: 0.9390\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 126us/sample - loss: 0.1991 - acc: 0.9431 - val_loss: 0.2060 - val_acc: 0.9422\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 86s 2ms/sample - loss: 0.1843 - acc: 0.9487 - val_loss: 0.1959 - val_acc: 0.9440\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 239us/sample - loss: 0.1731 - acc: 0.9518 - val_loss: 0.1951 - val_acc: 0.9446\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 8s 227us/sample - loss: 0.1649 - acc: 0.9541 - val_loss: 0.1873 - val_acc: 0.9486\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 163us/sample - loss: 0.1588 - acc: 0.9554 - val_loss: 0.1887 - val_acc: 0.9490\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 6s 169us/sample - loss: 0.1525 - acc: 0.9576 - val_loss: 0.1854 - val_acc: 0.9520\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 6s 173us/sample - loss: 0.1477 - acc: 0.9587 - val_loss: 0.1889 - val_acc: 0.9480\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 6s 163us/sample - loss: 0.1430 - acc: 0.9606 - val_loss: 0.2005 - val_acc: 0.9488\n",
      "18333/18333 [==============================] - 2s 102us/sample - loss: 0.2169 - acc: 0.9410\n",
      "[CV] ..................................... n_neurons=18, total= 2.5min\n",
      "[CV] n_neurons=18 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 7s 189us/sample - loss: 0.4760 - acc: 0.8716 - val_loss: 0.2781 - val_acc: 0.9198\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 153us/sample - loss: 0.2701 - acc: 0.9226 - val_loss: 0.2349 - val_acc: 0.9332\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 6s 165us/sample - loss: 0.2318 - acc: 0.9332 - val_loss: 0.2087 - val_acc: 0.9420\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 148us/sample - loss: 0.2084 - acc: 0.9401 - val_loss: 0.2024 - val_acc: 0.9426\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 129us/sample - loss: 0.1925 - acc: 0.9458 - val_loss: 0.1844 - val_acc: 0.9470\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 127us/sample - loss: 0.1800 - acc: 0.9491 - val_loss: 0.1837 - val_acc: 0.9462\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 118us/sample - loss: 0.1711 - acc: 0.9510 - val_loss: 0.1771 - val_acc: 0.9508\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 170us/sample - loss: 0.1632 - acc: 0.9541 - val_loss: 0.1777 - val_acc: 0.9516\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 7s 183us/sample - loss: 0.1563 - acc: 0.9559 - val_loss: 0.1802 - val_acc: 0.9510\n",
      "18333/18333 [==============================] - 2s 97us/sample - loss: 0.1970 - acc: 0.9457\n",
      "[CV] ..................................... n_neurons=18, total=  54.8s\n",
      "[CV] n_neurons=19 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 7s 192us/sample - loss: 0.4833 - acc: 0.8680 - val_loss: 0.2768 - val_acc: 0.9172\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 6s 171us/sample - loss: 0.2699 - acc: 0.9204 - val_loss: 0.2346 - val_acc: 0.9338\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 6s 174us/sample - loss: 0.2301 - acc: 0.9337 - val_loss: 0.2102 - val_acc: 0.9364\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 6s 156us/sample - loss: 0.2033 - acc: 0.9407 - val_loss: 0.1859 - val_acc: 0.9482\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 7s 185us/sample - loss: 0.1834 - acc: 0.9467 - val_loss: 0.1794 - val_acc: 0.9504\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 7s 179us/sample - loss: 0.1680 - acc: 0.9516 - val_loss: 0.1710 - val_acc: 0.9522\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 6s 171us/sample - loss: 0.1564 - acc: 0.9544 - val_loss: 0.1649 - val_acc: 0.9536\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 6s 171us/sample - loss: 0.1480 - acc: 0.9577 - val_loss: 0.1625 - val_acc: 0.9538\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 6s 168us/sample - loss: 0.1408 - acc: 0.9593 - val_loss: 0.1607 - val_acc: 0.9556\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 6s 167us/sample - loss: 0.1349 - acc: 0.9616 - val_loss: 0.1603 - val_acc: 0.9560\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 7s 181us/sample - loss: 0.1304 - acc: 0.9631 - val_loss: 0.1626 - val_acc: 0.9566\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 6s 159us/sample - loss: 0.1266 - acc: 0.9641 - val_loss: 0.1617 - val_acc: 0.9552\n",
      "18334/18334 [==============================] - 1s 81us/sample - loss: 0.1922 - acc: 0.9478\n",
      "[CV] ..................................... n_neurons=19, total= 1.3min\n",
      "[CV] n_neurons=19 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 7s 195us/sample - loss: 0.4827 - acc: 0.8694 - val_loss: 0.2772 - val_acc: 0.9216\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 155us/sample - loss: 0.2607 - acc: 0.9263 - val_loss: 0.2288 - val_acc: 0.9356\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 7s 178us/sample - loss: 0.2222 - acc: 0.9371 - val_loss: 0.2078 - val_acc: 0.9420\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 6s 169us/sample - loss: 0.2003 - acc: 0.9443 - val_loss: 0.2008 - val_acc: 0.9456\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 6s 173us/sample - loss: 0.1836 - acc: 0.9483 - val_loss: 0.1912 - val_acc: 0.9464\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 6s 162us/sample - loss: 0.1717 - acc: 0.9520 - val_loss: 0.1872 - val_acc: 0.9486\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 6s 155us/sample - loss: 0.1627 - acc: 0.9534 - val_loss: 0.1866 - val_acc: 0.9476\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 174us/sample - loss: 0.1550 - acc: 0.9570 - val_loss: 0.1864 - val_acc: 0.9470\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 6s 165us/sample - loss: 0.1485 - acc: 0.9585 - val_loss: 0.1825 - val_acc: 0.9464\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 6s 163us/sample - loss: 0.1428 - acc: 0.9598 - val_loss: 0.1830 - val_acc: 0.9498\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 6s 153us/sample - loss: 0.1385 - acc: 0.9616 - val_loss: 0.1794 - val_acc: 0.9490\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 6s 163us/sample - loss: 0.1341 - acc: 0.9632 - val_loss: 0.1804 - val_acc: 0.9524\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 7s 180us/sample - loss: 0.1306 - acc: 0.9641 - val_loss: 0.1812 - val_acc: 0.9476\n",
      "18333/18333 [==============================] - 2s 85us/sample - loss: 0.2002 - acc: 0.9479\n",
      "[CV] ..................................... n_neurons=19, total= 1.4min\n",
      "[CV] n_neurons=19 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 8s 209us/sample - loss: 0.4795 - acc: 0.8704 - val_loss: 0.2733 - val_acc: 0.9220\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 161us/sample - loss: 0.2719 - acc: 0.9202 - val_loss: 0.2420 - val_acc: 0.9306\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 6s 158us/sample - loss: 0.2390 - acc: 0.9313 - val_loss: 0.2249 - val_acc: 0.9336\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 6s 163us/sample - loss: 0.2178 - acc: 0.9371 - val_loss: 0.2133 - val_acc: 0.9428\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 6s 167us/sample - loss: 0.2010 - acc: 0.9425 - val_loss: 0.2028 - val_acc: 0.9440\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 6s 156us/sample - loss: 0.1884 - acc: 0.9459 - val_loss: 0.1984 - val_acc: 0.9460\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 6s 160us/sample - loss: 0.1792 - acc: 0.9476 - val_loss: 0.1895 - val_acc: 0.9448\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.1709 - acc: 0.9517 - val_loss: 0.1876 - val_acc: 0.9470\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.1640 - acc: 0.9531 - val_loss: 0.1877 - val_acc: 0.9482\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 6s 156us/sample - loss: 0.1584 - acc: 0.9548 - val_loss: 0.1804 - val_acc: 0.9496\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.1539 - acc: 0.9565 - val_loss: 0.1835 - val_acc: 0.9490\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 6s 162us/sample - loss: 0.1509 - acc: 0.9573 - val_loss: 0.1828 - val_acc: 0.9494\n",
      "18333/18333 [==============================] - 2s 91us/sample - loss: 0.1995 - acc: 0.9462\n",
      "[CV] ..................................... n_neurons=19, total= 1.3min\n",
      "[CV] n_neurons=20 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 8s 223us/sample - loss: 0.4859 - acc: 0.8662 - val_loss: 0.2882 - val_acc: 0.9174\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 6s 168us/sample - loss: 0.2793 - acc: 0.9206 - val_loss: 0.2497 - val_acc: 0.9304\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 6s 168us/sample - loss: 0.2419 - acc: 0.9312 - val_loss: 0.2207 - val_acc: 0.9392\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 6s 158us/sample - loss: 0.2180 - acc: 0.9383 - val_loss: 0.2128 - val_acc: 0.9398\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 6s 158us/sample - loss: 0.2006 - acc: 0.9432 - val_loss: 0.2071 - val_acc: 0.9402\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 6s 172us/sample - loss: 0.1879 - acc: 0.9478 - val_loss: 0.1996 - val_acc: 0.9468\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 6s 161us/sample - loss: 0.1769 - acc: 0.9504 - val_loss: 0.1919 - val_acc: 0.9490\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 6s 174us/sample - loss: 0.1689 - acc: 0.9530 - val_loss: 0.1864 - val_acc: 0.9498\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 6s 169us/sample - loss: 0.1616 - acc: 0.9558 - val_loss: 0.1892 - val_acc: 0.9506\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 6s 162us/sample - loss: 0.1556 - acc: 0.9576 - val_loss: 0.1890 - val_acc: 0.9494\n",
      "18334/18334 [==============================] - 2s 87us/sample - loss: 0.2097 - acc: 0.9422\n",
      "[CV] ..................................... n_neurons=20, total= 1.1min\n",
      "[CV] n_neurons=20 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 8s 227us/sample - loss: 0.4539 - acc: 0.8810 - val_loss: 0.2612 - val_acc: 0.9300\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 173us/sample - loss: 0.2459 - acc: 0.9313 - val_loss: 0.2180 - val_acc: 0.9364\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 6s 165us/sample - loss: 0.2128 - acc: 0.9392 - val_loss: 0.1989 - val_acc: 0.9454\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 6s 158us/sample - loss: 0.1936 - acc: 0.9454 - val_loss: 0.1878 - val_acc: 0.9476\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 6s 166us/sample - loss: 0.1779 - acc: 0.9488 - val_loss: 0.1824 - val_acc: 0.9474\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 6s 174us/sample - loss: 0.1658 - acc: 0.9530 - val_loss: 0.1764 - val_acc: 0.9504\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 7s 189us/sample - loss: 0.1568 - acc: 0.9556 - val_loss: 0.1704 - val_acc: 0.9536\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 174us/sample - loss: 0.1499 - acc: 0.9574 - val_loss: 0.1672 - val_acc: 0.9528\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 6s 165us/sample - loss: 0.1428 - acc: 0.9599 - val_loss: 0.1645 - val_acc: 0.9532\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 6s 169us/sample - loss: 0.1376 - acc: 0.9611 - val_loss: 0.1614 - val_acc: 0.9556\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 7s 186us/sample - loss: 0.1318 - acc: 0.9619 - val_loss: 0.1647 - val_acc: 0.9566\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 6s 176us/sample - loss: 0.1269 - acc: 0.9644 - val_loss: 0.1666 - val_acc: 0.9522\n",
      "18333/18333 [==============================] - 2s 86us/sample - loss: 0.2036 - acc: 0.9451\n",
      "[CV] ..................................... n_neurons=20, total= 1.4min\n",
      "[CV] n_neurons=20 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 7s 203us/sample - loss: 0.4806 - acc: 0.8685 - val_loss: 0.2886 - val_acc: 0.9200\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 160us/sample - loss: 0.2855 - acc: 0.9174 - val_loss: 0.2590 - val_acc: 0.9274\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 6s 168us/sample - loss: 0.2517 - acc: 0.9288 - val_loss: 0.2349 - val_acc: 0.9346\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 6s 163us/sample - loss: 0.2288 - acc: 0.9341 - val_loss: 0.2321 - val_acc: 0.9342\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 6s 168us/sample - loss: 0.2113 - acc: 0.9396 - val_loss: 0.2177 - val_acc: 0.9394\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 6s 171us/sample - loss: 0.1981 - acc: 0.9427 - val_loss: 0.2131 - val_acc: 0.9416\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 7s 193us/sample - loss: 0.1854 - acc: 0.9467 - val_loss: 0.2042 - val_acc: 0.9442\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 176us/sample - loss: 0.1755 - acc: 0.9503 - val_loss: 0.2027 - val_acc: 0.9436\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 7s 186us/sample - loss: 0.1658 - acc: 0.9522 - val_loss: 0.1910 - val_acc: 0.9478\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 7s 177us/sample - loss: 0.1590 - acc: 0.9547 - val_loss: 0.1909 - val_acc: 0.9484\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 6s 172us/sample - loss: 0.1521 - acc: 0.9572 - val_loss: 0.1922 - val_acc: 0.9492\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 6s 169us/sample - loss: 0.1467 - acc: 0.9587 - val_loss: 0.1904 - val_acc: 0.9474\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 7s 190us/sample - loss: 0.1413 - acc: 0.9604 - val_loss: 0.1872 - val_acc: 0.9500\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 7s 185us/sample - loss: 0.1372 - acc: 0.9610 - val_loss: 0.1834 - val_acc: 0.9516\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 6s 175us/sample - loss: 0.1331 - acc: 0.9624 - val_loss: 0.1943 - val_acc: 0.9482\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 7s 187us/sample - loss: 0.1300 - acc: 0.9638 - val_loss: 0.1840 - val_acc: 0.9528\n",
      "18333/18333 [==============================] - 2s 85us/sample - loss: 0.1953 - acc: 0.9500\n",
      "[CV] ..................................... n_neurons=20, total= 1.8min\n",
      "[CV] n_neurons=21 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 8s 216us/sample - loss: 0.4459 - acc: 0.8789 - val_loss: 0.2625 - val_acc: 0.9260\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 6s 173us/sample - loss: 0.2485 - acc: 0.9277 - val_loss: 0.2162 - val_acc: 0.9378\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 7s 178us/sample - loss: 0.2105 - acc: 0.9393 - val_loss: 0.2121 - val_acc: 0.9396\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 6s 169us/sample - loss: 0.1872 - acc: 0.9471 - val_loss: 0.1933 - val_acc: 0.9458\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 6s 164us/sample - loss: 0.1716 - acc: 0.9510 - val_loss: 0.1807 - val_acc: 0.9490\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 6s 165us/sample - loss: 0.1590 - acc: 0.9543 - val_loss: 0.1769 - val_acc: 0.9496\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 6s 162us/sample - loss: 0.1497 - acc: 0.9580 - val_loss: 0.1749 - val_acc: 0.9506\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 6s 173us/sample - loss: 0.1420 - acc: 0.9599 - val_loss: 0.1739 - val_acc: 0.9520\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 6s 175us/sample - loss: 0.1353 - acc: 0.9624 - val_loss: 0.1785 - val_acc: 0.9526\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 6s 175us/sample - loss: 0.1301 - acc: 0.9637 - val_loss: 0.1755 - val_acc: 0.9536\n",
      "18334/18334 [==============================] - 2s 84us/sample - loss: 0.1880 - acc: 0.9499\n",
      "[CV] ..................................... n_neurons=21, total= 1.1min\n",
      "[CV] n_neurons=21 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 7s 199us/sample - loss: 0.4686 - acc: 0.8732 - val_loss: 0.2717 - val_acc: 0.9246\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 166us/sample - loss: 0.2553 - acc: 0.9280 - val_loss: 0.2307 - val_acc: 0.9334\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 6s 177us/sample - loss: 0.2155 - acc: 0.9383 - val_loss: 0.2023 - val_acc: 0.9418\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 7s 187us/sample - loss: 0.1886 - acc: 0.9474 - val_loss: 0.1962 - val_acc: 0.9428\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 6s 168us/sample - loss: 0.1711 - acc: 0.9520 - val_loss: 0.1711 - val_acc: 0.9518\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 6s 176us/sample - loss: 0.1589 - acc: 0.9552 - val_loss: 0.1675 - val_acc: 0.9518\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 6s 165us/sample - loss: 0.1488 - acc: 0.9579 - val_loss: 0.1600 - val_acc: 0.9546\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 174us/sample - loss: 0.1409 - acc: 0.9607 - val_loss: 0.1720 - val_acc: 0.9504\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 7s 188us/sample - loss: 0.1348 - acc: 0.9626 - val_loss: 0.1557 - val_acc: 0.9560\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 6s 176us/sample - loss: 0.1291 - acc: 0.9638 - val_loss: 0.1568 - val_acc: 0.9566\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 7s 178us/sample - loss: 0.1249 - acc: 0.9653 - val_loss: 0.1588 - val_acc: 0.9592\n",
      "18333/18333 [==============================] - 2s 87us/sample - loss: 0.1887 - acc: 0.9493\n",
      "[CV] ..................................... n_neurons=21, total= 1.3min\n",
      "[CV] n_neurons=21 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 7s 203us/sample - loss: 0.4560 - acc: 0.8775 - val_loss: 0.2677 - val_acc: 0.9228\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 173us/sample - loss: 0.2616 - acc: 0.9251 - val_loss: 0.2229 - val_acc: 0.9370\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 7s 178us/sample - loss: 0.2206 - acc: 0.9368 - val_loss: 0.2028 - val_acc: 0.9436\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 7s 186us/sample - loss: 0.1952 - acc: 0.9432 - val_loss: 0.1947 - val_acc: 0.9456\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.1786 - acc: 0.9485 - val_loss: 0.1790 - val_acc: 0.9492\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 7s 184us/sample - loss: 0.1651 - acc: 0.9531 - val_loss: 0.1750 - val_acc: 0.9514\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 6s 169us/sample - loss: 0.1553 - acc: 0.9557 - val_loss: 0.1706 - val_acc: 0.9518\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 161us/sample - loss: 0.1472 - acc: 0.9580 - val_loss: 0.1658 - val_acc: 0.9542\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 6s 168us/sample - loss: 0.1391 - acc: 0.9602 - val_loss: 0.1683 - val_acc: 0.9518\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 6s 173us/sample - loss: 0.1333 - acc: 0.9627 - val_loss: 0.1625 - val_acc: 0.9566\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 6s 166us/sample - loss: 0.1283 - acc: 0.9638 - val_loss: 0.1611 - val_acc: 0.9556\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.1233 - acc: 0.9654 - val_loss: 0.1806 - val_acc: 0.9514\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 6s 162us/sample - loss: 0.1188 - acc: 0.9663 - val_loss: 0.1631 - val_acc: 0.9562\n",
      "18333/18333 [==============================] - 2s 87us/sample - loss: 0.1787 - acc: 0.9533\n",
      "[CV] ..................................... n_neurons=21, total= 1.5min\n",
      "[CV] n_neurons=22 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 8s 212us/sample - loss: 0.4526 - acc: 0.8750 - val_loss: 0.2509 - val_acc: 0.9270\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 5s 149us/sample - loss: 0.2425 - acc: 0.9295 - val_loss: 0.2061 - val_acc: 0.9418\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 6s 157us/sample - loss: 0.2069 - acc: 0.9389 - val_loss: 0.1874 - val_acc: 0.9466\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 5s 142us/sample - loss: 0.1835 - acc: 0.9457 - val_loss: 0.1789 - val_acc: 0.9486\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 6s 152us/sample - loss: 0.1676 - acc: 0.9511 - val_loss: 0.1626 - val_acc: 0.9508\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 5s 134us/sample - loss: 0.1562 - acc: 0.9541 - val_loss: 0.1622 - val_acc: 0.9534\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 5s 139us/sample - loss: 0.1467 - acc: 0.9576 - val_loss: 0.1610 - val_acc: 0.9556\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 5s 137us/sample - loss: 0.1390 - acc: 0.9594 - val_loss: 0.1624 - val_acc: 0.9512\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 5s 145us/sample - loss: 0.1330 - acc: 0.9612 - val_loss: 0.1486 - val_acc: 0.9578\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 6s 155us/sample - loss: 0.1271 - acc: 0.9633 - val_loss: 0.1569 - val_acc: 0.9538\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 5s 137us/sample - loss: 0.1229 - acc: 0.9648 - val_loss: 0.1591 - val_acc: 0.9534\n",
      "18334/18334 [==============================] - 1s 79us/sample - loss: 0.1817 - acc: 0.9507\n",
      "[CV] ..................................... n_neurons=22, total= 1.1min\n",
      "[CV] n_neurons=22 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 8s 220us/sample - loss: 0.4577 - acc: 0.8731 - val_loss: 0.2762 - val_acc: 0.9168\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 7s 183us/sample - loss: 0.2621 - acc: 0.9257 - val_loss: 0.2324 - val_acc: 0.9328\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 142us/sample - loss: 0.2276 - acc: 0.9338 - val_loss: 0.2139 - val_acc: 0.9406\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 131us/sample - loss: 0.2045 - acc: 0.9422 - val_loss: 0.2017 - val_acc: 0.9404\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 136us/sample - loss: 0.1880 - acc: 0.9471 - val_loss: 0.1956 - val_acc: 0.9450\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 6s 168us/sample - loss: 0.1750 - acc: 0.9501 - val_loss: 0.1806 - val_acc: 0.9456\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 7s 184us/sample - loss: 0.1640 - acc: 0.9532 - val_loss: 0.1880 - val_acc: 0.9438\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 7s 191us/sample - loss: 0.1564 - acc: 0.9556 - val_loss: 0.1798 - val_acc: 0.9490\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 7s 183us/sample - loss: 0.1488 - acc: 0.9587 - val_loss: 0.1724 - val_acc: 0.9524\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 7s 178us/sample - loss: 0.1432 - acc: 0.9603 - val_loss: 0.1733 - val_acc: 0.9490\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 7s 186us/sample - loss: 0.1373 - acc: 0.9617 - val_loss: 0.1717 - val_acc: 0.9506\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 6s 175us/sample - loss: 0.1319 - acc: 0.9636 - val_loss: 0.1742 - val_acc: 0.9488\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 6s 171us/sample - loss: 0.1291 - acc: 0.9644 - val_loss: 0.1686 - val_acc: 0.9540\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.1245 - acc: 0.9651 - val_loss: 0.1643 - val_acc: 0.9532\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 7s 189us/sample - loss: 0.1201 - acc: 0.9665 - val_loss: 0.1697 - val_acc: 0.9520\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 6s 170us/sample - loss: 0.1180 - acc: 0.9672 - val_loss: 0.1648 - val_acc: 0.9550\n",
      "18333/18333 [==============================] - 2s 92us/sample - loss: 0.2078 - acc: 0.9479\n",
      "[CV] ..................................... n_neurons=22, total= 1.8min\n",
      "[CV] n_neurons=22 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 8s 209us/sample - loss: 0.4588 - acc: 0.8732 - val_loss: 0.2700 - val_acc: 0.9212\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 174us/sample - loss: 0.2719 - acc: 0.9226 - val_loss: 0.2328 - val_acc: 0.9330\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.2327 - acc: 0.9323 - val_loss: 0.2077 - val_acc: 0.9398\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 131us/sample - loss: 0.2066 - acc: 0.9410 - val_loss: 0.1908 - val_acc: 0.9460\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 137us/sample - loss: 0.1860 - acc: 0.9464 - val_loss: 0.1978 - val_acc: 0.9446\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 135us/sample - loss: 0.1716 - acc: 0.9504 - val_loss: 0.1797 - val_acc: 0.9490\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 136us/sample - loss: 0.1603 - acc: 0.9534 - val_loss: 0.1742 - val_acc: 0.9504\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.1501 - acc: 0.9564 - val_loss: 0.1650 - val_acc: 0.9558\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 6s 177us/sample - loss: 0.1417 - acc: 0.9597 - val_loss: 0.1654 - val_acc: 0.9534\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.1377 - acc: 0.9605 - val_loss: 0.1577 - val_acc: 0.9562\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 7s 186us/sample - loss: 0.1308 - acc: 0.9630 - val_loss: 0.1650 - val_acc: 0.9548\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 7s 180us/sample - loss: 0.1255 - acc: 0.9647 - val_loss: 0.1653 - val_acc: 0.9552\n",
      "18333/18333 [==============================] - 2s 106us/sample - loss: 0.1942 - acc: 0.9493\n",
      "[CV] ..................................... n_neurons=22, total= 1.3min\n",
      "[CV] n_neurons=23 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 9s 235us/sample - loss: 0.4563 - acc: 0.8748 - val_loss: 0.2836 - val_acc: 0.9230\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 7s 191us/sample - loss: 0.2689 - acc: 0.9224 - val_loss: 0.2364 - val_acc: 0.9322\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 7s 188us/sample - loss: 0.2261 - acc: 0.9347 - val_loss: 0.2164 - val_acc: 0.9398\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 7s 192us/sample - loss: 0.2003 - acc: 0.9416 - val_loss: 0.1929 - val_acc: 0.9484\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 7s 194us/sample - loss: 0.1830 - acc: 0.9469 - val_loss: 0.1879 - val_acc: 0.9492\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 6s 163us/sample - loss: 0.1696 - acc: 0.9514 - val_loss: 0.1828 - val_acc: 0.9474\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 6s 152us/sample - loss: 0.1595 - acc: 0.9540 - val_loss: 0.1742 - val_acc: 0.9510\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 6s 150us/sample - loss: 0.1506 - acc: 0.9564 - val_loss: 0.1774 - val_acc: 0.9522\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 5s 136us/sample - loss: 0.1431 - acc: 0.9583 - val_loss: 0.1718 - val_acc: 0.9540\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 5s 135us/sample - loss: 0.1371 - acc: 0.9604 - val_loss: 0.1744 - val_acc: 0.9528\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 6s 158us/sample - loss: 0.1316 - acc: 0.9627 - val_loss: 0.1667 - val_acc: 0.9550\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 5s 136us/sample - loss: 0.1259 - acc: 0.9637 - val_loss: 0.1765 - val_acc: 0.9520\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 6s 153us/sample - loss: 0.1220 - acc: 0.9653 - val_loss: 0.1723 - val_acc: 0.9546\n",
      "18334/18334 [==============================] - 1s 77us/sample - loss: 0.1924 - acc: 0.9484\n",
      "[CV] ..................................... n_neurons=23, total= 1.4min\n",
      "[CV] n_neurons=23 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 7s 180us/sample - loss: 0.4401 - acc: 0.8783 - val_loss: 0.2717 - val_acc: 0.9238\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 133us/sample - loss: 0.2545 - acc: 0.9280 - val_loss: 0.2219 - val_acc: 0.9378\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.2193 - acc: 0.9385 - val_loss: 0.2054 - val_acc: 0.9432\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 6s 163us/sample - loss: 0.1965 - acc: 0.9447 - val_loss: 0.1966 - val_acc: 0.9456\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.1789 - acc: 0.9490 - val_loss: 0.1828 - val_acc: 0.9508\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.1640 - acc: 0.9534 - val_loss: 0.1798 - val_acc: 0.9472\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 6s 155us/sample - loss: 0.1529 - acc: 0.9564 - val_loss: 0.1765 - val_acc: 0.9516\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 0.1444 - acc: 0.9590 - val_loss: 0.1727 - val_acc: 0.9516\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 142us/sample - loss: 0.1364 - acc: 0.9608 - val_loss: 0.1674 - val_acc: 0.9508\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.1306 - acc: 0.9629 - val_loss: 0.1691 - val_acc: 0.9522\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 5s 140us/sample - loss: 0.1263 - acc: 0.9639 - val_loss: 0.1720 - val_acc: 0.9530\n",
      "18333/18333 [==============================] - 1s 72us/sample - loss: 0.1873 - acc: 0.9511\n",
      "[CV] ..................................... n_neurons=23, total= 1.1min\n",
      "[CV] n_neurons=23 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 7s 193us/sample - loss: 0.4804 - acc: 0.8675 - val_loss: 0.2767 - val_acc: 0.9184\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 151us/sample - loss: 0.2763 - acc: 0.9210 - val_loss: 0.2311 - val_acc: 0.9340\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 7s 178us/sample - loss: 0.2321 - acc: 0.9333 - val_loss: 0.2065 - val_acc: 0.9428\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 6s 176us/sample - loss: 0.2037 - acc: 0.9416 - val_loss: 0.1984 - val_acc: 0.9436\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 7s 188us/sample - loss: 0.1857 - acc: 0.9465 - val_loss: 0.1865 - val_acc: 0.9462\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 133us/sample - loss: 0.1719 - acc: 0.9504 - val_loss: 0.1811 - val_acc: 0.9492\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 148us/sample - loss: 0.1606 - acc: 0.9537 - val_loss: 0.1755 - val_acc: 0.9504\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.1509 - acc: 0.9570 - val_loss: 0.1792 - val_acc: 0.9506\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 6s 154us/sample - loss: 0.1440 - acc: 0.9588 - val_loss: 0.1734 - val_acc: 0.9506\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 136us/sample - loss: 0.1366 - acc: 0.9605 - val_loss: 0.1717 - val_acc: 0.9514\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 0.1313 - acc: 0.9629 - val_loss: 0.1786 - val_acc: 0.9512\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 0.1274 - acc: 0.9636 - val_loss: 0.1730 - val_acc: 0.9514\n",
      "18333/18333 [==============================] - 1s 74us/sample - loss: 0.1848 - acc: 0.95010s - loss:\n",
      "[CV] ..................................... n_neurons=23, total= 1.2min\n",
      "[CV] n_neurons=24 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 8s 208us/sample - loss: 0.4534 - acc: 0.8731 - val_loss: 0.2685 - val_acc: 0.9276\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 5s 129us/sample - loss: 0.2601 - acc: 0.9252 - val_loss: 0.2265 - val_acc: 0.9370\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 6s 162us/sample - loss: 0.2216 - acc: 0.9356 - val_loss: 0.2097 - val_acc: 0.9388\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 5s 143us/sample - loss: 0.1956 - acc: 0.9428 - val_loss: 0.1899 - val_acc: 0.9422\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 5s 137us/sample - loss: 0.1773 - acc: 0.9491 - val_loss: 0.1899 - val_acc: 0.9444\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 5s 134us/sample - loss: 0.1617 - acc: 0.9535 - val_loss: 0.1826 - val_acc: 0.9470\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 5s 142us/sample - loss: 0.1484 - acc: 0.9577 - val_loss: 0.1737 - val_acc: 0.9484\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 5s 140us/sample - loss: 0.1390 - acc: 0.9603 - val_loss: 0.1643 - val_acc: 0.9546\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 6s 156us/sample - loss: 0.1313 - acc: 0.9626 - val_loss: 0.1632 - val_acc: 0.9534\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 6s 153us/sample - loss: 0.1248 - acc: 0.9642 - val_loss: 0.1606 - val_acc: 0.9552\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 6s 165us/sample - loss: 0.1193 - acc: 0.9660 - val_loss: 0.1583 - val_acc: 0.9552\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 10s 263us/sample - loss: 0.1150 - acc: 0.9675 - val_loss: 0.1642 - val_acc: 0.9562\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 6s 152us/sample - loss: 0.1104 - acc: 0.9695 - val_loss: 0.1568 - val_acc: 0.9562\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 5s 142us/sample - loss: 0.1062 - acc: 0.9702 - val_loss: 0.1606 - val_acc: 0.9572\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 5s 133us/sample - loss: 0.1032 - acc: 0.9710 - val_loss: 0.1582 - val_acc: 0.9572\n",
      "18334/18334 [==============================] - 1s 72us/sample - loss: 0.1877 - acc: 0.9531\n",
      "[CV] ..................................... n_neurons=24, total= 1.5min\n",
      "[CV] n_neurons=24 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 7s 194us/sample - loss: 0.4565 - acc: 0.8755 - val_loss: 0.2715 - val_acc: 0.9282\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 151us/sample - loss: 0.2606 - acc: 0.9253 - val_loss: 0.2303 - val_acc: 0.9348\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 148us/sample - loss: 0.2207 - acc: 0.9376 - val_loss: 0.2038 - val_acc: 0.9430\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 135us/sample - loss: 0.1938 - acc: 0.9456 - val_loss: 0.1885 - val_acc: 0.9488\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 137us/sample - loss: 0.1720 - acc: 0.9510 - val_loss: 0.1818 - val_acc: 0.9482\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 138us/sample - loss: 0.1582 - acc: 0.9554 - val_loss: 0.1677 - val_acc: 0.9530\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 145us/sample - loss: 0.1459 - acc: 0.9584 - val_loss: 0.1660 - val_acc: 0.9542\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 142us/sample - loss: 0.1359 - acc: 0.9620 - val_loss: 0.1586 - val_acc: 0.9542\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 149us/sample - loss: 0.1277 - acc: 0.9647 - val_loss: 0.1528 - val_acc: 0.9578\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.1226 - acc: 0.9653 - val_loss: 0.1534 - val_acc: 0.9590\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.1161 - acc: 0.9676 - val_loss: 0.1562 - val_acc: 0.9598\n",
      "18333/18333 [==============================] - 1s 72us/sample - loss: 0.1857 - acc: 0.9503\n",
      "[CV] ..................................... n_neurons=24, total= 1.1min\n",
      "[CV] n_neurons=24 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 7s 195us/sample - loss: 0.4761 - acc: 0.8688 - val_loss: 0.2762 - val_acc: 0.9206\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 150us/sample - loss: 0.2766 - acc: 0.9204 - val_loss: 0.2570 - val_acc: 0.9292\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 6s 166us/sample - loss: 0.2386 - acc: 0.9299 - val_loss: 0.2233 - val_acc: 0.9358\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 7s 191us/sample - loss: 0.2113 - acc: 0.9391 - val_loss: 0.2079 - val_acc: 0.9408\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 7s 190us/sample - loss: 0.1896 - acc: 0.9456 - val_loss: 0.1949 - val_acc: 0.9432\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 213us/sample - loss: 0.1707 - acc: 0.9507 - val_loss: 0.1833 - val_acc: 0.9488\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 7s 194us/sample - loss: 0.1566 - acc: 0.9550 - val_loss: 0.1793 - val_acc: 0.9510\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 7s 199us/sample - loss: 0.1460 - acc: 0.9581 - val_loss: 0.1709 - val_acc: 0.9520\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 7s 182us/sample - loss: 0.1387 - acc: 0.9605 - val_loss: 0.1718 - val_acc: 0.9538\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 7s 196us/sample - loss: 0.1309 - acc: 0.9631 - val_loss: 0.1800 - val_acc: 0.9496\n",
      "18333/18333 [==============================] - 2s 106us/sample - loss: 0.1936 - acc: 0.9454\n",
      "[CV] ..................................... n_neurons=24, total= 1.2min\n",
      "[CV] n_neurons=25 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 9s 232us/sample - loss: 0.4422 - acc: 0.8787 - val_loss: 0.2810 - val_acc: 0.9232\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 7s 195us/sample - loss: 0.2695 - acc: 0.9225 - val_loss: 0.2376 - val_acc: 0.9350\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 7s 185us/sample - loss: 0.2288 - acc: 0.9353 - val_loss: 0.2272 - val_acc: 0.9394\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 8s 216us/sample - loss: 0.2029 - acc: 0.9412 - val_loss: 0.2064 - val_acc: 0.9436\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 8s 208us/sample - loss: 0.1823 - acc: 0.9477 - val_loss: 0.1917 - val_acc: 0.9470\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 7s 184us/sample - loss: 0.1662 - acc: 0.9533 - val_loss: 0.1831 - val_acc: 0.9504\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 7s 187us/sample - loss: 0.1549 - acc: 0.9563 - val_loss: 0.1771 - val_acc: 0.9522\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 7s 183us/sample - loss: 0.1452 - acc: 0.9576 - val_loss: 0.1736 - val_acc: 0.9526\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 7s 189us/sample - loss: 0.1365 - acc: 0.9615 - val_loss: 0.1789 - val_acc: 0.9506\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 7s 194us/sample - loss: 0.1314 - acc: 0.9644 - val_loss: 0.1823 - val_acc: 0.9512\n",
      "18334/18334 [==============================] - 2s 101us/sample - loss: 0.2038 - acc: 0.9458\n",
      "[CV] ..................................... n_neurons=25, total= 1.3min\n",
      "[CV] n_neurons=25 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 9s 242us/sample - loss: 0.4199 - acc: 0.8866 - val_loss: 0.2515 - val_acc: 0.9298\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 166us/sample - loss: 0.2414 - acc: 0.9321 - val_loss: 0.2071 - val_acc: 0.9416\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 7s 200us/sample - loss: 0.2031 - acc: 0.9416 - val_loss: 0.1858 - val_acc: 0.9470\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 7s 197us/sample - loss: 0.1788 - acc: 0.9487 - val_loss: 0.1775 - val_acc: 0.9522\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 149us/sample - loss: 0.1630 - acc: 0.9537 - val_loss: 0.1750 - val_acc: 0.9518\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.1508 - acc: 0.9573 - val_loss: 0.1668 - val_acc: 0.9532\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 7s 200us/sample - loss: 0.1405 - acc: 0.9599 - val_loss: 0.1696 - val_acc: 0.9518\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 7s 194us/sample - loss: 0.1329 - acc: 0.9614 - val_loss: 0.1661 - val_acc: 0.9532\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 8s 207us/sample - loss: 0.1266 - acc: 0.9638 - val_loss: 0.1650 - val_acc: 0.9528\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 7s 193us/sample - loss: 0.1214 - acc: 0.9658 - val_loss: 0.1712 - val_acc: 0.9532\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 7s 200us/sample - loss: 0.1162 - acc: 0.9672 - val_loss: 0.1673 - val_acc: 0.9558\n",
      "18333/18333 [==============================] - 2s 104us/sample - loss: 0.1810 - acc: 0.9516\n",
      "[CV] ..................................... n_neurons=25, total= 1.4min\n",
      "[CV] n_neurons=25 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 9s 235us/sample - loss: 0.4591 - acc: 0.8739 - val_loss: 0.2701 - val_acc: 0.9244\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 7s 185us/sample - loss: 0.2600 - acc: 0.9257 - val_loss: 0.2282 - val_acc: 0.9360\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 7s 185us/sample - loss: 0.2191 - acc: 0.9384 - val_loss: 0.2047 - val_acc: 0.9444\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 8s 215us/sample - loss: 0.1934 - acc: 0.9443 - val_loss: 0.1834 - val_acc: 0.9472\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 8s 213us/sample - loss: 0.1723 - acc: 0.9508 - val_loss: 0.1788 - val_acc: 0.9502\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 228us/sample - loss: 0.1571 - acc: 0.9558 - val_loss: 0.1807 - val_acc: 0.9512\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 9s 250us/sample - loss: 0.1470 - acc: 0.9591 - val_loss: 0.1644 - val_acc: 0.9540\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 10s 265us/sample - loss: 0.1374 - acc: 0.9612 - val_loss: 0.1605 - val_acc: 0.9572\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 10s 259us/sample - loss: 0.1311 - acc: 0.9629 - val_loss: 0.1694 - val_acc: 0.9564\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 9s 256us/sample - loss: 0.1233 - acc: 0.9649 - val_loss: 0.1527 - val_acc: 0.9588\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 9s 247us/sample - loss: 0.1188 - acc: 0.9663 - val_loss: 0.1645 - val_acc: 0.9554\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 9s 237us/sample - loss: 0.1133 - acc: 0.9681 - val_loss: 0.1616 - val_acc: 0.9576\n",
      "18333/18333 [==============================] - 2s 125us/sample - loss: 0.1778 - acc: 0.9533\n",
      "[CV] ..................................... n_neurons=25, total= 1.8min\n",
      "[CV] n_neurons=26 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 11s 305us/sample - loss: 0.4266 - acc: 0.8873 - val_loss: 0.2536 - val_acc: 0.9278\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 9s 234us/sample - loss: 0.2408 - acc: 0.9304 - val_loss: 0.2079 - val_acc: 0.9406\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 9s 244us/sample - loss: 0.2015 - acc: 0.9417 - val_loss: 0.1923 - val_acc: 0.9436\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 7s 185us/sample - loss: 0.1786 - acc: 0.9481 - val_loss: 0.1850 - val_acc: 0.9444\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 14s 382us/sample - loss: 0.1632 - acc: 0.9531 - val_loss: 0.1734 - val_acc: 0.9484\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 6s 162us/sample - loss: 0.1511 - acc: 0.9561 - val_loss: 0.1671 - val_acc: 0.9526\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 6s 165us/sample - loss: 0.1427 - acc: 0.9597 - val_loss: 0.1628 - val_acc: 0.9532\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 8s 212us/sample - loss: 0.1331 - acc: 0.9626 - val_loss: 0.1645 - val_acc: 0.9528\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 6s 168us/sample - loss: 0.1263 - acc: 0.9636 - val_loss: 0.1617 - val_acc: 0.9508\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 6s 165us/sample - loss: 0.1206 - acc: 0.9653 - val_loss: 0.1611 - val_acc: 0.9534\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 6s 156us/sample - loss: 0.1154 - acc: 0.9674 - val_loss: 0.1595 - val_acc: 0.9534\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 6s 165us/sample - loss: 0.1111 - acc: 0.9687 - val_loss: 0.1575 - val_acc: 0.9540\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 6s 154us/sample - loss: 0.1070 - acc: 0.9695 - val_loss: 0.1639 - val_acc: 0.9556\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 6s 156us/sample - loss: 0.1030 - acc: 0.9707 - val_loss: 0.1681 - val_acc: 0.9530\n",
      "18334/18334 [==============================] - 2s 103us/sample - loss: 0.1864 - acc: 0.9482\n",
      "[CV] ..................................... n_neurons=26, total= 1.8min\n",
      "[CV] n_neurons=26 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 7s 203us/sample - loss: 0.4481 - acc: 0.8766 - val_loss: 0.2565 - val_acc: 0.9272\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 151us/sample - loss: 0.2536 - acc: 0.9282 - val_loss: 0.2242 - val_acc: 0.9374\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 7s 185us/sample - loss: 0.2163 - acc: 0.9396 - val_loss: 0.1967 - val_acc: 0.9434\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 6s 168us/sample - loss: 0.1899 - acc: 0.9462 - val_loss: 0.1803 - val_acc: 0.9500\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.1703 - acc: 0.9525 - val_loss: 0.1710 - val_acc: 0.9520\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 6s 152us/sample - loss: 0.1557 - acc: 0.9559 - val_loss: 0.1623 - val_acc: 0.9542\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.1438 - acc: 0.9597 - val_loss: 0.1632 - val_acc: 0.9552\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.1352 - acc: 0.9617 - val_loss: 0.1525 - val_acc: 0.9580\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 6s 154us/sample - loss: 0.1263 - acc: 0.9644 - val_loss: 0.1481 - val_acc: 0.9598\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 6s 161us/sample - loss: 0.1195 - acc: 0.9664 - val_loss: 0.1507 - val_acc: 0.9566\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 6s 162us/sample - loss: 0.1147 - acc: 0.9684 - val_loss: 0.1451 - val_acc: 0.9616\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 7s 179us/sample - loss: 0.1078 - acc: 0.9692 - val_loss: 0.1448 - val_acc: 0.9608\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 6s 176us/sample - loss: 0.1039 - acc: 0.9701 - val_loss: 0.1460 - val_acc: 0.9596\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 6s 173us/sample - loss: 0.0999 - acc: 0.9716 - val_loss: 0.1405 - val_acc: 0.9620\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 6s 165us/sample - loss: 0.0962 - acc: 0.9729 - val_loss: 0.1492 - val_acc: 0.9594\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 6s 170us/sample - loss: 0.0927 - acc: 0.9736 - val_loss: 0.1383 - val_acc: 0.9626\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 8s 207us/sample - loss: 0.0894 - acc: 0.9758 - val_loss: 0.1522 - val_acc: 0.9586\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.0859 - acc: 0.9753 - val_loss: 0.1449 - val_acc: 0.9600\n",
      "18333/18333 [==============================] - 2s 96us/sample - loss: 0.1883 - acc: 0.9529\n",
      "[CV] ..................................... n_neurons=26, total= 1.9min\n",
      "[CV] n_neurons=26 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 8s 205us/sample - loss: 0.4544 - acc: 0.8755 - val_loss: 0.2617 - val_acc: 0.9250\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 211us/sample - loss: 0.2508 - acc: 0.9284 - val_loss: 0.2237 - val_acc: 0.9374\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 268us/sample - loss: 0.2097 - acc: 0.9404 - val_loss: 0.1949 - val_acc: 0.9460\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 284us/sample - loss: 0.1853 - acc: 0.9479 - val_loss: 0.1779 - val_acc: 0.9502\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 6s 173us/sample - loss: 0.1678 - acc: 0.9524 - val_loss: 0.1735 - val_acc: 0.9518\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.1547 - acc: 0.9565 - val_loss: 0.1621 - val_acc: 0.9552\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 6s 155us/sample - loss: 0.1437 - acc: 0.9600 - val_loss: 0.1628 - val_acc: 0.9556\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 150us/sample - loss: 0.1350 - acc: 0.9624 - val_loss: 0.1563 - val_acc: 0.9586\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.1283 - acc: 0.9643 - val_loss: 0.1564 - val_acc: 0.9574\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 6s 156us/sample - loss: 0.1222 - acc: 0.9653 - val_loss: 0.1606 - val_acc: 0.9554\n",
      "18333/18333 [==============================] - 2s 90us/sample - loss: 0.1796 - acc: 0.9504\n",
      "[CV] ..................................... n_neurons=26, total= 1.2min\n",
      "[CV] n_neurons=27 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 11s 301us/sample - loss: 0.4210 - acc: 0.8835 - val_loss: 0.2504 - val_acc: 0.9306\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 10s 279us/sample - loss: 0.2455 - acc: 0.9289 - val_loss: 0.2144 - val_acc: 0.9394\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 10s 280us/sample - loss: 0.2092 - acc: 0.9392 - val_loss: 0.1977 - val_acc: 0.9448\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 9s 257us/sample - loss: 0.1855 - acc: 0.9462 - val_loss: 0.1792 - val_acc: 0.9484\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 10s 277us/sample - loss: 0.1676 - acc: 0.9515 - val_loss: 0.1708 - val_acc: 0.9504\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 9s 257us/sample - loss: 0.1540 - acc: 0.9555 - val_loss: 0.1598 - val_acc: 0.9558\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 10s 270us/sample - loss: 0.1426 - acc: 0.9584 - val_loss: 0.1659 - val_acc: 0.9538\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 9s 255us/sample - loss: 0.1338 - acc: 0.9622 - val_loss: 0.1492 - val_acc: 0.9574\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 9s 243us/sample - loss: 0.1258 - acc: 0.9637 - val_loss: 0.1583 - val_acc: 0.9572\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 9s 237us/sample - loss: 0.1185 - acc: 0.9657 - val_loss: 0.1569 - val_acc: 0.9550\n",
      "18334/18334 [==============================] - 1s 77us/sample - loss: 0.1827 - acc: 0.9481\n",
      "[CV] ..................................... n_neurons=27, total= 1.7min\n",
      "[CV] n_neurons=27 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 9s 243us/sample - loss: 0.4464 - acc: 0.8771 - val_loss: 0.2609 - val_acc: 0.9260\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 158us/sample - loss: 0.2352 - acc: 0.9332 - val_loss: 0.2413 - val_acc: 0.9298\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.1958 - acc: 0.9447 - val_loss: 0.1896 - val_acc: 0.9472\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 6s 168us/sample - loss: 0.1725 - acc: 0.9507 - val_loss: 0.1877 - val_acc: 0.9486\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 6s 161us/sample - loss: 0.1577 - acc: 0.9551 - val_loss: 0.1796 - val_acc: 0.9460\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 6s 176us/sample - loss: 0.1448 - acc: 0.9595 - val_loss: 0.1700 - val_acc: 0.9520\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 6s 152us/sample - loss: 0.1349 - acc: 0.9621 - val_loss: 0.1612 - val_acc: 0.9548\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 153us/sample - loss: 0.1265 - acc: 0.9641 - val_loss: 0.1659 - val_acc: 0.9540\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 6s 167us/sample - loss: 0.1204 - acc: 0.9664 - val_loss: 0.1720 - val_acc: 0.9550\n",
      "18333/18333 [==============================] - 1s 81us/sample - loss: 0.1869 - acc: 0.9480\n",
      "[CV] ..................................... n_neurons=27, total= 1.0min\n",
      "[CV] n_neurons=27 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 8s 222us/sample - loss: 0.4493 - acc: 0.8766 - val_loss: 0.2732 - val_acc: 0.9218\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 6s 173us/sample - loss: 0.2543 - acc: 0.9259 - val_loss: 0.2150 - val_acc: 0.9410\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 6s 155us/sample - loss: 0.2083 - acc: 0.9399 - val_loss: 0.1909 - val_acc: 0.9466\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 148us/sample - loss: 0.1818 - acc: 0.9475 - val_loss: 0.1743 - val_acc: 0.9528\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 6s 163us/sample - loss: 0.1631 - acc: 0.9524 - val_loss: 0.1657 - val_acc: 0.9554\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.1495 - acc: 0.9574 - val_loss: 0.1642 - val_acc: 0.9544\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 6s 175us/sample - loss: 0.1383 - acc: 0.9603 - val_loss: 0.1586 - val_acc: 0.9572\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 6s 151us/sample - loss: 0.1295 - acc: 0.9631 - val_loss: 0.1617 - val_acc: 0.9550\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 150us/sample - loss: 0.1228 - acc: 0.9642 - val_loss: 0.1514 - val_acc: 0.9578\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.1169 - acc: 0.9665 - val_loss: 0.1560 - val_acc: 0.9592\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 5s 149us/sample - loss: 0.1119 - acc: 0.9675 - val_loss: 0.1505 - val_acc: 0.9592\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 6s 167us/sample - loss: 0.1072 - acc: 0.9693 - val_loss: 0.1551 - val_acc: 0.9588\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 8s 210us/sample - loss: 0.1026 - acc: 0.9707 - val_loss: 0.1531 - val_acc: 0.9580\n",
      "18333/18333 [==============================] - 3s 170us/sample - loss: 0.1757 - acc: 0.9541\n",
      "[CV] ..................................... n_neurons=27, total= 1.4min\n",
      "[CV] n_neurons=28 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 13s 347us/sample - loss: 0.4460 - acc: 0.8770 - val_loss: 0.2492 - val_acc: 0.9310\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 10s 275us/sample - loss: 0.2351 - acc: 0.9327 - val_loss: 0.2087 - val_acc: 0.9424\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 6s 159us/sample - loss: 0.1957 - acc: 0.9445 - val_loss: 0.1887 - val_acc: 0.9472\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 8s 206us/sample - loss: 0.1727 - acc: 0.9504 - val_loss: 0.1729 - val_acc: 0.9498\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 10s 272us/sample - loss: 0.1546 - acc: 0.9553 - val_loss: 0.1710 - val_acc: 0.9520\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 10s 285us/sample - loss: 0.1418 - acc: 0.9588 - val_loss: 0.1593 - val_acc: 0.9554\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 9s 249us/sample - loss: 0.1307 - acc: 0.9621 - val_loss: 0.1490 - val_acc: 0.9580\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 10s 261us/sample - loss: 0.1221 - acc: 0.9650 - val_loss: 0.1529 - val_acc: 0.9554\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 10s 282us/sample - loss: 0.1158 - acc: 0.9672 - val_loss: 0.1494 - val_acc: 0.9586\n",
      "18334/18334 [==============================] - 3s 150us/sample - loss: 0.1699 - acc: 0.9525\n",
      "[CV] ..................................... n_neurons=28, total= 1.5min\n",
      "[CV] n_neurons=28 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 12s 334us/sample - loss: 0.4455 - acc: 0.8779 - val_loss: 0.2712 - val_acc: 0.9200\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 10s 262us/sample - loss: 0.2616 - acc: 0.9252 - val_loss: 0.2281 - val_acc: 0.9356\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 260us/sample - loss: 0.2197 - acc: 0.9368 - val_loss: 0.1943 - val_acc: 0.9446\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 265us/sample - loss: 0.1889 - acc: 0.9458 - val_loss: 0.1805 - val_acc: 0.9484\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 272us/sample - loss: 0.1683 - acc: 0.9518 - val_loss: 0.1637 - val_acc: 0.9526\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 255us/sample - loss: 0.1517 - acc: 0.9563 - val_loss: 0.1598 - val_acc: 0.9536\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 10s 277us/sample - loss: 0.1396 - acc: 0.9597 - val_loss: 0.1489 - val_acc: 0.9576\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 10s 285us/sample - loss: 0.1296 - acc: 0.9632 - val_loss: 0.1512 - val_acc: 0.9558\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 10s 267us/sample - loss: 0.1221 - acc: 0.9641 - val_loss: 0.1477 - val_acc: 0.9558\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 10s 260us/sample - loss: 0.1150 - acc: 0.9663 - val_loss: 0.1487 - val_acc: 0.9576\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 10s 263us/sample - loss: 0.1111 - acc: 0.9678 - val_loss: 0.1509 - val_acc: 0.9570\n",
      "18333/18333 [==============================] - 2s 127us/sample - loss: 0.1807 - acc: 0.9501\n",
      "[CV] ..................................... n_neurons=28, total= 1.9min\n",
      "[CV] n_neurons=28 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.4614 - acc: 0.8726 - val_loss: 0.2738 - val_acc: 0.9220\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 7s 180us/sample - loss: 0.2501 - acc: 0.9281 - val_loss: 0.2184 - val_acc: 0.9390\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 6s 150us/sample - loss: 0.2044 - acc: 0.9421 - val_loss: 0.1805 - val_acc: 0.9492\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 6s 160us/sample - loss: 0.1778 - acc: 0.9493 - val_loss: 0.1728 - val_acc: 0.9530\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 8s 230us/sample - loss: 0.1591 - acc: 0.9546 - val_loss: 0.1657 - val_acc: 0.9522\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 260us/sample - loss: 0.1459 - acc: 0.9591 - val_loss: 0.1548 - val_acc: 0.9570\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.1356 - acc: 0.9616 - val_loss: 0.1559 - val_acc: 0.9566\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 7s 197us/sample - loss: 0.1276 - acc: 0.9649 - val_loss: 0.1475 - val_acc: 0.9590\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 7s 201us/sample - loss: 0.1192 - acc: 0.9678 - val_loss: 0.1503 - val_acc: 0.9588\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 6s 158us/sample - loss: 0.1136 - acc: 0.9686 - val_loss: 0.1504 - val_acc: 0.9598\n",
      "18333/18333 [==============================] - 2s 100us/sample - loss: 0.1674 - acc: 0.9548\n",
      "[CV] ..................................... n_neurons=28, total= 1.3min\n",
      "[CV] n_neurons=29 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 8s 218us/sample - loss: 0.4234 - acc: 0.8826 - val_loss: 0.2574 - val_acc: 0.9282\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 6s 162us/sample - loss: 0.2346 - acc: 0.9320 - val_loss: 0.2065 - val_acc: 0.9430\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 10s 267us/sample - loss: 0.1994 - acc: 0.9428 - val_loss: 0.1833 - val_acc: 0.9482\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 10s 261us/sample - loss: 0.1763 - acc: 0.9494 - val_loss: 0.1667 - val_acc: 0.9516\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 10s 286us/sample - loss: 0.1585 - acc: 0.9546 - val_loss: 0.1644 - val_acc: 0.9526\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 10s 277us/sample - loss: 0.1454 - acc: 0.9588 - val_loss: 0.1644 - val_acc: 0.9552\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 9s 246us/sample - loss: 0.1352 - acc: 0.9613 - val_loss: 0.1641 - val_acc: 0.9534\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 10s 260us/sample - loss: 0.1258 - acc: 0.9649 - val_loss: 0.1597 - val_acc: 0.9550\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 10s 272us/sample - loss: 0.1184 - acc: 0.9661 - val_loss: 0.1557 - val_acc: 0.9564\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 11s 291us/sample - loss: 0.1121 - acc: 0.9687 - val_loss: 0.1674 - val_acc: 0.9522\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 6s 164us/sample - loss: 0.1071 - acc: 0.9701 - val_loss: 0.1594 - val_acc: 0.9578\n",
      "18334/18334 [==============================] - 1s 76us/sample - loss: 0.1717 - acc: 0.9561\n",
      "[CV] ..................................... n_neurons=29, total= 1.7min\n",
      "[CV] n_neurons=29 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 10s 262us/sample - loss: 0.4252 - acc: 0.8848 - val_loss: 0.2599 - val_acc: 0.9232\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 258us/sample - loss: 0.2367 - acc: 0.9320 - val_loss: 0.2030 - val_acc: 0.9456\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.1961 - acc: 0.9440 - val_loss: 0.1857 - val_acc: 0.9468\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 268us/sample - loss: 0.1715 - acc: 0.9522 - val_loss: 0.1704 - val_acc: 0.9528\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 9s 254us/sample - loss: 0.1529 - acc: 0.9567 - val_loss: 0.1623 - val_acc: 0.9528\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 275us/sample - loss: 0.1404 - acc: 0.9600 - val_loss: 0.1521 - val_acc: 0.9568\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 10s 271us/sample - loss: 0.1298 - acc: 0.9625 - val_loss: 0.1477 - val_acc: 0.9564\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 9s 255us/sample - loss: 0.1215 - acc: 0.9654 - val_loss: 0.1463 - val_acc: 0.9584\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 10s 283us/sample - loss: 0.1158 - acc: 0.9671 - val_loss: 0.1502 - val_acc: 0.9564\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 10s 260us/sample - loss: 0.1083 - acc: 0.9687 - val_loss: 0.1547 - val_acc: 0.9576\n",
      "18333/18333 [==============================] - 2s 133us/sample - loss: 0.1779 - acc: 0.9528\n",
      "[CV] ..................................... n_neurons=29, total= 1.7min\n",
      "[CV] n_neurons=29 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 12s 318us/sample - loss: 0.4292 - acc: 0.8818 - val_loss: 0.2354 - val_acc: 0.9322\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 10s 278us/sample - loss: 0.2324 - acc: 0.9336 - val_loss: 0.2024 - val_acc: 0.9422\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 264us/sample - loss: 0.1954 - acc: 0.9445 - val_loss: 0.1823 - val_acc: 0.9486\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 270us/sample - loss: 0.1720 - acc: 0.9509 - val_loss: 0.1642 - val_acc: 0.9528\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 275us/sample - loss: 0.1561 - acc: 0.9551 - val_loss: 0.1598 - val_acc: 0.9544\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 303us/sample - loss: 0.1427 - acc: 0.9587 - val_loss: 0.1524 - val_acc: 0.9550\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 10s 283us/sample - loss: 0.1325 - acc: 0.9623 - val_loss: 0.1566 - val_acc: 0.9556\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 297us/sample - loss: 0.1247 - acc: 0.9641 - val_loss: 0.1510 - val_acc: 0.9588\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 322us/sample - loss: 0.1184 - acc: 0.9671 - val_loss: 0.1534 - val_acc: 0.9570\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.1111 - acc: 0.9688 - val_loss: 0.1472 - val_acc: 0.9594\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.1072 - acc: 0.9707 - val_loss: 0.1451 - val_acc: 0.9590\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 10s 274us/sample - loss: 0.1012 - acc: 0.9728 - val_loss: 0.1512 - val_acc: 0.9598\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 10s 271us/sample - loss: 0.0984 - acc: 0.9738 - val_loss: 0.1416 - val_acc: 0.9628\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.0939 - acc: 0.9741 - val_loss: 0.1464 - val_acc: 0.9624\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.0917 - acc: 0.9753 - val_loss: 0.1445 - val_acc: 0.9616\n",
      "18333/18333 [==============================] - 3s 166us/sample - loss: 0.1654 - acc: 0.9585\n",
      "[CV] ..................................... n_neurons=29, total= 2.8min\n",
      "[CV] n_neurons=30 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 13s 349us/sample - loss: 0.4105 - acc: 0.8874 - val_loss: 0.2475 - val_acc: 0.9324\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 11s 299us/sample - loss: 0.2295 - acc: 0.9333 - val_loss: 0.1932 - val_acc: 0.9446\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 10s 274us/sample - loss: 0.1848 - acc: 0.9450 - val_loss: 0.1736 - val_acc: 0.9536\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 10s 280us/sample - loss: 0.1595 - acc: 0.9536 - val_loss: 0.1551 - val_acc: 0.9570\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 11s 299us/sample - loss: 0.1409 - acc: 0.9589 - val_loss: 0.1484 - val_acc: 0.9606\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 10s 262us/sample - loss: 0.1278 - acc: 0.9637 - val_loss: 0.1640 - val_acc: 0.9548\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 312us/sample - loss: 0.1172 - acc: 0.9663 - val_loss: 0.1516 - val_acc: 0.9594\n",
      "18334/18334 [==============================] - 3s 157us/sample - loss: 0.1694 - acc: 0.9522s - los\n",
      "[CV] ..................................... n_neurons=30, total= 1.4min\n",
      "[CV] n_neurons=30 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 14s 384us/sample - loss: 0.4238 - acc: 0.8823 - val_loss: 0.2536 - val_acc: 0.9270\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 301us/sample - loss: 0.2416 - acc: 0.9303 - val_loss: 0.2120 - val_acc: 0.9386\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 296us/sample - loss: 0.1998 - acc: 0.9424 - val_loss: 0.1903 - val_acc: 0.9450\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 9s 243us/sample - loss: 0.1738 - acc: 0.9496 - val_loss: 0.1701 - val_acc: 0.9516\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 283us/sample - loss: 0.1536 - acc: 0.9556 - val_loss: 0.1770 - val_acc: 0.9478\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 290us/sample - loss: 0.1395 - acc: 0.9592 - val_loss: 0.1574 - val_acc: 0.9526\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 294us/sample - loss: 0.1276 - acc: 0.9627 - val_loss: 0.1509 - val_acc: 0.9540\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 10s 274us/sample - loss: 0.1185 - acc: 0.9647 - val_loss: 0.1476 - val_acc: 0.9572\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 294us/sample - loss: 0.1115 - acc: 0.9674 - val_loss: 0.1495 - val_acc: 0.9586\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 308us/sample - loss: 0.1047 - acc: 0.9699 - val_loss: 0.1488 - val_acc: 0.9584\n",
      "18333/18333 [==============================] - 3s 164us/sample - loss: 0.1751 - acc: 0.9537\n",
      "[CV] ..................................... n_neurons=30, total= 1.9min\n",
      "[CV] n_neurons=30 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 13s 353us/sample - loss: 0.4369 - acc: 0.8810 - val_loss: 0.2643 - val_acc: 0.9252\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 313us/sample - loss: 0.2509 - acc: 0.9276 - val_loss: 0.2122 - val_acc: 0.9400\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.2059 - acc: 0.9396 - val_loss: 0.1876 - val_acc: 0.9488\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 273us/sample - loss: 0.1773 - acc: 0.9475 - val_loss: 0.1680 - val_acc: 0.9538\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 267us/sample - loss: 0.1569 - acc: 0.9555 - val_loss: 0.1609 - val_acc: 0.9578\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 263us/sample - loss: 0.1409 - acc: 0.9599 - val_loss: 0.1512 - val_acc: 0.9600\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 10s 262us/sample - loss: 0.1301 - acc: 0.9638 - val_loss: 0.1573 - val_acc: 0.9606\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 10s 262us/sample - loss: 0.1201 - acc: 0.9656 - val_loss: 0.1495 - val_acc: 0.9596\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.1126 - acc: 0.9686 - val_loss: 0.1423 - val_acc: 0.9630\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 303us/sample - loss: 0.1063 - acc: 0.9700 - val_loss: 0.1431 - val_acc: 0.9622\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 10s 279us/sample - loss: 0.1012 - acc: 0.9714 - val_loss: 0.1465 - val_acc: 0.9628\n",
      "18333/18333 [==============================] - 3s 166us/sample - loss: 0.1731 - acc: 0.9558\n",
      "[CV] ..................................... n_neurons=30, total= 2.1min\n",
      "[CV] n_neurons=31 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 15s 396us/sample - loss: 0.4094 - acc: 0.8870 - val_loss: 0.2474 - val_acc: 0.9312\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 12s 323us/sample - loss: 0.2334 - acc: 0.9335 - val_loss: 0.2042 - val_acc: 0.9420\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 305us/sample - loss: 0.1953 - acc: 0.9438 - val_loss: 0.1826 - val_acc: 0.9496\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 299us/sample - loss: 0.1699 - acc: 0.9514 - val_loss: 0.1665 - val_acc: 0.9536\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 11s 310us/sample - loss: 0.1517 - acc: 0.9573 - val_loss: 0.1630 - val_acc: 0.9546\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 304us/sample - loss: 0.1392 - acc: 0.9613 - val_loss: 0.1566 - val_acc: 0.9544\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 10s 272us/sample - loss: 0.1289 - acc: 0.9640 - val_loss: 0.1499 - val_acc: 0.9604\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 10s 272us/sample - loss: 0.1209 - acc: 0.9652 - val_loss: 0.1520 - val_acc: 0.9580\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 10s 286us/sample - loss: 0.1123 - acc: 0.9686 - val_loss: 0.1463 - val_acc: 0.9614\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 10s 264us/sample - loss: 0.1060 - acc: 0.9697 - val_loss: 0.1504 - val_acc: 0.9610\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 11s 298us/sample - loss: 0.1003 - acc: 0.9722 - val_loss: 0.1444 - val_acc: 0.9614\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 11s 290us/sample - loss: 0.0950 - acc: 0.9736 - val_loss: 0.1493 - val_acc: 0.9594\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 11s 294us/sample - loss: 0.0913 - acc: 0.9743 - val_loss: 0.1455 - val_acc: 0.9610\n",
      "18334/18334 [==============================] - 3s 158us/sample - loss: 0.1640 - acc: 0.9579\n",
      "[CV] ..................................... n_neurons=31, total= 2.5min\n",
      "[CV] n_neurons=31 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 401us/sample - loss: 0.4187 - acc: 0.8847 - val_loss: 0.2540 - val_acc: 0.9300\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.2393 - acc: 0.9324 - val_loss: 0.2045 - val_acc: 0.9420\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 296us/sample - loss: 0.1940 - acc: 0.9447 - val_loss: 0.1780 - val_acc: 0.9496\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 332us/sample - loss: 0.1668 - acc: 0.9523 - val_loss: 0.1659 - val_acc: 0.9524\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 9s 254us/sample - loss: 0.1484 - acc: 0.9579 - val_loss: 0.1549 - val_acc: 0.9558\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 255us/sample - loss: 0.1345 - acc: 0.9619 - val_loss: 0.1518 - val_acc: 0.9582\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 9s 255us/sample - loss: 0.1235 - acc: 0.9644 - val_loss: 0.1496 - val_acc: 0.9588\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 9s 246us/sample - loss: 0.1142 - acc: 0.9671 - val_loss: 0.1501 - val_acc: 0.9584\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 8s 212us/sample - loss: 0.1079 - acc: 0.9684 - val_loss: 0.1429 - val_acc: 0.9606\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 7s 193us/sample - loss: 0.1013 - acc: 0.9702 - val_loss: 0.1450 - val_acc: 0.9602\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 6s 157us/sample - loss: 0.0958 - acc: 0.9729 - val_loss: 0.1419 - val_acc: 0.9654\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 6s 158us/sample - loss: 0.0921 - acc: 0.9734 - val_loss: 0.1416 - val_acc: 0.9630\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 6s 158us/sample - loss: 0.0883 - acc: 0.9749 - val_loss: 0.1466 - val_acc: 0.9610\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 6s 162us/sample - loss: 0.0843 - acc: 0.9762 - val_loss: 0.1432 - val_acc: 0.9622\n",
      "18333/18333 [==============================] - 2s 94us/sample - loss: 0.1741 - acc: 0.9546\n",
      "[CV] ..................................... n_neurons=31, total= 2.2min\n",
      "[CV] n_neurons=31 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 9s 253us/sample - loss: 0.4439 - acc: 0.8793 - val_loss: 0.2762 - val_acc: 0.9234\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 220us/sample - loss: 0.2630 - acc: 0.9250 - val_loss: 0.2270 - val_acc: 0.9360\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 8s 221us/sample - loss: 0.2186 - acc: 0.9386 - val_loss: 0.2049 - val_acc: 0.9444\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 8s 216us/sample - loss: 0.1858 - acc: 0.9483 - val_loss: 0.1860 - val_acc: 0.9478\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 7s 203us/sample - loss: 0.1629 - acc: 0.9540 - val_loss: 0.1783 - val_acc: 0.9500\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 222us/sample - loss: 0.1466 - acc: 0.9584 - val_loss: 0.1733 - val_acc: 0.9508\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 8s 226us/sample - loss: 0.1341 - acc: 0.9620 - val_loss: 0.1595 - val_acc: 0.9582\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 9s 235us/sample - loss: 0.1240 - acc: 0.9653 - val_loss: 0.1540 - val_acc: 0.9590\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 8s 215us/sample - loss: 0.1154 - acc: 0.9684 - val_loss: 0.1540 - val_acc: 0.9590\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 8s 206us/sample - loss: 0.1095 - acc: 0.9694 - val_loss: 0.1537 - val_acc: 0.9604\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 7s 204us/sample - loss: 0.1029 - acc: 0.9716 - val_loss: 0.1567 - val_acc: 0.9586\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 8s 205us/sample - loss: 0.0982 - acc: 0.9731 - val_loss: 0.1504 - val_acc: 0.9586\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 8s 224us/sample - loss: 0.0933 - acc: 0.9743 - val_loss: 0.1562 - val_acc: 0.9586\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 8s 223us/sample - loss: 0.0890 - acc: 0.9756 - val_loss: 0.1524 - val_acc: 0.9632\n",
      "18333/18333 [==============================] - 2s 123us/sample - loss: 0.1749 - acc: 0.9563\n",
      "[CV] ..................................... n_neurons=31, total= 2.0min\n",
      "[CV] n_neurons=32 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 10s 274us/sample - loss: 0.4167 - acc: 0.8833 - val_loss: 0.2602 - val_acc: 0.9270\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 9s 239us/sample - loss: 0.2367 - acc: 0.9299 - val_loss: 0.2042 - val_acc: 0.9420\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 8s 227us/sample - loss: 0.1903 - acc: 0.9443 - val_loss: 0.1758 - val_acc: 0.9476\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 8s 223us/sample - loss: 0.1627 - acc: 0.9527 - val_loss: 0.1641 - val_acc: 0.9528\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 8s 221us/sample - loss: 0.1441 - acc: 0.9576 - val_loss: 0.1572 - val_acc: 0.9550\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 8s 209us/sample - loss: 0.1309 - acc: 0.9620 - val_loss: 0.1462 - val_acc: 0.9556\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 8s 215us/sample - loss: 0.1190 - acc: 0.9661 - val_loss: 0.1426 - val_acc: 0.9606\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 8s 219us/sample - loss: 0.1112 - acc: 0.9689 - val_loss: 0.1376 - val_acc: 0.9594\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 8s 210us/sample - loss: 0.1048 - acc: 0.9710 - val_loss: 0.1412 - val_acc: 0.9598\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 8s 209us/sample - loss: 0.0981 - acc: 0.9724 - val_loss: 0.1463 - val_acc: 0.9596\n",
      "18334/18334 [==============================] - 2s 110us/sample - loss: 0.1663 - acc: 0.9566\n",
      "[CV] ..................................... n_neurons=32, total= 1.5min\n",
      "[CV] n_neurons=32 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.4265 - acc: 0.8787 - val_loss: 0.2609 - val_acc: 0.9266\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 230us/sample - loss: 0.2415 - acc: 0.9316 - val_loss: 0.2167 - val_acc: 0.9386\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 9s 237us/sample - loss: 0.1970 - acc: 0.9431 - val_loss: 0.1872 - val_acc: 0.9458\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 8s 220us/sample - loss: 0.1672 - acc: 0.9522 - val_loss: 0.1730 - val_acc: 0.9544\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 8s 210us/sample - loss: 0.1487 - acc: 0.9573 - val_loss: 0.1650 - val_acc: 0.9504\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 225us/sample - loss: 0.1352 - acc: 0.9610 - val_loss: 0.1591 - val_acc: 0.9558\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 8s 211us/sample - loss: 0.1251 - acc: 0.9636 - val_loss: 0.1569 - val_acc: 0.9576\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 8s 209us/sample - loss: 0.1169 - acc: 0.9660 - val_loss: 0.1588 - val_acc: 0.9556\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 8s 213us/sample - loss: 0.1100 - acc: 0.9688 - val_loss: 0.1483 - val_acc: 0.9592\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 9s 234us/sample - loss: 0.1030 - acc: 0.9701 - val_loss: 0.1546 - val_acc: 0.9588\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 8s 214us/sample - loss: 0.0978 - acc: 0.9719 - val_loss: 0.1497 - val_acc: 0.9590\n",
      "18333/18333 [==============================] - 2s 115us/sample - loss: 0.1778 - acc: 0.9524\n",
      "[CV] ..................................... n_neurons=32, total= 1.6min\n",
      "[CV] n_neurons=32 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 11s 296us/sample - loss: 0.4152 - acc: 0.8839 - val_loss: 0.2371 - val_acc: 0.9318\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 215us/sample - loss: 0.2256 - acc: 0.9345 - val_loss: 0.1898 - val_acc: 0.9440\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 8s 231us/sample - loss: 0.1838 - acc: 0.9472 - val_loss: 0.1749 - val_acc: 0.9506\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 8s 222us/sample - loss: 0.1581 - acc: 0.9539 - val_loss: 0.1444 - val_acc: 0.9584\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 9s 233us/sample - loss: 0.1401 - acc: 0.9604 - val_loss: 0.1434 - val_acc: 0.9578\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 213us/sample - loss: 0.1285 - acc: 0.9631 - val_loss: 0.1305 - val_acc: 0.9632\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 8s 217us/sample - loss: 0.1167 - acc: 0.9665 - val_loss: 0.1320 - val_acc: 0.9624\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 8s 231us/sample - loss: 0.1081 - acc: 0.9689 - val_loss: 0.1398 - val_acc: 0.9628\n",
      "18333/18333 [==============================] - 2s 128us/sample - loss: 0.1606 - acc: 0.9565\n",
      "[CV] ..................................... n_neurons=32, total= 1.2min\n",
      "[CV] n_neurons=33 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 10s 269us/sample - loss: 0.4090 - acc: 0.8884 - val_loss: 0.2407 - val_acc: 0.9314\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 8s 215us/sample - loss: 0.2212 - acc: 0.9378 - val_loss: 0.1874 - val_acc: 0.9466\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 8s 223us/sample - loss: 0.1819 - acc: 0.9482 - val_loss: 0.1783 - val_acc: 0.9484\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 8s 228us/sample - loss: 0.1562 - acc: 0.9551 - val_loss: 0.1541 - val_acc: 0.9552\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 9s 252us/sample - loss: 0.1375 - acc: 0.9603 - val_loss: 0.1412 - val_acc: 0.9590\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 9s 249us/sample - loss: 0.1236 - acc: 0.9636 - val_loss: 0.1401 - val_acc: 0.9598\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 8s 213us/sample - loss: 0.1131 - acc: 0.9676 - val_loss: 0.1404 - val_acc: 0.9620\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 8s 215us/sample - loss: 0.1039 - acc: 0.9702 - val_loss: 0.1375 - val_acc: 0.9602\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 8s 220us/sample - loss: 0.0972 - acc: 0.9723 - val_loss: 0.1371 - val_acc: 0.9610\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 8s 221us/sample - loss: 0.0903 - acc: 0.9745 - val_loss: 0.1355 - val_acc: 0.9636\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 8s 223us/sample - loss: 0.0849 - acc: 0.9760 - val_loss: 0.1439 - val_acc: 0.9610\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 8s 211us/sample - loss: 0.0805 - acc: 0.9769 - val_loss: 0.1361 - val_acc: 0.9638\n",
      "18334/18334 [==============================] - 2s 107us/sample - loss: 0.1599 - acc: 0.9572\n",
      "[CV] ..................................... n_neurons=33, total= 1.8min\n",
      "[CV] n_neurons=33 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 10s 270us/sample - loss: 0.4167 - acc: 0.8859 - val_loss: 0.2642 - val_acc: 0.9238\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 209us/sample - loss: 0.2428 - acc: 0.9320 - val_loss: 0.2081 - val_acc: 0.9434\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 8s 212us/sample - loss: 0.1961 - acc: 0.9453 - val_loss: 0.1901 - val_acc: 0.9452\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 9s 240us/sample - loss: 0.1700 - acc: 0.9521 - val_loss: 0.1692 - val_acc: 0.9508\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 8s 220us/sample - loss: 0.1513 - acc: 0.9573 - val_loss: 0.1683 - val_acc: 0.9526\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 251us/sample - loss: 0.1371 - acc: 0.9600 - val_loss: 0.1572 - val_acc: 0.9520\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 8s 230us/sample - loss: 0.1269 - acc: 0.9649 - val_loss: 0.1563 - val_acc: 0.9526\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 8s 230us/sample - loss: 0.1172 - acc: 0.9671 - val_loss: 0.1461 - val_acc: 0.9578\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 8s 213us/sample - loss: 0.1103 - acc: 0.9690 - val_loss: 0.1490 - val_acc: 0.9562\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 8s 213us/sample - loss: 0.1029 - acc: 0.9716 - val_loss: 0.1558 - val_acc: 0.9572\n",
      "18333/18333 [==============================] - 2s 129us/sample - loss: 0.1702 - acc: 0.9550\n",
      "[CV] ..................................... n_neurons=33, total= 1.5min\n",
      "[CV] n_neurons=33 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 10s 283us/sample - loss: 0.4341 - acc: 0.8800 - val_loss: 0.2611 - val_acc: 0.9282\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 230us/sample - loss: 0.2521 - acc: 0.9291 - val_loss: 0.2187 - val_acc: 0.9380\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 9s 245us/sample - loss: 0.2093 - acc: 0.9393 - val_loss: 0.1904 - val_acc: 0.9448\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 8s 229us/sample - loss: 0.1842 - acc: 0.9467 - val_loss: 0.1778 - val_acc: 0.9504\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 8s 230us/sample - loss: 0.1647 - acc: 0.9526 - val_loss: 0.1633 - val_acc: 0.9522\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 216us/sample - loss: 0.1475 - acc: 0.9573 - val_loss: 0.1642 - val_acc: 0.9530\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 8s 213us/sample - loss: 0.1366 - acc: 0.9600 - val_loss: 0.1581 - val_acc: 0.9528\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 8s 231us/sample - loss: 0.1258 - acc: 0.9641 - val_loss: 0.1452 - val_acc: 0.9600\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 9s 233us/sample - loss: 0.1178 - acc: 0.9662 - val_loss: 0.1477 - val_acc: 0.9586\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 8s 216us/sample - loss: 0.1095 - acc: 0.9696 - val_loss: 0.1454 - val_acc: 0.9598\n",
      "18333/18333 [==============================] - 2s 115us/sample - loss: 0.1670 - acc: 0.9556\n",
      "[CV] ..................................... n_neurons=33, total= 1.5min\n",
      "[CV] n_neurons=34 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 11s 296us/sample - loss: 0.4097 - acc: 0.8867 - val_loss: 0.2417 - val_acc: 0.9314\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 8s 231us/sample - loss: 0.2239 - acc: 0.9362 - val_loss: 0.1936 - val_acc: 0.9446\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 8s 226us/sample - loss: 0.1823 - acc: 0.9471 - val_loss: 0.1837 - val_acc: 0.9480\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 9s 241us/sample - loss: 0.1561 - acc: 0.9543 - val_loss: 0.1651 - val_acc: 0.9526\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 8s 230us/sample - loss: 0.1399 - acc: 0.9598 - val_loss: 0.1458 - val_acc: 0.9588\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 8s 232us/sample - loss: 0.1262 - acc: 0.9633 - val_loss: 0.1475 - val_acc: 0.9592\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 9s 240us/sample - loss: 0.1164 - acc: 0.9654 - val_loss: 0.1426 - val_acc: 0.9616\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 9s 235us/sample - loss: 0.1070 - acc: 0.9691 - val_loss: 0.1397 - val_acc: 0.9620\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 9s 233us/sample - loss: 0.1001 - acc: 0.9711 - val_loss: 0.1470 - val_acc: 0.9586\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 8s 224us/sample - loss: 0.0948 - acc: 0.9728 - val_loss: 0.1443 - val_acc: 0.9622\n",
      "18334/18334 [==============================] - 2s 120us/sample - loss: 0.1641 - acc: 0.9564\n",
      "[CV] ..................................... n_neurons=34, total= 1.6min\n",
      "[CV] n_neurons=34 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 10s 286us/sample - loss: 0.4006 - acc: 0.8891 - val_loss: 0.2445 - val_acc: 0.9306\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 243us/sample - loss: 0.2316 - acc: 0.9337 - val_loss: 0.2054 - val_acc: 0.9438\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 8s 231us/sample - loss: 0.1881 - acc: 0.9463 - val_loss: 0.1766 - val_acc: 0.9516\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 8s 228us/sample - loss: 0.1598 - acc: 0.9544 - val_loss: 0.1694 - val_acc: 0.9530\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 8s 223us/sample - loss: 0.1416 - acc: 0.9606 - val_loss: 0.1629 - val_acc: 0.9536\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 235us/sample - loss: 0.1280 - acc: 0.9635 - val_loss: 0.1537 - val_acc: 0.9566\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 10s 259us/sample - loss: 0.1163 - acc: 0.9671 - val_loss: 0.1530 - val_acc: 0.9548\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 9s 232us/sample - loss: 0.1077 - acc: 0.9692 - val_loss: 0.1608 - val_acc: 0.9568\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 9s 253us/sample - loss: 0.1014 - acc: 0.9716 - val_loss: 0.1437 - val_acc: 0.9594\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 8s 229us/sample - loss: 0.0948 - acc: 0.9732 - val_loss: 0.1464 - val_acc: 0.9584\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 9s 236us/sample - loss: 0.0897 - acc: 0.9752 - val_loss: 0.1458 - val_acc: 0.9580\n",
      "18333/18333 [==============================] - 2s 130us/sample - loss: 0.1599 - acc: 0.9589\n",
      "[CV] ..................................... n_neurons=34, total= 1.7min\n",
      "[CV] n_neurons=34 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 12s 327us/sample - loss: 0.4129 - acc: 0.8844 - val_loss: 0.2558 - val_acc: 0.9256\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 233us/sample - loss: 0.2326 - acc: 0.9319 - val_loss: 0.1958 - val_acc: 0.9424\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 8s 211us/sample - loss: 0.1869 - acc: 0.9456 - val_loss: 0.1787 - val_acc: 0.9506\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 8s 216us/sample - loss: 0.1589 - acc: 0.9544 - val_loss: 0.1676 - val_acc: 0.9534\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 8s 215us/sample - loss: 0.1407 - acc: 0.9601 - val_loss: 0.1499 - val_acc: 0.9590\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 229us/sample - loss: 0.1261 - acc: 0.9634 - val_loss: 0.1426 - val_acc: 0.9588\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 8s 225us/sample - loss: 0.1158 - acc: 0.9664 - val_loss: 0.1520 - val_acc: 0.9586\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 8s 229us/sample - loss: 0.1066 - acc: 0.9692 - val_loss: 0.1354 - val_acc: 0.9620\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 8s 219us/sample - loss: 0.1006 - acc: 0.9721 - val_loss: 0.1348 - val_acc: 0.9630\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 9s 239us/sample - loss: 0.0949 - acc: 0.9729 - val_loss: 0.1375 - val_acc: 0.9620\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 9s 243us/sample - loss: 0.0896 - acc: 0.9751 - val_loss: 0.1415 - val_acc: 0.9602\n",
      "18333/18333 [==============================] - 2s 117us/sample - loss: 0.1578 - acc: 0.9598\n",
      "[CV] ..................................... n_neurons=34, total= 1.7min\n",
      "[CV] n_neurons=35 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 10s 283us/sample - loss: 0.4038 - acc: 0.8885 - val_loss: 0.2449 - val_acc: 0.9308\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 8s 211us/sample - loss: 0.2194 - acc: 0.9363 - val_loss: 0.1996 - val_acc: 0.9412\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 8s 228us/sample - loss: 0.1754 - acc: 0.9483 - val_loss: 0.1682 - val_acc: 0.9524\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 8s 220us/sample - loss: 0.1508 - acc: 0.9567 - val_loss: 0.1570 - val_acc: 0.9534\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 7s 184us/sample - loss: 0.1323 - acc: 0.9622 - val_loss: 0.1463 - val_acc: 0.9582\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 7s 183us/sample - loss: 0.1189 - acc: 0.9651 - val_loss: 0.1478 - val_acc: 0.9592\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 7s 203us/sample - loss: 0.1099 - acc: 0.9691 - val_loss: 0.1386 - val_acc: 0.9610\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 9s 236us/sample - loss: 0.1020 - acc: 0.9715 - val_loss: 0.1410 - val_acc: 0.9614\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 9s 240us/sample - loss: 0.0950 - acc: 0.9739 - val_loss: 0.1357 - val_acc: 0.9620\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 9s 248us/sample - loss: 0.0896 - acc: 0.9749 - val_loss: 0.1375 - val_acc: 0.9622\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 8s 230us/sample - loss: 0.0853 - acc: 0.9768 - val_loss: 0.1429 - val_acc: 0.9616\n",
      "18334/18334 [==============================] - 2s 122us/sample - loss: 0.1583 - acc: 0.9583\n",
      "[CV] ..................................... n_neurons=35, total= 1.6min\n",
      "[CV] n_neurons=35 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 11s 308us/sample - loss: 0.4226 - acc: 0.8832 - val_loss: 0.2395 - val_acc: 0.9338\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 217us/sample - loss: 0.2314 - acc: 0.9357 - val_loss: 0.1981 - val_acc: 0.9464\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 8s 219us/sample - loss: 0.1853 - acc: 0.9482 - val_loss: 0.1739 - val_acc: 0.9498\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 9s 237us/sample - loss: 0.1590 - acc: 0.9551 - val_loss: 0.1623 - val_acc: 0.9536\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 8s 225us/sample - loss: 0.1402 - acc: 0.9608 - val_loss: 0.1597 - val_acc: 0.9556\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 248us/sample - loss: 0.1265 - acc: 0.9650 - val_loss: 0.1462 - val_acc: 0.9590\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 8s 230us/sample - loss: 0.1139 - acc: 0.9682 - val_loss: 0.1380 - val_acc: 0.9600\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 8s 228us/sample - loss: 0.1063 - acc: 0.9710 - val_loss: 0.1443 - val_acc: 0.9584\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 9s 238us/sample - loss: 0.0999 - acc: 0.9723 - val_loss: 0.1373 - val_acc: 0.9614\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 9s 233us/sample - loss: 0.0924 - acc: 0.9738 - val_loss: 0.1371 - val_acc: 0.9626\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 9s 234us/sample - loss: 0.0874 - acc: 0.9747 - val_loss: 0.1341 - val_acc: 0.9628\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 9s 241us/sample - loss: 0.0811 - acc: 0.9772 - val_loss: 0.1354 - val_acc: 0.9642\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 8s 230us/sample - loss: 0.0772 - acc: 0.9784 - val_loss: 0.1358 - val_acc: 0.9626\n",
      "18333/18333 [==============================] - 3s 142us/sample - loss: 0.1592 - acc: 0.9605\n",
      "[CV] ..................................... n_neurons=35, total= 2.0min\n",
      "[CV] n_neurons=35 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 11s 291us/sample - loss: 0.4132 - acc: 0.8874 - val_loss: 0.2408 - val_acc: 0.9336\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 219us/sample - loss: 0.2269 - acc: 0.9348 - val_loss: 0.1956 - val_acc: 0.9460\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 8s 226us/sample - loss: 0.1813 - acc: 0.9465 - val_loss: 0.1640 - val_acc: 0.9534\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 8s 215us/sample - loss: 0.1543 - acc: 0.9554 - val_loss: 0.1470 - val_acc: 0.9600\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 8s 226us/sample - loss: 0.1374 - acc: 0.9594 - val_loss: 0.1438 - val_acc: 0.9608\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 228us/sample - loss: 0.1236 - acc: 0.9645 - val_loss: 0.1379 - val_acc: 0.9616\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 9s 246us/sample - loss: 0.1136 - acc: 0.9675 - val_loss: 0.1362 - val_acc: 0.9640\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 9s 245us/sample - loss: 0.1056 - acc: 0.9702 - val_loss: 0.1383 - val_acc: 0.9618\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 8s 218us/sample - loss: 0.0985 - acc: 0.9720 - val_loss: 0.1345 - val_acc: 0.9644\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 9s 241us/sample - loss: 0.0928 - acc: 0.9735 - val_loss: 0.1371 - val_acc: 0.9638\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 9s 251us/sample - loss: 0.0872 - acc: 0.9759 - val_loss: 0.1367 - val_acc: 0.9638\n",
      "18333/18333 [==============================] - 2s 133us/sample - loss: 0.1576 - acc: 0.9601\n",
      "[CV] ..................................... n_neurons=35, total= 1.7min\n",
      "[CV] n_neurons=36 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 11s 297us/sample - loss: 0.4051 - acc: 0.8879 - val_loss: 0.2487 - val_acc: 0.9282\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 9s 245us/sample - loss: 0.2342 - acc: 0.9326 - val_loss: 0.2044 - val_acc: 0.9448\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 8s 223us/sample - loss: 0.1939 - acc: 0.9438 - val_loss: 0.1761 - val_acc: 0.9516\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 9s 241us/sample - loss: 0.1682 - acc: 0.9526 - val_loss: 0.1789 - val_acc: 0.9482\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 8s 229us/sample - loss: 0.1516 - acc: 0.9573 - val_loss: 0.1594 - val_acc: 0.9540\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 8s 228us/sample - loss: 0.1387 - acc: 0.9612 - val_loss: 0.1600 - val_acc: 0.9564\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 8s 230us/sample - loss: 0.1277 - acc: 0.9637 - val_loss: 0.1632 - val_acc: 0.9532\n",
      "18334/18334 [==============================] - 2s 117us/sample - loss: 0.1817 - acc: 0.9497\n",
      "[CV] ..................................... n_neurons=36, total= 1.1min\n",
      "[CV] n_neurons=36 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.3952 - acc: 0.8911 - val_loss: 0.2437 - val_acc: 0.9294\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 217us/sample - loss: 0.2249 - acc: 0.9355 - val_loss: 0.1910 - val_acc: 0.9464\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 9s 233us/sample - loss: 0.1792 - acc: 0.9494 - val_loss: 0.1630 - val_acc: 0.9542\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 8s 230us/sample - loss: 0.1517 - acc: 0.9565 - val_loss: 0.1601 - val_acc: 0.9550\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 8s 221us/sample - loss: 0.1338 - acc: 0.9611 - val_loss: 0.1434 - val_acc: 0.9600\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 225us/sample - loss: 0.1199 - acc: 0.9648 - val_loss: 0.1469 - val_acc: 0.9558\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 10s 261us/sample - loss: 0.1102 - acc: 0.9673 - val_loss: 0.1405 - val_acc: 0.9618\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 9s 253us/sample - loss: 0.1015 - acc: 0.9701 - val_loss: 0.1337 - val_acc: 0.9630\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 9s 236us/sample - loss: 0.0945 - acc: 0.9728 - val_loss: 0.1357 - val_acc: 0.9608\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 8s 224us/sample - loss: 0.0888 - acc: 0.9743 - val_loss: 0.1352 - val_acc: 0.9642\n",
      "18333/18333 [==============================] - 2s 118us/sample - loss: 0.1587 - acc: 0.9587\n",
      "[CV] ..................................... n_neurons=36, total= 1.6min\n",
      "[CV] n_neurons=36 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 11s 296us/sample - loss: 0.4239 - acc: 0.8829 - val_loss: 0.2414 - val_acc: 0.9344\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 234us/sample - loss: 0.2309 - acc: 0.9330 - val_loss: 0.2014 - val_acc: 0.9424\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 8s 222us/sample - loss: 0.1868 - acc: 0.9459 - val_loss: 0.1659 - val_acc: 0.9574\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 8s 221us/sample - loss: 0.1549 - acc: 0.9547 - val_loss: 0.1498 - val_acc: 0.9602\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 9s 245us/sample - loss: 0.1343 - acc: 0.9615 - val_loss: 0.1390 - val_acc: 0.9614\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 239us/sample - loss: 0.1195 - acc: 0.9651 - val_loss: 0.1369 - val_acc: 0.9624\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 10s 260us/sample - loss: 0.1083 - acc: 0.9691 - val_loss: 0.1307 - val_acc: 0.9646\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 9s 233us/sample - loss: 0.0980 - acc: 0.9724 - val_loss: 0.1284 - val_acc: 0.9656\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 8s 217us/sample - loss: 0.0922 - acc: 0.9748 - val_loss: 0.1284 - val_acc: 0.9638\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 8s 219us/sample - loss: 0.0858 - acc: 0.9770 - val_loss: 0.1335 - val_acc: 0.9650\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 8s 230us/sample - loss: 0.0796 - acc: 0.9781 - val_loss: 0.1285 - val_acc: 0.9656\n",
      "18333/18333 [==============================] - 2s 119us/sample - loss: 0.1608 - acc: 0.9600\n",
      "[CV] ..................................... n_neurons=36, total= 1.7min\n",
      "[CV] n_neurons=37 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 11s 312us/sample - loss: 0.3994 - acc: 0.8890 - val_loss: 0.2434 - val_acc: 0.9312\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 9s 232us/sample - loss: 0.2303 - acc: 0.9329 - val_loss: 0.2056 - val_acc: 0.9416\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 8s 230us/sample - loss: 0.1847 - acc: 0.9465 - val_loss: 0.1719 - val_acc: 0.9522\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 8s 226us/sample - loss: 0.1589 - acc: 0.9533 - val_loss: 0.1510 - val_acc: 0.9570\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 9s 235us/sample - loss: 0.1386 - acc: 0.9596 - val_loss: 0.1622 - val_acc: 0.9534\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 7s 197us/sample - loss: 0.1253 - acc: 0.9643 - val_loss: 0.1450 - val_acc: 0.9610\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 8s 223us/sample - loss: 0.1138 - acc: 0.9674 - val_loss: 0.1434 - val_acc: 0.9624\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 9s 242us/sample - loss: 0.1046 - acc: 0.9700 - val_loss: 0.1435 - val_acc: 0.9616\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 8s 222us/sample - loss: 0.0976 - acc: 0.9725 - val_loss: 0.1403 - val_acc: 0.9598\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 8s 224us/sample - loss: 0.0906 - acc: 0.9745 - val_loss: 0.1457 - val_acc: 0.9598\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 9s 252us/sample - loss: 0.0864 - acc: 0.9755 - val_loss: 0.1446 - val_acc: 0.9612\n",
      "18334/18334 [==============================] - 2s 132us/sample - loss: 0.1607 - acc: 0.9578\n",
      "[CV] ..................................... n_neurons=37, total= 1.7min\n",
      "[CV] n_neurons=37 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 11s 313us/sample - loss: 0.4068 - acc: 0.8865 - val_loss: 0.2326 - val_acc: 0.9306\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 247us/sample - loss: 0.2208 - acc: 0.9379 - val_loss: 0.1891 - val_acc: 0.9452\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 8s 221us/sample - loss: 0.1775 - acc: 0.9492 - val_loss: 0.1646 - val_acc: 0.9548\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 9s 237us/sample - loss: 0.1497 - acc: 0.9572 - val_loss: 0.1520 - val_acc: 0.9586\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 9s 236us/sample - loss: 0.1321 - acc: 0.9613 - val_loss: 0.1355 - val_acc: 0.9612\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 244us/sample - loss: 0.1183 - acc: 0.9657 - val_loss: 0.1376 - val_acc: 0.9616\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 9s 254us/sample - loss: 0.1086 - acc: 0.9680 - val_loss: 0.1335 - val_acc: 0.9636\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 10s 268us/sample - loss: 0.0994 - acc: 0.9714 - val_loss: 0.1319 - val_acc: 0.9618\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 9s 238us/sample - loss: 0.0923 - acc: 0.9733 - val_loss: 0.1330 - val_acc: 0.9622\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 9s 236us/sample - loss: 0.0865 - acc: 0.9748 - val_loss: 0.1336 - val_acc: 0.9644\n",
      "18333/18333 [==============================] - 3s 140us/sample - loss: 0.1575 - acc: 0.9582\n",
      "[CV] ..................................... n_neurons=37, total= 1.6min\n",
      "[CV] n_neurons=37 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 11s 298us/sample - loss: 0.4174 - acc: 0.8854 - val_loss: 0.2394 - val_acc: 0.9320\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 231us/sample - loss: 0.2260 - acc: 0.9348 - val_loss: 0.1811 - val_acc: 0.9520\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 9s 251us/sample - loss: 0.1772 - acc: 0.9481 - val_loss: 0.1656 - val_acc: 0.9520\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 9s 251us/sample - loss: 0.1506 - acc: 0.9569 - val_loss: 0.1566 - val_acc: 0.9572\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 8s 227us/sample - loss: 0.1308 - acc: 0.9621 - val_loss: 0.1385 - val_acc: 0.9628\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 223us/sample - loss: 0.1174 - acc: 0.9661 - val_loss: 0.1393 - val_acc: 0.9624\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 9s 236us/sample - loss: 0.1081 - acc: 0.9696 - val_loss: 0.1380 - val_acc: 0.9620\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 9s 246us/sample - loss: 0.1004 - acc: 0.9718 - val_loss: 0.1345 - val_acc: 0.9638\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 8s 230us/sample - loss: 0.0923 - acc: 0.9738 - val_loss: 0.1378 - val_acc: 0.9622\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 9s 233us/sample - loss: 0.0873 - acc: 0.9757 - val_loss: 0.1324 - val_acc: 0.9628\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 8s 228us/sample - loss: 0.0826 - acc: 0.9767 - val_loss: 0.1316 - val_acc: 0.9652\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 9s 241us/sample - loss: 0.0780 - acc: 0.9787 - val_loss: 0.1394 - val_acc: 0.9626\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 8s 228us/sample - loss: 0.0747 - acc: 0.9803 - val_loss: 0.1392 - val_acc: 0.9644\n",
      "18333/18333 [==============================] - 2s 117us/sample - loss: 0.1553 - acc: 0.9620\n",
      "[CV] ..................................... n_neurons=37, total= 2.0min\n",
      "[CV] n_neurons=38 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 11s 298us/sample - loss: 0.4140 - acc: 0.8823 - val_loss: 0.2419 - val_acc: 0.9282\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 9s 234us/sample - loss: 0.2276 - acc: 0.9324 - val_loss: 0.1944 - val_acc: 0.9428\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 9s 244us/sample - loss: 0.1839 - acc: 0.9464 - val_loss: 0.1797 - val_acc: 0.9482\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 9s 256us/sample - loss: 0.1587 - acc: 0.9534 - val_loss: 0.1648 - val_acc: 0.9516\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 9s 233us/sample - loss: 0.1414 - acc: 0.9591 - val_loss: 0.1542 - val_acc: 0.9556\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 9s 235us/sample - loss: 0.1281 - acc: 0.9628 - val_loss: 0.1535 - val_acc: 0.9526\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 10s 264us/sample - loss: 0.1173 - acc: 0.9656 - val_loss: 0.1476 - val_acc: 0.9548\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 9s 246us/sample - loss: 0.1086 - acc: 0.9688 - val_loss: 0.1399 - val_acc: 0.9586\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 9s 255us/sample - loss: 0.1003 - acc: 0.9708 - val_loss: 0.1564 - val_acc: 0.9538\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 8s 221us/sample - loss: 0.0942 - acc: 0.9729 - val_loss: 0.1461 - val_acc: 0.9594\n",
      "18334/18334 [==============================] - 2s 116us/sample - loss: 0.1672 - acc: 0.9566\n",
      "[CV] ..................................... n_neurons=38, total= 1.6min\n",
      "[CV] n_neurons=38 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.3983 - acc: 0.8919 - val_loss: 0.2350 - val_acc: 0.9330\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 244us/sample - loss: 0.2110 - acc: 0.9403 - val_loss: 0.1770 - val_acc: 0.9504\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 8s 229us/sample - loss: 0.1711 - acc: 0.9510 - val_loss: 0.1636 - val_acc: 0.9520\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 9s 248us/sample - loss: 0.1483 - acc: 0.9575 - val_loss: 0.1530 - val_acc: 0.9556\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 9s 244us/sample - loss: 0.1301 - acc: 0.9623 - val_loss: 0.1442 - val_acc: 0.9618\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 237us/sample - loss: 0.1191 - acc: 0.9650 - val_loss: 0.1427 - val_acc: 0.9608\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 8s 231us/sample - loss: 0.1091 - acc: 0.9676 - val_loss: 0.1338 - val_acc: 0.9618\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 8s 228us/sample - loss: 0.1007 - acc: 0.9710 - val_loss: 0.1353 - val_acc: 0.9618\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 9s 235us/sample - loss: 0.0926 - acc: 0.9730 - val_loss: 0.1302 - val_acc: 0.9638\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 9s 246us/sample - loss: 0.0859 - acc: 0.9758 - val_loss: 0.1335 - val_acc: 0.9624\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 9s 243us/sample - loss: 0.0811 - acc: 0.9761 - val_loss: 0.1309 - val_acc: 0.9646\n",
      "18333/18333 [==============================] - 2s 128us/sample - loss: 0.1545 - acc: 0.9591\n",
      "[CV] ..................................... n_neurons=38, total= 1.7min\n",
      "[CV] n_neurons=38 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 11s 309us/sample - loss: 0.4176 - acc: 0.8858 - val_loss: 0.2449 - val_acc: 0.9300\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 242us/sample - loss: 0.2313 - acc: 0.9330 - val_loss: 0.1905 - val_acc: 0.9452\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 9s 233us/sample - loss: 0.1812 - acc: 0.9480 - val_loss: 0.1687 - val_acc: 0.9502\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 9s 246us/sample - loss: 0.1520 - acc: 0.9551 - val_loss: 0.1422 - val_acc: 0.9586\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 9s 233us/sample - loss: 0.1327 - acc: 0.9609 - val_loss: 0.1376 - val_acc: 0.9618\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 239us/sample - loss: 0.1199 - acc: 0.9659 - val_loss: 0.1284 - val_acc: 0.9636\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 9s 237us/sample - loss: 0.1101 - acc: 0.9681 - val_loss: 0.1317 - val_acc: 0.9604\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 9s 255us/sample - loss: 0.1007 - acc: 0.9714 - val_loss: 0.1291 - val_acc: 0.9620\n",
      "18333/18333 [==============================] - 2s 135us/sample - loss: 0.1519 - acc: 0.9570\n",
      "[CV] ..................................... n_neurons=38, total= 1.3min\n",
      "[CV] n_neurons=39 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 11s 308us/sample - loss: 0.3858 - acc: 0.8918 - val_loss: 0.2287 - val_acc: 0.9382\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 9s 255us/sample - loss: 0.2140 - acc: 0.9381 - val_loss: 0.1849 - val_acc: 0.9486\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 10s 275us/sample - loss: 0.1692 - acc: 0.9500 - val_loss: 0.1634 - val_acc: 0.9526\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 9s 258us/sample - loss: 0.1441 - acc: 0.9578 - val_loss: 0.1492 - val_acc: 0.9582\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 10s 265us/sample - loss: 0.1266 - acc: 0.9631 - val_loss: 0.1426 - val_acc: 0.9590\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 9s 251us/sample - loss: 0.1132 - acc: 0.9677 - val_loss: 0.1370 - val_acc: 0.9626\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 10s 269us/sample - loss: 0.1034 - acc: 0.9706 - val_loss: 0.1357 - val_acc: 0.9636\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 10s 265us/sample - loss: 0.0952 - acc: 0.9728 - val_loss: 0.1365 - val_acc: 0.9644\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 9s 256us/sample - loss: 0.0874 - acc: 0.9745 - val_loss: 0.1382 - val_acc: 0.9604\n",
      "18334/18334 [==============================] - 2s 128us/sample - loss: 0.1624 - acc: 0.9561s - l\n",
      "[CV] ..................................... n_neurons=39, total= 1.6min\n",
      "[CV] n_neurons=39 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 13s 357us/sample - loss: 0.3941 - acc: 0.8898 - val_loss: 0.2369 - val_acc: 0.9334\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 10s 267us/sample - loss: 0.2174 - acc: 0.9380 - val_loss: 0.1849 - val_acc: 0.9466\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 259us/sample - loss: 0.1717 - acc: 0.9507 - val_loss: 0.1648 - val_acc: 0.9510\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 9s 258us/sample - loss: 0.1451 - acc: 0.9585 - val_loss: 0.1507 - val_acc: 0.9538\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 9s 251us/sample - loss: 0.1265 - acc: 0.9638 - val_loss: 0.1368 - val_acc: 0.9600\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 317us/sample - loss: 0.1115 - acc: 0.9680 - val_loss: 0.1490 - val_acc: 0.9548\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 10s 282us/sample - loss: 0.1008 - acc: 0.9707 - val_loss: 0.1381 - val_acc: 0.9598\n",
      "18333/18333 [==============================] - 3s 150us/sample - loss: 0.1627 - acc: 0.9543\n",
      "[CV] ..................................... n_neurons=39, total= 1.4min\n",
      "[CV] n_neurons=39 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 12s 334us/sample - loss: 0.3939 - acc: 0.8925 - val_loss: 0.2305 - val_acc: 0.9340\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 240us/sample - loss: 0.2162 - acc: 0.9381 - val_loss: 0.1900 - val_acc: 0.9436\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 8s 230us/sample - loss: 0.1737 - acc: 0.9506 - val_loss: 0.1606 - val_acc: 0.9552\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 8s 231us/sample - loss: 0.1480 - acc: 0.9572 - val_loss: 0.1398 - val_acc: 0.9598\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 260us/sample - loss: 0.1292 - acc: 0.9635 - val_loss: 0.1329 - val_acc: 0.9634\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 279us/sample - loss: 0.1152 - acc: 0.9670 - val_loss: 0.1316 - val_acc: 0.9628\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 9s 238us/sample - loss: 0.1044 - acc: 0.9698 - val_loss: 0.1307 - val_acc: 0.9628\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 9s 252us/sample - loss: 0.0964 - acc: 0.9726 - val_loss: 0.1249 - val_acc: 0.9630\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 10s 266us/sample - loss: 0.0892 - acc: 0.9741 - val_loss: 0.1292 - val_acc: 0.9642\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 9s 239us/sample - loss: 0.0811 - acc: 0.9761 - val_loss: 0.1324 - val_acc: 0.9632\n",
      "18333/18333 [==============================] - 2s 126us/sample - loss: 0.1552 - acc: 0.9579\n",
      "[CV] ..................................... n_neurons=39, total= 1.7min\n",
      "[CV] n_neurons=40 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 14s 380us/sample - loss: 0.3956 - acc: 0.8880 - val_loss: 0.2389 - val_acc: 0.9322\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 9s 249us/sample - loss: 0.2215 - acc: 0.9365 - val_loss: 0.1816 - val_acc: 0.9494\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 9s 236us/sample - loss: 0.1729 - acc: 0.9516 - val_loss: 0.1577 - val_acc: 0.9532\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 9s 240us/sample - loss: 0.1456 - acc: 0.9587 - val_loss: 0.1498 - val_acc: 0.9572\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 9s 238us/sample - loss: 0.1271 - acc: 0.9641 - val_loss: 0.1421 - val_acc: 0.9582\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 9s 253us/sample - loss: 0.1133 - acc: 0.9688 - val_loss: 0.1335 - val_acc: 0.9618\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 10s 272us/sample - loss: 0.1025 - acc: 0.9713 - val_loss: 0.1331 - val_acc: 0.9616\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 10s 262us/sample - loss: 0.0946 - acc: 0.9738 - val_loss: 0.1362 - val_acc: 0.9620\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 10s 267us/sample - loss: 0.0874 - acc: 0.9753 - val_loss: 0.1402 - val_acc: 0.9612\n",
      "18334/18334 [==============================] - 3s 137us/sample - loss: 0.1593 - acc: 0.9594\n",
      "[CV] ..................................... n_neurons=40, total= 1.6min\n",
      "[CV] n_neurons=40 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 13s 344us/sample - loss: 0.3903 - acc: 0.8940 - val_loss: 0.2297 - val_acc: 0.9358\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 256us/sample - loss: 0.2109 - acc: 0.9392 - val_loss: 0.1851 - val_acc: 0.9462\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 274us/sample - loss: 0.1691 - acc: 0.9515 - val_loss: 0.1590 - val_acc: 0.9522\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 9s 243us/sample - loss: 0.1454 - acc: 0.9589 - val_loss: 0.1444 - val_acc: 0.9588\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 7s 191us/sample - loss: 0.1272 - acc: 0.9637 - val_loss: 0.1361 - val_acc: 0.9630\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 7s 198us/sample - loss: 0.1152 - acc: 0.9680 - val_loss: 0.1280 - val_acc: 0.9612\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 8s 214us/sample - loss: 0.1053 - acc: 0.9693 - val_loss: 0.1215 - val_acc: 0.9666\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 8s 209us/sample - loss: 0.0975 - acc: 0.9725 - val_loss: 0.1188 - val_acc: 0.9664\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 7s 194us/sample - loss: 0.0913 - acc: 0.9736 - val_loss: 0.1261 - val_acc: 0.9634\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 7s 193us/sample - loss: 0.0864 - acc: 0.9749 - val_loss: 0.1176 - val_acc: 0.9670\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 8s 222us/sample - loss: 0.0806 - acc: 0.9771 - val_loss: 0.1222 - val_acc: 0.9658\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 7s 193us/sample - loss: 0.0764 - acc: 0.9778 - val_loss: 0.1203 - val_acc: 0.9684\n",
      "18333/18333 [==============================] - 3s 176us/sample - loss: 0.1479 - acc: 0.9615\n",
      "[CV] ..................................... n_neurons=40, total= 1.8min\n",
      "[CV] n_neurons=40 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 11s 286us/sample - loss: 0.3940 - acc: 0.8909 - val_loss: 0.2322 - val_acc: 0.9372\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 206us/sample - loss: 0.2188 - acc: 0.9371 - val_loss: 0.1867 - val_acc: 0.9472\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 8s 227us/sample - loss: 0.1748 - acc: 0.9494 - val_loss: 0.1547 - val_acc: 0.9576\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 7s 189us/sample - loss: 0.1496 - acc: 0.9569 - val_loss: 0.1446 - val_acc: 0.9592\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 7s 189us/sample - loss: 0.1318 - acc: 0.9614 - val_loss: 0.1338 - val_acc: 0.9620\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 7s 197us/sample - loss: 0.1187 - acc: 0.9650 - val_loss: 0.1292 - val_acc: 0.9626\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 8s 226us/sample - loss: 0.1075 - acc: 0.9692 - val_loss: 0.1316 - val_acc: 0.9632\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 7s 202us/sample - loss: 0.0990 - acc: 0.9717 - val_loss: 0.1286 - val_acc: 0.9630\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 7s 194us/sample - loss: 0.0916 - acc: 0.9740 - val_loss: 0.1425 - val_acc: 0.9576\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 7s 194us/sample - loss: 0.0857 - acc: 0.9757 - val_loss: 0.1328 - val_acc: 0.9636\n",
      "18333/18333 [==============================] - 2s 103us/sample - loss: 0.1505 - acc: 0.9599\n",
      "[CV] ..................................... n_neurons=40, total= 1.4min\n",
      "[CV] n_neurons=41 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 10s 276us/sample - loss: 0.4010 - acc: 0.8887 - val_loss: 0.2449 - val_acc: 0.9286\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 7s 197us/sample - loss: 0.2231 - acc: 0.9362 - val_loss: 0.1877 - val_acc: 0.9482\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 7s 200us/sample - loss: 0.1794 - acc: 0.9487 - val_loss: 0.1668 - val_acc: 0.9554\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 7s 194us/sample - loss: 0.1522 - acc: 0.9563 - val_loss: 0.1600 - val_acc: 0.9546\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 7s 186us/sample - loss: 0.1338 - acc: 0.9616 - val_loss: 0.1524 - val_acc: 0.9574\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 7s 191us/sample - loss: 0.1196 - acc: 0.9657 - val_loss: 0.1424 - val_acc: 0.9592\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 8s 205us/sample - loss: 0.1085 - acc: 0.9687 - val_loss: 0.1407 - val_acc: 0.9626\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 7s 203us/sample - loss: 0.1005 - acc: 0.9716 - val_loss: 0.1399 - val_acc: 0.9618\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 7s 201us/sample - loss: 0.0924 - acc: 0.9738 - val_loss: 0.1419 - val_acc: 0.9630\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 8s 214us/sample - loss: 0.0860 - acc: 0.9753 - val_loss: 0.1451 - val_acc: 0.9626\n",
      "18334/18334 [==============================] - 2s 106us/sample - loss: 0.1576 - acc: 0.9593\n",
      "[CV] ..................................... n_neurons=41, total= 1.4min\n",
      "[CV] n_neurons=41 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 14s 395us/sample - loss: 0.3860 - acc: 0.8918 - val_loss: 0.2441 - val_acc: 0.9286\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 219us/sample - loss: 0.2159 - acc: 0.9381 - val_loss: 0.1852 - val_acc: 0.9478\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 16s 436us/sample - loss: 0.1718 - acc: 0.9516 - val_loss: 0.1650 - val_acc: 0.9524\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 263us/sample - loss: 0.1456 - acc: 0.9587 - val_loss: 0.1486 - val_acc: 0.9572\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 8s 207us/sample - loss: 0.1266 - acc: 0.9645 - val_loss: 0.1452 - val_acc: 0.9580\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 211us/sample - loss: 0.1128 - acc: 0.9673 - val_loss: 0.1300 - val_acc: 0.9620\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 8s 214us/sample - loss: 0.1033 - acc: 0.9705 - val_loss: 0.1327 - val_acc: 0.9624\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 7s 203us/sample - loss: 0.0946 - acc: 0.9727 - val_loss: 0.1267 - val_acc: 0.9624\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 8s 205us/sample - loss: 0.0873 - acc: 0.9741 - val_loss: 0.1278 - val_acc: 0.9638\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 7s 204us/sample - loss: 0.0805 - acc: 0.9761 - val_loss: 0.1244 - val_acc: 0.9642\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 7s 203us/sample - loss: 0.0748 - acc: 0.9787 - val_loss: 0.1413 - val_acc: 0.9612\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 7s 197us/sample - loss: 0.0711 - acc: 0.9795 - val_loss: 0.1298 - val_acc: 0.9660\n",
      "18333/18333 [==============================] - 2s 115us/sample - loss: 0.1573 - acc: 0.9606\n",
      "[CV] ..................................... n_neurons=41, total= 1.9min\n",
      "[CV] n_neurons=41 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 10s 286us/sample - loss: 0.3935 - acc: 0.8917 - val_loss: 0.2342 - val_acc: 0.9288\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 205us/sample - loss: 0.2165 - acc: 0.9374 - val_loss: 0.1811 - val_acc: 0.9472\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 7s 204us/sample - loss: 0.1723 - acc: 0.9512 - val_loss: 0.1573 - val_acc: 0.9548\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 7s 200us/sample - loss: 0.1444 - acc: 0.9581 - val_loss: 0.1486 - val_acc: 0.9580\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 8s 208us/sample - loss: 0.1265 - acc: 0.9633 - val_loss: 0.1316 - val_acc: 0.9622\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 211us/sample - loss: 0.1128 - acc: 0.9680 - val_loss: 0.1343 - val_acc: 0.9634\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 8s 215us/sample - loss: 0.1015 - acc: 0.9707 - val_loss: 0.1257 - val_acc: 0.9650\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 8s 210us/sample - loss: 0.0928 - acc: 0.9739 - val_loss: 0.1192 - val_acc: 0.9674\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 8s 207us/sample - loss: 0.0844 - acc: 0.9764 - val_loss: 0.1230 - val_acc: 0.9662\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 8s 215us/sample - loss: 0.0801 - acc: 0.9778 - val_loss: 0.1233 - val_acc: 0.9664\n",
      "18333/18333 [==============================] - 2s 135us/sample - loss: 0.1491 - acc: 0.9598\n",
      "[CV] ..................................... n_neurons=41, total= 1.4min\n",
      "[CV] n_neurons=42 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 14s 394us/sample - loss: 0.3880 - acc: 0.8913 - val_loss: 0.2259 - val_acc: 0.9324\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 11s 293us/sample - loss: 0.2021 - acc: 0.9409 - val_loss: 0.1683 - val_acc: 0.9534\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 10s 264us/sample - loss: 0.1584 - acc: 0.9533 - val_loss: 0.1555 - val_acc: 0.9542\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 10s 266us/sample - loss: 0.1344 - acc: 0.9610 - val_loss: 0.1425 - val_acc: 0.9586\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 10s 269us/sample - loss: 0.1157 - acc: 0.9655 - val_loss: 0.1345 - val_acc: 0.9622\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 10s 263us/sample - loss: 0.1036 - acc: 0.9700 - val_loss: 0.1347 - val_acc: 0.9608\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 9s 254us/sample - loss: 0.0934 - acc: 0.9731 - val_loss: 0.1279 - val_acc: 0.9630\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 9s 259us/sample - loss: 0.0851 - acc: 0.9759 - val_loss: 0.1254 - val_acc: 0.9646\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 9s 252us/sample - loss: 0.0789 - acc: 0.9773 - val_loss: 0.1277 - val_acc: 0.9642\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 10s 262us/sample - loss: 0.0737 - acc: 0.9794 - val_loss: 0.1199 - val_acc: 0.9680\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 10s 262us/sample - loss: 0.0680 - acc: 0.9807 - val_loss: 0.1328 - val_acc: 0.9664\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 9s 252us/sample - loss: 0.0643 - acc: 0.9817 - val_loss: 0.1211 - val_acc: 0.9666\n",
      "18334/18334 [==============================] - 2s 132us/sample - loss: 0.1490 - acc: 0.9614\n",
      "[CV] ..................................... n_neurons=42, total= 2.2min\n",
      "[CV] n_neurons=42 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 13s 357us/sample - loss: 0.3867 - acc: 0.8920 - val_loss: 0.2338 - val_acc: 0.9328\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 253us/sample - loss: 0.2182 - acc: 0.9368 - val_loss: 0.1967 - val_acc: 0.9440\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 262us/sample - loss: 0.1743 - acc: 0.9505 - val_loss: 0.1590 - val_acc: 0.9552\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 265us/sample - loss: 0.1465 - acc: 0.9572 - val_loss: 0.1482 - val_acc: 0.9580\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 263us/sample - loss: 0.1281 - acc: 0.9632 - val_loss: 0.1365 - val_acc: 0.9598\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 208us/sample - loss: 0.1142 - acc: 0.9672 - val_loss: 0.1316 - val_acc: 0.9630\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 8s 209us/sample - loss: 0.1028 - acc: 0.9708 - val_loss: 0.1418 - val_acc: 0.9620\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 8s 223us/sample - loss: 0.0947 - acc: 0.9726 - val_loss: 0.1266 - val_acc: 0.9660\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 8s 226us/sample - loss: 0.0880 - acc: 0.9750 - val_loss: 0.1315 - val_acc: 0.9610\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 8s 229us/sample - loss: 0.0818 - acc: 0.9770 - val_loss: 0.1268 - val_acc: 0.9654\n",
      "18333/18333 [==============================] - 2s 131us/sample - loss: 0.1570 - acc: 0.9588\n",
      "[CV] ..................................... n_neurons=42, total= 1.6min\n",
      "[CV] n_neurons=42 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 10s 284us/sample - loss: 0.3856 - acc: 0.8923 - val_loss: 0.2263 - val_acc: 0.9350\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 211us/sample - loss: 0.2117 - acc: 0.9376 - val_loss: 0.1794 - val_acc: 0.9502\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 8s 224us/sample - loss: 0.1682 - acc: 0.9504 - val_loss: 0.1457 - val_acc: 0.9566\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 7s 199us/sample - loss: 0.1407 - acc: 0.9592 - val_loss: 0.1354 - val_acc: 0.9610\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 7s 200us/sample - loss: 0.1218 - acc: 0.9641 - val_loss: 0.1297 - val_acc: 0.9646\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 207us/sample - loss: 0.1092 - acc: 0.9674 - val_loss: 0.1299 - val_acc: 0.9662\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 7s 198us/sample - loss: 0.0978 - acc: 0.9709 - val_loss: 0.1262 - val_acc: 0.9652\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 7s 200us/sample - loss: 0.0898 - acc: 0.9743 - val_loss: 0.1282 - val_acc: 0.9650\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 8s 207us/sample - loss: 0.0832 - acc: 0.9753 - val_loss: 0.1234 - val_acc: 0.9658\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 8s 208us/sample - loss: 0.0763 - acc: 0.9784 - val_loss: 0.1259 - val_acc: 0.9660\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 8s 211us/sample - loss: 0.0719 - acc: 0.9796 - val_loss: 0.1175 - val_acc: 0.9662\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 7s 197us/sample - loss: 0.0673 - acc: 0.9815 - val_loss: 0.1240 - val_acc: 0.9644\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 7s 198us/sample - loss: 0.0642 - acc: 0.9819 - val_loss: 0.1264 - val_acc: 0.9682\n",
      "18333/18333 [==============================] - 2s 112us/sample - loss: 0.1517 - acc: 0.9631\n",
      "[CV] ..................................... n_neurons=42, total= 1.8min\n",
      "[CV] n_neurons=43 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 12s 322us/sample - loss: 0.3900 - acc: 0.8903 - val_loss: 0.2444 - val_acc: 0.9328\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 8s 218us/sample - loss: 0.2087 - acc: 0.9383 - val_loss: 0.1800 - val_acc: 0.9464\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 7s 204us/sample - loss: 0.1659 - acc: 0.9511 - val_loss: 0.1564 - val_acc: 0.9536\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 7s 200us/sample - loss: 0.1410 - acc: 0.9589 - val_loss: 0.1620 - val_acc: 0.9530\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 8s 208us/sample - loss: 0.1227 - acc: 0.9649 - val_loss: 0.1308 - val_acc: 0.9622\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 9s 257us/sample - loss: 0.1080 - acc: 0.9681 - val_loss: 0.1354 - val_acc: 0.9594\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 9s 257us/sample - loss: 0.0980 - acc: 0.9715 - val_loss: 0.1369 - val_acc: 0.9622\n",
      "18334/18334 [==============================] - 2s 110us/sample - loss: 0.1628 - acc: 0.9544\n",
      "[CV] ..................................... n_neurons=43, total= 1.1min\n",
      "[CV] n_neurons=43 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.3890 - acc: 0.8937 - val_loss: 0.2208 - val_acc: 0.9384\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 10s 277us/sample - loss: 0.2045 - acc: 0.9425 - val_loss: 0.1810 - val_acc: 0.9498\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 259us/sample - loss: 0.1601 - acc: 0.9542 - val_loss: 0.1534 - val_acc: 0.9580\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 9s 240us/sample - loss: 0.1338 - acc: 0.9615 - val_loss: 0.1374 - val_acc: 0.9618\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 15s 416us/sample - loss: 0.1171 - acc: 0.9661 - val_loss: 0.1313 - val_acc: 0.9666\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 220us/sample - loss: 0.1038 - acc: 0.9711 - val_loss: 0.1304 - val_acc: 0.9656\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 7s 203us/sample - loss: 0.0935 - acc: 0.9729 - val_loss: 0.1239 - val_acc: 0.9666\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 8s 206us/sample - loss: 0.0855 - acc: 0.9767 - val_loss: 0.1243 - val_acc: 0.9662\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 8s 206us/sample - loss: 0.0789 - acc: 0.9776 - val_loss: 0.1203 - val_acc: 0.9662\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 8s 214us/sample - loss: 0.0736 - acc: 0.9795 - val_loss: 0.1302 - val_acc: 0.9676\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 8s 223us/sample - loss: 0.0694 - acc: 0.9812 - val_loss: 0.1209 - val_acc: 0.9674\n",
      "18333/18333 [==============================] - 2s 116us/sample - loss: 0.1449 - acc: 0.9641\n",
      "[CV] ..................................... n_neurons=43, total= 1.8min\n",
      "[CV] n_neurons=43 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 11s 298us/sample - loss: 0.3869 - acc: 0.8900 - val_loss: 0.2252 - val_acc: 0.9362\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 7s 201us/sample - loss: 0.2129 - acc: 0.9394 - val_loss: 0.1748 - val_acc: 0.9510\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 7s 194us/sample - loss: 0.1652 - acc: 0.9524 - val_loss: 0.1508 - val_acc: 0.9610\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 8s 213us/sample - loss: 0.1372 - acc: 0.9605 - val_loss: 0.1470 - val_acc: 0.9578\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 8s 213us/sample - loss: 0.1177 - acc: 0.9657 - val_loss: 0.1325 - val_acc: 0.9620\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 8s 212us/sample - loss: 0.1032 - acc: 0.9714 - val_loss: 0.1245 - val_acc: 0.9674\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 7s 197us/sample - loss: 0.0927 - acc: 0.9735 - val_loss: 0.1221 - val_acc: 0.9656\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 8s 206us/sample - loss: 0.0835 - acc: 0.9764 - val_loss: 0.1207 - val_acc: 0.9684\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 8s 216us/sample - loss: 0.0779 - acc: 0.9786 - val_loss: 0.1281 - val_acc: 0.9638\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 8s 218us/sample - loss: 0.0722 - acc: 0.9801 - val_loss: 0.1207 - val_acc: 0.9676\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 8s 212us/sample - loss: 0.0667 - acc: 0.9816 - val_loss: 0.1184 - val_acc: 0.9704\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 8s 212us/sample - loss: 0.0640 - acc: 0.9833 - val_loss: 0.1180 - val_acc: 0.9698\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 8s 215us/sample - loss: 0.0602 - acc: 0.9837 - val_loss: 0.1212 - val_acc: 0.9678\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 8s 216us/sample - loss: 0.0560 - acc: 0.9857 - val_loss: 0.1175 - val_acc: 0.9694\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 8s 210us/sample - loss: 0.0528 - acc: 0.9864 - val_loss: 0.1261 - val_acc: 0.9696\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 8s 216us/sample - loss: 0.0505 - acc: 0.9869 - val_loss: 0.1269 - val_acc: 0.9698\n",
      "18333/18333 [==============================] - 2s 120us/sample - loss: 0.1480 - acc: 0.9664\n",
      "[CV] ..................................... n_neurons=43, total= 2.2min\n",
      "[CV] n_neurons=44 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 12s 320us/sample - loss: 0.3778 - acc: 0.8963 - val_loss: 0.2334 - val_acc: 0.9320\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 9s 254us/sample - loss: 0.2021 - acc: 0.9424 - val_loss: 0.1818 - val_acc: 0.9514\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 9s 255us/sample - loss: 0.1596 - acc: 0.9541 - val_loss: 0.1612 - val_acc: 0.9538\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 8s 210us/sample - loss: 0.1344 - acc: 0.9621 - val_loss: 0.1467 - val_acc: 0.9574\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 8s 214us/sample - loss: 0.1176 - acc: 0.9672 - val_loss: 0.1384 - val_acc: 0.9628\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 8s 214us/sample - loss: 0.1048 - acc: 0.9702 - val_loss: 0.1433 - val_acc: 0.9622\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 8s 216us/sample - loss: 0.0919 - acc: 0.9744 - val_loss: 0.1277 - val_acc: 0.9652\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 8s 217us/sample - loss: 0.0850 - acc: 0.9767 - val_loss: 0.1348 - val_acc: 0.9644\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 8s 220us/sample - loss: 0.0784 - acc: 0.9785 - val_loss: 0.1274 - val_acc: 0.9644\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 8s 218us/sample - loss: 0.0723 - acc: 0.9804 - val_loss: 0.1308 - val_acc: 0.9648\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 8s 220us/sample - loss: 0.0670 - acc: 0.9813 - val_loss: 0.1273 - val_acc: 0.9668\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 9s 257us/sample - loss: 0.0630 - acc: 0.9826 - val_loss: 0.1324 - val_acc: 0.9646\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 10s 265us/sample - loss: 0.0594 - acc: 0.9835 - val_loss: 0.1314 - val_acc: 0.9648\n",
      "18334/18334 [==============================] - 3s 146us/sample - loss: 0.1534 - acc: 0.9635\n",
      "[CV] ..................................... n_neurons=44, total= 2.0min\n",
      "[CV] n_neurons=44 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 12s 333us/sample - loss: 0.3739 - acc: 0.8976 - val_loss: 0.2133 - val_acc: 0.9404\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 253us/sample - loss: 0.2052 - acc: 0.9413 - val_loss: 0.1852 - val_acc: 0.9472\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 262us/sample - loss: 0.1631 - acc: 0.9538 - val_loss: 0.1521 - val_acc: 0.9548\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 273us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1461 - val_acc: 0.9570\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 9s 255us/sample - loss: 0.1184 - acc: 0.9656 - val_loss: 0.1343 - val_acc: 0.9600\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 266us/sample - loss: 0.1056 - acc: 0.9696 - val_loss: 0.1325 - val_acc: 0.9620\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 10s 268us/sample - loss: 0.0946 - acc: 0.9726 - val_loss: 0.1304 - val_acc: 0.9610\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 10s 263us/sample - loss: 0.0863 - acc: 0.9755 - val_loss: 0.1245 - val_acc: 0.9624\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 10s 279us/sample - loss: 0.0790 - acc: 0.9779 - val_loss: 0.1278 - val_acc: 0.9652\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 9s 257us/sample - loss: 0.0726 - acc: 0.9787 - val_loss: 0.1191 - val_acc: 0.9668\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 10s 277us/sample - loss: 0.0676 - acc: 0.9805 - val_loss: 0.1219 - val_acc: 0.9670\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 10s 263us/sample - loss: 0.0630 - acc: 0.9821 - val_loss: 0.1225 - val_acc: 0.9672\n",
      "18333/18333 [==============================] - 3s 151us/sample - loss: 0.1461 - acc: 0.9634\n",
      "[CV] ..................................... n_neurons=44, total= 2.1min\n",
      "[CV] n_neurons=44 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 13s 351us/sample - loss: 0.3811 - acc: 0.8945 - val_loss: 0.2167 - val_acc: 0.9374\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 286us/sample - loss: 0.2020 - acc: 0.9408 - val_loss: 0.1776 - val_acc: 0.9472\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 275us/sample - loss: 0.1574 - acc: 0.9540 - val_loss: 0.1469 - val_acc: 0.9566\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.1327 - acc: 0.9607 - val_loss: 0.1357 - val_acc: 0.9604\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 279us/sample - loss: 0.1144 - acc: 0.9668 - val_loss: 0.1300 - val_acc: 0.9624\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 281us/sample - loss: 0.1024 - acc: 0.9706 - val_loss: 0.1250 - val_acc: 0.9644\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.0916 - acc: 0.9736 - val_loss: 0.1204 - val_acc: 0.9646\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 288us/sample - loss: 0.0831 - acc: 0.9761 - val_loss: 0.1178 - val_acc: 0.9664\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 10s 280us/sample - loss: 0.0753 - acc: 0.9785 - val_loss: 0.1166 - val_acc: 0.9672\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 10s 270us/sample - loss: 0.0685 - acc: 0.9813 - val_loss: 0.1159 - val_acc: 0.9676\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 10s 280us/sample - loss: 0.0640 - acc: 0.9824 - val_loss: 0.1169 - val_acc: 0.9678\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 10s 272us/sample - loss: 0.0594 - acc: 0.9834 - val_loss: 0.1175 - val_acc: 0.9676\n",
      "18333/18333 [==============================] - 3s 163us/sample - loss: 0.1391 - acc: 0.9655\n",
      "[CV] ..................................... n_neurons=44, total= 2.2min\n",
      "[CV] n_neurons=45 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 13s 355us/sample - loss: 0.3773 - acc: 0.8943 - val_loss: 0.2183 - val_acc: 0.9384\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 10s 268us/sample - loss: 0.2051 - acc: 0.9406 - val_loss: 0.1745 - val_acc: 0.9512\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 10s 267us/sample - loss: 0.1634 - acc: 0.9533 - val_loss: 0.1493 - val_acc: 0.9578\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 10s 262us/sample - loss: 0.1369 - acc: 0.9599 - val_loss: 0.1513 - val_acc: 0.9562\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 11s 287us/sample - loss: 0.1195 - acc: 0.9663 - val_loss: 0.1427 - val_acc: 0.9602\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 10s 286us/sample - loss: 0.1079 - acc: 0.9693 - val_loss: 0.1288 - val_acc: 0.9652\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 10s 272us/sample - loss: 0.0976 - acc: 0.9727 - val_loss: 0.1405 - val_acc: 0.9582\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 302us/sample - loss: 0.0888 - acc: 0.9745 - val_loss: 0.1307 - val_acc: 0.9634\n",
      "18334/18334 [==============================] - 3s 168us/sample - loss: 0.1439 - acc: 0.9613\n",
      "[CV] ..................................... n_neurons=45, total= 1.5min\n",
      "[CV] n_neurons=45 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 14s 391us/sample - loss: 0.3759 - acc: 0.8954 - val_loss: 0.2221 - val_acc: 0.9352\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 293us/sample - loss: 0.2040 - acc: 0.9421 - val_loss: 0.1747 - val_acc: 0.9492\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 266us/sample - loss: 0.1600 - acc: 0.9538 - val_loss: 0.1540 - val_acc: 0.9566\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 278us/sample - loss: 0.1340 - acc: 0.9615 - val_loss: 0.1382 - val_acc: 0.9600\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 279us/sample - loss: 0.1151 - acc: 0.9666 - val_loss: 0.1340 - val_acc: 0.9628\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 279us/sample - loss: 0.1019 - acc: 0.9701 - val_loss: 0.1275 - val_acc: 0.9640\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 10s 282us/sample - loss: 0.0919 - acc: 0.9737 - val_loss: 0.1291 - val_acc: 0.9646\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 10s 280us/sample - loss: 0.0839 - acc: 0.9761 - val_loss: 0.1219 - val_acc: 0.9666\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 10s 286us/sample - loss: 0.0769 - acc: 0.9786 - val_loss: 0.1230 - val_acc: 0.9650\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 10s 275us/sample - loss: 0.0708 - acc: 0.9797 - val_loss: 0.1238 - val_acc: 0.9674\n",
      "18333/18333 [==============================] - 3s 159us/sample - loss: 0.1454 - acc: 0.9627\n",
      "[CV] ..................................... n_neurons=45, total= 1.9min\n",
      "[CV] n_neurons=45 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 14s 384us/sample - loss: 0.3711 - acc: 0.8970 - val_loss: 0.2146 - val_acc: 0.9406\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 295us/sample - loss: 0.1977 - acc: 0.9425 - val_loss: 0.1667 - val_acc: 0.9542\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 284us/sample - loss: 0.1532 - acc: 0.9547 - val_loss: 0.1402 - val_acc: 0.9604\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 274us/sample - loss: 0.1275 - acc: 0.9627 - val_loss: 0.1290 - val_acc: 0.9612\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 294us/sample - loss: 0.1111 - acc: 0.9682 - val_loss: 0.1228 - val_acc: 0.9632\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 269us/sample - loss: 0.0994 - acc: 0.9720 - val_loss: 0.1227 - val_acc: 0.9648\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 9s 253us/sample - loss: 0.0892 - acc: 0.9743 - val_loss: 0.1228 - val_acc: 0.9632\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 10s 262us/sample - loss: 0.0828 - acc: 0.9769 - val_loss: 0.1156 - val_acc: 0.9656\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 10s 284us/sample - loss: 0.0764 - acc: 0.9786 - val_loss: 0.1129 - val_acc: 0.9674\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 294us/sample - loss: 0.0709 - acc: 0.9807 - val_loss: 0.1132 - val_acc: 0.9686\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 10s 273us/sample - loss: 0.0663 - acc: 0.9810 - val_loss: 0.1211 - val_acc: 0.9676\n",
      "18333/18333 [==============================] - 3s 145us/sample - loss: 0.1451 - acc: 0.9630\n",
      "[CV] ..................................... n_neurons=45, total= 2.1min\n",
      "[CV] n_neurons=46 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 14s 369us/sample - loss: 0.3825 - acc: 0.8930 - val_loss: 0.2329 - val_acc: 0.9304\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 10s 285us/sample - loss: 0.2121 - acc: 0.9388 - val_loss: 0.1812 - val_acc: 0.9492\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 10s 266us/sample - loss: 0.1641 - acc: 0.9521 - val_loss: 0.1532 - val_acc: 0.9566\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 12s 316us/sample - loss: 0.1350 - acc: 0.9602 - val_loss: 0.1442 - val_acc: 0.9602\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 14s 372us/sample - loss: 0.1176 - acc: 0.9646 - val_loss: 0.1376 - val_acc: 0.9620\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 290us/sample - loss: 0.1035 - acc: 0.9698 - val_loss: 0.1341 - val_acc: 0.9642\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 10s 285us/sample - loss: 0.0936 - acc: 0.9732 - val_loss: 0.1377 - val_acc: 0.9660\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 289us/sample - loss: 0.0857 - acc: 0.9741 - val_loss: 0.1292 - val_acc: 0.9668\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 11s 295us/sample - loss: 0.0783 - acc: 0.9778 - val_loss: 0.1346 - val_acc: 0.9656\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 10s 286us/sample - loss: 0.0717 - acc: 0.9799 - val_loss: 0.1314 - val_acc: 0.9678\n",
      "18334/18334 [==============================] - 3s 156us/sample - loss: 0.1491 - acc: 0.9614\n",
      "[CV] ..................................... n_neurons=46, total= 2.0min\n",
      "[CV] n_neurons=46 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 14s 383us/sample - loss: 0.3835 - acc: 0.8941 - val_loss: 0.2342 - val_acc: 0.9342\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 288us/sample - loss: 0.2107 - acc: 0.9402 - val_loss: 0.1800 - val_acc: 0.9504\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 280us/sample - loss: 0.1646 - acc: 0.9533 - val_loss: 0.1614 - val_acc: 0.9542\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.1374 - acc: 0.9606 - val_loss: 0.1418 - val_acc: 0.9594\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 309us/sample - loss: 0.1196 - acc: 0.9659 - val_loss: 0.1458 - val_acc: 0.9594\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.1065 - acc: 0.9695 - val_loss: 0.1314 - val_acc: 0.9632\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 290us/sample - loss: 0.0964 - acc: 0.9724 - val_loss: 0.1250 - val_acc: 0.9642\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 290us/sample - loss: 0.0877 - acc: 0.9747 - val_loss: 0.1309 - val_acc: 0.9638\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 297us/sample - loss: 0.0794 - acc: 0.9767 - val_loss: 0.1241 - val_acc: 0.9660\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 10s 286us/sample - loss: 0.0719 - acc: 0.9787 - val_loss: 0.1237 - val_acc: 0.9680\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 11s 290us/sample - loss: 0.0677 - acc: 0.9799 - val_loss: 0.1249 - val_acc: 0.9642\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 11s 287us/sample - loss: 0.0624 - acc: 0.9815 - val_loss: 0.1175 - val_acc: 0.9670\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 11s 307us/sample - loss: 0.0590 - acc: 0.9824 - val_loss: 0.1206 - val_acc: 0.9664\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 11s 291us/sample - loss: 0.0549 - acc: 0.9839 - val_loss: 0.1251 - val_acc: 0.9662\n",
      "18333/18333 [==============================] - 3s 156us/sample - loss: 0.1410 - acc: 0.9662\n",
      "[CV] ..................................... n_neurons=46, total= 2.7min\n",
      "[CV] n_neurons=46 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 14s 385us/sample - loss: 0.3904 - acc: 0.8913 - val_loss: 0.2329 - val_acc: 0.9352\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 301us/sample - loss: 0.2079 - acc: 0.9398 - val_loss: 0.1726 - val_acc: 0.9518\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.1627 - acc: 0.9529 - val_loss: 0.1444 - val_acc: 0.9602\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 291us/sample - loss: 0.1358 - acc: 0.9606 - val_loss: 0.1451 - val_acc: 0.9574\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 278us/sample - loss: 0.1186 - acc: 0.9653 - val_loss: 0.1253 - val_acc: 0.9626\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.1041 - acc: 0.9699 - val_loss: 0.1293 - val_acc: 0.9624\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.0951 - acc: 0.9727 - val_loss: 0.1272 - val_acc: 0.9642\n",
      "18333/18333 [==============================] - 2s 133us/sample - loss: 0.1462 - acc: 0.9596\n",
      "[CV] ..................................... n_neurons=46, total= 1.5min\n",
      "[CV] n_neurons=47 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 13s 341us/sample - loss: 0.3710 - acc: 0.8959 - val_loss: 0.2205 - val_acc: 0.9356\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 10s 272us/sample - loss: 0.2091 - acc: 0.9386 - val_loss: 0.1752 - val_acc: 0.9486\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 10s 259us/sample - loss: 0.1647 - acc: 0.9521 - val_loss: 0.1490 - val_acc: 0.9560\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 10s 274us/sample - loss: 0.1361 - acc: 0.9611 - val_loss: 0.1370 - val_acc: 0.9630\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 10s 266us/sample - loss: 0.1167 - acc: 0.9659 - val_loss: 0.1306 - val_acc: 0.9634\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 311us/sample - loss: 0.1041 - acc: 0.9697 - val_loss: 0.1293 - val_acc: 0.9608\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 10s 279us/sample - loss: 0.0929 - acc: 0.9736 - val_loss: 0.1218 - val_acc: 0.9648\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 288us/sample - loss: 0.0844 - acc: 0.9756 - val_loss: 0.1224 - val_acc: 0.9646\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 11s 293us/sample - loss: 0.0773 - acc: 0.9779 - val_loss: 0.1130 - val_acc: 0.9676\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 10s 282us/sample - loss: 0.0706 - acc: 0.9801 - val_loss: 0.1188 - val_acc: 0.9648\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 10s 284us/sample - loss: 0.0666 - acc: 0.9813 - val_loss: 0.1223 - val_acc: 0.9668\n",
      "18334/18334 [==============================] - 3s 151us/sample - loss: 0.1448 - acc: 0.9630\n",
      "[CV] ..................................... n_neurons=47, total= 2.1min\n",
      "[CV] n_neurons=47 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 397us/sample - loss: 0.3807 - acc: 0.8963 - val_loss: 0.2331 - val_acc: 0.9348\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 297us/sample - loss: 0.2031 - acc: 0.9420 - val_loss: 0.1769 - val_acc: 0.9496\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 287us/sample - loss: 0.1588 - acc: 0.9552 - val_loss: 0.1515 - val_acc: 0.9554\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 294us/sample - loss: 0.1331 - acc: 0.9621 - val_loss: 0.1355 - val_acc: 0.9596\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 308us/sample - loss: 0.1174 - acc: 0.9669 - val_loss: 0.1321 - val_acc: 0.9594\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 284us/sample - loss: 0.1045 - acc: 0.9699 - val_loss: 0.1304 - val_acc: 0.9612\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 286us/sample - loss: 0.0947 - acc: 0.9725 - val_loss: 0.1268 - val_acc: 0.9636\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 293us/sample - loss: 0.0871 - acc: 0.9750 - val_loss: 0.1233 - val_acc: 0.9640\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 295us/sample - loss: 0.0799 - acc: 0.9771 - val_loss: 0.1186 - val_acc: 0.9642\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 309us/sample - loss: 0.0740 - acc: 0.9790 - val_loss: 0.1260 - val_acc: 0.9634\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 11s 305us/sample - loss: 0.0700 - acc: 0.9798 - val_loss: 0.1228 - val_acc: 0.9662\n",
      "18333/18333 [==============================] - 3s 155us/sample - loss: 0.1442 - acc: 0.9607\n",
      "[CV] ..................................... n_neurons=47, total= 2.2min\n",
      "[CV] n_neurons=47 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 14s 395us/sample - loss: 0.3860 - acc: 0.8921 - val_loss: 0.2276 - val_acc: 0.9368\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 325us/sample - loss: 0.2107 - acc: 0.9390 - val_loss: 0.1819 - val_acc: 0.9462\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.1623 - acc: 0.9528 - val_loss: 0.1465 - val_acc: 0.9606\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.1332 - acc: 0.9618 - val_loss: 0.1358 - val_acc: 0.9624\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.1148 - acc: 0.9670 - val_loss: 0.1395 - val_acc: 0.9606\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 306us/sample - loss: 0.1014 - acc: 0.9708 - val_loss: 0.1244 - val_acc: 0.9666\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 293us/sample - loss: 0.0921 - acc: 0.9736 - val_loss: 0.1257 - val_acc: 0.9678\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 301us/sample - loss: 0.0830 - acc: 0.9770 - val_loss: 0.1261 - val_acc: 0.9676\n",
      "18333/18333 [==============================] - 3s 163us/sample - loss: 0.1475 - acc: 0.9611\n",
      "[CV] ..................................... n_neurons=47, total= 1.7min\n",
      "[CV] n_neurons=48 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 15s 409us/sample - loss: 0.3698 - acc: 0.8968 - val_loss: 0.2283 - val_acc: 0.9356\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 11s 303us/sample - loss: 0.2033 - acc: 0.9410 - val_loss: 0.1747 - val_acc: 0.9480\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 313us/sample - loss: 0.1577 - acc: 0.9538 - val_loss: 0.1479 - val_acc: 0.9562\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 303us/sample - loss: 0.1318 - acc: 0.9626 - val_loss: 0.1366 - val_acc: 0.9614\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 11s 293us/sample - loss: 0.1130 - acc: 0.9672 - val_loss: 0.1307 - val_acc: 0.9618\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 304us/sample - loss: 0.1005 - acc: 0.9715 - val_loss: 0.1222 - val_acc: 0.9636\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 296us/sample - loss: 0.0911 - acc: 0.9740 - val_loss: 0.1200 - val_acc: 0.9652\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 294us/sample - loss: 0.0826 - acc: 0.9759 - val_loss: 0.1169 - val_acc: 0.9674\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 12s 318us/sample - loss: 0.0754 - acc: 0.9787 - val_loss: 0.1200 - val_acc: 0.9660\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 11s 289us/sample - loss: 0.0710 - acc: 0.9805 - val_loss: 0.1160 - val_acc: 0.9688\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 11s 311us/sample - loss: 0.0657 - acc: 0.9811 - val_loss: 0.1204 - val_acc: 0.9670\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 11s 310us/sample - loss: 0.0612 - acc: 0.9831 - val_loss: 0.1175 - val_acc: 0.9700\n",
      "18334/18334 [==============================] - 3s 161us/sample - loss: 0.1416 - acc: 0.9632\n",
      "[CV] ..................................... n_neurons=48, total= 2.4min\n",
      "[CV] n_neurons=48 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 434us/sample - loss: 0.3784 - acc: 0.8966 - val_loss: 0.2170 - val_acc: 0.9418\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.2023 - acc: 0.9422 - val_loss: 0.1698 - val_acc: 0.9506\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.1575 - acc: 0.9555 - val_loss: 0.1493 - val_acc: 0.9550\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 291us/sample - loss: 0.1319 - acc: 0.9620 - val_loss: 0.1318 - val_acc: 0.9618\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 266us/sample - loss: 0.1136 - acc: 0.9677 - val_loss: 0.1383 - val_acc: 0.9594\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 276us/sample - loss: 0.1009 - acc: 0.9709 - val_loss: 0.1320 - val_acc: 0.9590\n",
      "18333/18333 [==============================] - 3s 139us/sample - loss: 0.1548 - acc: 0.9554\n",
      "[CV] ..................................... n_neurons=48, total= 1.3min\n",
      "[CV] n_neurons=48 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 13s 350us/sample - loss: 0.3880 - acc: 0.8928 - val_loss: 0.2258 - val_acc: 0.9398\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 10s 267us/sample - loss: 0.2139 - acc: 0.9378 - val_loss: 0.1799 - val_acc: 0.9494\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 314us/sample - loss: 0.1687 - acc: 0.9513 - val_loss: 0.1507 - val_acc: 0.9564\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 309us/sample - loss: 0.1397 - acc: 0.9592 - val_loss: 0.1404 - val_acc: 0.9600\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 277us/sample - loss: 0.1205 - acc: 0.9649 - val_loss: 0.1278 - val_acc: 0.9660\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 251us/sample - loss: 0.1070 - acc: 0.9693 - val_loss: 0.1281 - val_acc: 0.9622\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 8s 227us/sample - loss: 0.0960 - acc: 0.9723 - val_loss: 0.1200 - val_acc: 0.9652\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 8s 221us/sample - loss: 0.0861 - acc: 0.9759 - val_loss: 0.1158 - val_acc: 0.9662\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 9s 249us/sample - loss: 0.0783 - acc: 0.9775 - val_loss: 0.1220 - val_acc: 0.9644\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 19s 515us/sample - loss: 0.0722 - acc: 0.9803 - val_loss: 0.1159 - val_acc: 0.9680\n",
      "18333/18333 [==============================] - 4s 203us/sample - loss: 0.1380 - acc: 0.9647\n",
      "[CV] ..................................... n_neurons=48, total= 2.0min\n",
      "[CV] n_neurons=49 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 12s 316us/sample - loss: 0.3620 - acc: 0.8999 - val_loss: 0.1972 - val_acc: 0.9434\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 8s 227us/sample - loss: 0.1855 - acc: 0.9462 - val_loss: 0.1519 - val_acc: 0.9566\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 8s 219us/sample - loss: 0.1468 - acc: 0.9565 - val_loss: 0.1384 - val_acc: 0.9586\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 8s 227us/sample - loss: 0.1224 - acc: 0.9642 - val_loss: 0.1231 - val_acc: 0.9658\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 10s 265us/sample - loss: 0.1074 - acc: 0.9689 - val_loss: 0.1190 - val_acc: 0.9660\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 10s 280us/sample - loss: 0.0959 - acc: 0.9721 - val_loss: 0.1175 - val_acc: 0.9680\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 293us/sample - loss: 0.0861 - acc: 0.9754 - val_loss: 0.1165 - val_acc: 0.9678\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 295us/sample - loss: 0.0793 - acc: 0.9774 - val_loss: 0.1162 - val_acc: 0.9662\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 9s 242us/sample - loss: 0.0729 - acc: 0.9795 - val_loss: 0.1165 - val_acc: 0.9674\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 8s 225us/sample - loss: 0.0666 - acc: 0.9812 - val_loss: 0.1119 - val_acc: 0.9702\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 8s 224us/sample - loss: 0.0624 - acc: 0.9828 - val_loss: 0.1166 - val_acc: 0.9680\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 8s 225us/sample - loss: 0.0569 - acc: 0.9836 - val_loss: 0.1213 - val_acc: 0.9700\n",
      "18334/18334 [==============================] - 2s 124us/sample - loss: 0.1526 - acc: 0.9631\n",
      "[CV] ..................................... n_neurons=49, total= 2.0min\n",
      "[CV] n_neurons=49 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 12s 334us/sample - loss: 0.3758 - acc: 0.8965 - val_loss: 0.2211 - val_acc: 0.9390\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 219us/sample - loss: 0.2071 - acc: 0.9412 - val_loss: 0.1751 - val_acc: 0.9504\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 8s 221us/sample - loss: 0.1618 - acc: 0.9532 - val_loss: 0.1562 - val_acc: 0.9554\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 8s 228us/sample - loss: 0.1371 - acc: 0.9612 - val_loss: 0.1386 - val_acc: 0.9618\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 9s 242us/sample - loss: 0.1174 - acc: 0.9665 - val_loss: 0.1288 - val_acc: 0.9616\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 236us/sample - loss: 0.1045 - acc: 0.9701 - val_loss: 0.1249 - val_acc: 0.9642\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 9s 234us/sample - loss: 0.0944 - acc: 0.9735 - val_loss: 0.1180 - val_acc: 0.9648\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 8s 228us/sample - loss: 0.0847 - acc: 0.9756 - val_loss: 0.1240 - val_acc: 0.9646\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 9s 241us/sample - loss: 0.0777 - acc: 0.9779 - val_loss: 0.1226 - val_acc: 0.9650\n",
      "18333/18333 [==============================] - 9s 492us/sample - loss: 0.1508 - acc: 0.9609\n",
      "[CV] ..................................... n_neurons=49, total= 1.6min\n",
      "[CV] n_neurons=49 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 14s 372us/sample - loss: 0.3996 - acc: 0.8892 - val_loss: 0.2346 - val_acc: 0.9342\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 8s 229us/sample - loss: 0.2154 - acc: 0.9384 - val_loss: 0.1797 - val_acc: 0.9520\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 9s 242us/sample - loss: 0.1655 - acc: 0.9521 - val_loss: 0.1517 - val_acc: 0.9578\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 9s 244us/sample - loss: 0.1369 - acc: 0.9596 - val_loss: 0.1381 - val_acc: 0.9628\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 8s 226us/sample - loss: 0.1176 - acc: 0.9658 - val_loss: 0.1322 - val_acc: 0.9646\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 255us/sample - loss: 0.1047 - acc: 0.9696 - val_loss: 0.1270 - val_acc: 0.9642\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 293us/sample - loss: 0.0936 - acc: 0.9723 - val_loss: 0.1228 - val_acc: 0.9656\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 314us/sample - loss: 0.0860 - acc: 0.9750 - val_loss: 0.1289 - val_acc: 0.9644\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 10s 276us/sample - loss: 0.0779 - acc: 0.9766 - val_loss: 0.1173 - val_acc: 0.9656\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 10s 285us/sample - loss: 0.0719 - acc: 0.9792 - val_loss: 0.1284 - val_acc: 0.9656\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 11s 306us/sample - loss: 0.0667 - acc: 0.9819 - val_loss: 0.1214 - val_acc: 0.9656\n",
      "18333/18333 [==============================] - 3s 157us/sample - loss: 0.1435 - acc: 0.9643\n",
      "[CV] ..................................... n_neurons=49, total= 2.2min\n",
      "[CV] n_neurons=50 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 13s 354us/sample - loss: 0.3889 - acc: 0.8904 - val_loss: 0.2271 - val_acc: 0.9354\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 8s 224us/sample - loss: 0.2080 - acc: 0.9397 - val_loss: 0.1815 - val_acc: 0.9482\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 9s 252us/sample - loss: 0.1613 - acc: 0.9531 - val_loss: 0.1467 - val_acc: 0.9588\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 9s 238us/sample - loss: 0.1326 - acc: 0.9612 - val_loss: 0.1335 - val_acc: 0.9626\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 8s 225us/sample - loss: 0.1119 - acc: 0.9674 - val_loss: 0.1274 - val_acc: 0.9648\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 9s 233us/sample - loss: 0.0988 - acc: 0.9719 - val_loss: 0.1299 - val_acc: 0.9626\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 8s 228us/sample - loss: 0.0884 - acc: 0.9752 - val_loss: 0.1208 - val_acc: 0.9650\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 8s 229us/sample - loss: 0.0793 - acc: 0.9780 - val_loss: 0.1194 - val_acc: 0.9662\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 10s 283us/sample - loss: 0.0735 - acc: 0.9791 - val_loss: 0.1213 - val_acc: 0.9656\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 10s 263us/sample - loss: 0.0680 - acc: 0.9807 - val_loss: 0.1169 - val_acc: 0.9684\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 8s 224us/sample - loss: 0.0614 - acc: 0.9829 - val_loss: 0.1197 - val_acc: 0.9666\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 8s 220us/sample - loss: 0.0576 - acc: 0.9836 - val_loss: 0.1200 - val_acc: 0.9662\n",
      "18334/18334 [==============================] - 2s 122us/sample - loss: 0.1429 - acc: 0.9632\n",
      "[CV] ..................................... n_neurons=50, total= 2.0min\n",
      "[CV] n_neurons=50 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 12s 324us/sample - loss: 0.3682 - acc: 0.8968 - val_loss: 0.2252 - val_acc: 0.9340\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 233us/sample - loss: 0.1981 - acc: 0.9426 - val_loss: 0.1692 - val_acc: 0.9508\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 284us/sample - loss: 0.1530 - acc: 0.9560 - val_loss: 0.1450 - val_acc: 0.9590\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 268us/sample - loss: 0.1280 - acc: 0.9630 - val_loss: 0.1328 - val_acc: 0.9614\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 298us/sample - loss: 0.1104 - acc: 0.9679 - val_loss: 0.1236 - val_acc: 0.9654\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 283us/sample - loss: 0.0971 - acc: 0.9720 - val_loss: 0.1207 - val_acc: 0.9644\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 311us/sample - loss: 0.0867 - acc: 0.9750 - val_loss: 0.1287 - val_acc: 0.9640\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 295us/sample - loss: 0.0797 - acc: 0.9770 - val_loss: 0.1262 - val_acc: 0.9650\n",
      "18333/18333 [==============================] - 3s 169us/sample - loss: 0.1471 - acc: 0.9601\n",
      "[CV] ..................................... n_neurons=50, total= 1.5min\n",
      "[CV] n_neurons=50 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 408us/sample - loss: 0.3813 - acc: 0.8924 - val_loss: 0.2162 - val_acc: 0.9386\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.2043 - acc: 0.9410 - val_loss: 0.1751 - val_acc: 0.9496\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.1572 - acc: 0.9542 - val_loss: 0.1520 - val_acc: 0.9578\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 288us/sample - loss: 0.1297 - acc: 0.9619 - val_loss: 0.1320 - val_acc: 0.9616\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 301us/sample - loss: 0.1132 - acc: 0.9662 - val_loss: 0.1322 - val_acc: 0.9612\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.0999 - acc: 0.9710 - val_loss: 0.1287 - val_acc: 0.9654\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.0898 - acc: 0.9741 - val_loss: 0.1280 - val_acc: 0.9624\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 13s 344us/sample - loss: 0.0825 - acc: 0.9761 - val_loss: 0.1139 - val_acc: 0.9684\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 297us/sample - loss: 0.0752 - acc: 0.9783 - val_loss: 0.1459 - val_acc: 0.9560\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 293us/sample - loss: 0.0693 - acc: 0.9800 - val_loss: 0.1335 - val_acc: 0.9608\n",
      "18333/18333 [==============================] - 3s 167us/sample - loss: 0.1566 - acc: 0.9589\n",
      "[CV] ..................................... n_neurons=50, total= 2.1min\n",
      "[CV] n_neurons=51 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 13s 362us/sample - loss: 0.3760 - acc: 0.8954 - val_loss: 0.2194 - val_acc: 0.9354\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 10s 281us/sample - loss: 0.2024 - acc: 0.9406 - val_loss: 0.1749 - val_acc: 0.9504\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 10s 279us/sample - loss: 0.1594 - acc: 0.9536 - val_loss: 0.1542 - val_acc: 0.9588\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 295us/sample - loss: 0.1333 - acc: 0.9605 - val_loss: 0.1382 - val_acc: 0.9594\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 10s 278us/sample - loss: 0.1153 - acc: 0.9661 - val_loss: 0.1339 - val_acc: 0.9618\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 10s 284us/sample - loss: 0.1016 - acc: 0.9707 - val_loss: 0.1401 - val_acc: 0.9628\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 313us/sample - loss: 0.0907 - acc: 0.9741 - val_loss: 0.1290 - val_acc: 0.9634\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 10s 284us/sample - loss: 0.0821 - acc: 0.9756 - val_loss: 0.1263 - val_acc: 0.9628\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 12s 330us/sample - loss: 0.0755 - acc: 0.9787 - val_loss: 0.1268 - val_acc: 0.9630\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 12s 315us/sample - loss: 0.0689 - acc: 0.9802 - val_loss: 0.1296 - val_acc: 0.9648\n",
      "18334/18334 [==============================] - 3s 166us/sample - loss: 0.1438 - acc: 0.9625\n",
      "[CV] ..................................... n_neurons=51, total= 2.0min\n",
      "[CV] n_neurons=51 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 14s 384us/sample - loss: 0.3741 - acc: 0.8952 - val_loss: 0.2158 - val_acc: 0.9406\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.2037 - acc: 0.9408 - val_loss: 0.1771 - val_acc: 0.9494\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 307us/sample - loss: 0.1595 - acc: 0.9533 - val_loss: 0.1549 - val_acc: 0.9524\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 312us/sample - loss: 0.1329 - acc: 0.9611 - val_loss: 0.1263 - val_acc: 0.9640\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.1137 - acc: 0.9666 - val_loss: 0.1249 - val_acc: 0.9630\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 285us/sample - loss: 0.0981 - acc: 0.9721 - val_loss: 0.1132 - val_acc: 0.9664\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 307us/sample - loss: 0.0868 - acc: 0.9746 - val_loss: 0.1080 - val_acc: 0.9680\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 325us/sample - loss: 0.0773 - acc: 0.9770 - val_loss: 0.1033 - val_acc: 0.9698\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 296us/sample - loss: 0.0705 - acc: 0.9793 - val_loss: 0.1033 - val_acc: 0.9704\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 291us/sample - loss: 0.0641 - acc: 0.9820 - val_loss: 0.1099 - val_acc: 0.9686\n",
      "18333/18333 [==============================] - 3s 158us/sample - loss: 0.1497 - acc: 0.9609\n",
      "[CV] ..................................... n_neurons=51, total= 2.1min\n",
      "[CV] n_neurons=51 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 398us/sample - loss: 0.3721 - acc: 0.8966 - val_loss: 0.2138 - val_acc: 0.9398\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 288us/sample - loss: 0.1970 - acc: 0.9425 - val_loss: 0.1616 - val_acc: 0.9546\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 303us/sample - loss: 0.1502 - acc: 0.9560 - val_loss: 0.1370 - val_acc: 0.9622\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 285us/sample - loss: 0.1221 - acc: 0.9652 - val_loss: 0.1201 - val_acc: 0.9640\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 284us/sample - loss: 0.1037 - acc: 0.9702 - val_loss: 0.1154 - val_acc: 0.9680\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 283us/sample - loss: 0.0908 - acc: 0.9740 - val_loss: 0.1141 - val_acc: 0.9654\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.0810 - acc: 0.9769 - val_loss: 0.1038 - val_acc: 0.9700\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.0726 - acc: 0.9796 - val_loss: 0.1037 - val_acc: 0.9682\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.0668 - acc: 0.9811 - val_loss: 0.0987 - val_acc: 0.9726\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 296us/sample - loss: 0.0614 - acc: 0.9828 - val_loss: 0.1051 - val_acc: 0.9682\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 12s 322us/sample - loss: 0.0553 - acc: 0.9841 - val_loss: 0.1045 - val_acc: 0.9720\n",
      "18333/18333 [==============================] - 3s 156us/sample - loss: 0.1388 - acc: 0.9679\n",
      "[CV] ..................................... n_neurons=51, total= 2.2min\n",
      "[CV] n_neurons=52 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 14s 395us/sample - loss: 0.3570 - acc: 0.8996 - val_loss: 0.2194 - val_acc: 0.9386\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 11s 293us/sample - loss: 0.1913 - acc: 0.9444 - val_loss: 0.1648 - val_acc: 0.9528\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 288us/sample - loss: 0.1486 - acc: 0.9565 - val_loss: 0.1381 - val_acc: 0.9600\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 297us/sample - loss: 0.1224 - acc: 0.9637 - val_loss: 0.1411 - val_acc: 0.9626\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 12s 323us/sample - loss: 0.1058 - acc: 0.9685 - val_loss: 0.1289 - val_acc: 0.9634\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 12s 314us/sample - loss: 0.0943 - acc: 0.9726 - val_loss: 0.1236 - val_acc: 0.9664\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 306us/sample - loss: 0.0855 - acc: 0.9750 - val_loss: 0.1303 - val_acc: 0.9630\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 12s 327us/sample - loss: 0.0769 - acc: 0.9772 - val_loss: 0.1214 - val_acc: 0.9674\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 12s 318us/sample - loss: 0.0691 - acc: 0.9802 - val_loss: 0.1419 - val_acc: 0.9626\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 12s 325us/sample - loss: 0.0637 - acc: 0.9817 - val_loss: 0.1218 - val_acc: 0.9690\n",
      "18334/18334 [==============================] - 3s 181us/sample - loss: 0.1398 - acc: 0.9641\n",
      "[CV] ..................................... n_neurons=52, total= 2.1min\n",
      "[CV] n_neurons=52 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 403us/sample - loss: 0.3605 - acc: 0.8997 - val_loss: 0.2169 - val_acc: 0.9376\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 307us/sample - loss: 0.1943 - acc: 0.9440 - val_loss: 0.1858 - val_acc: 0.9462\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 331us/sample - loss: 0.1486 - acc: 0.9569 - val_loss: 0.1375 - val_acc: 0.9632\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 347us/sample - loss: 0.1235 - acc: 0.9641 - val_loss: 0.1267 - val_acc: 0.9618\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.1060 - acc: 0.9686 - val_loss: 0.1216 - val_acc: 0.9648\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.0925 - acc: 0.9736 - val_loss: 0.1185 - val_acc: 0.9656\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 10s 267us/sample - loss: 0.0831 - acc: 0.9760 - val_loss: 0.1170 - val_acc: 0.9664\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 10s 275us/sample - loss: 0.0758 - acc: 0.9789 - val_loss: 0.1196 - val_acc: 0.9684\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 303us/sample - loss: 0.0691 - acc: 0.9807 - val_loss: 0.1228 - val_acc: 0.9688\n",
      "18333/18333 [==============================] - 3s 157us/sample - loss: 0.1353 - acc: 0.9643\n",
      "[CV] ..................................... n_neurons=52, total= 1.9min\n",
      "[CV] n_neurons=52 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 13s 357us/sample - loss: 0.3839 - acc: 0.8930 - val_loss: 0.2188 - val_acc: 0.9372\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 235us/sample - loss: 0.1999 - acc: 0.9426 - val_loss: 0.1571 - val_acc: 0.9568\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 8s 229us/sample - loss: 0.1534 - acc: 0.9548 - val_loss: 0.1406 - val_acc: 0.9612\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 8s 230us/sample - loss: 0.1277 - acc: 0.9632 - val_loss: 0.1330 - val_acc: 0.9626\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 9s 232us/sample - loss: 0.1109 - acc: 0.9684 - val_loss: 0.1215 - val_acc: 0.9654\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 241us/sample - loss: 0.0993 - acc: 0.9712 - val_loss: 0.1214 - val_acc: 0.9672\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 9s 236us/sample - loss: 0.0894 - acc: 0.9748 - val_loss: 0.1128 - val_acc: 0.9682\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 9s 251us/sample - loss: 0.0811 - acc: 0.9765 - val_loss: 0.1196 - val_acc: 0.9662\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 315us/sample - loss: 0.0737 - acc: 0.9787 - val_loss: 0.1214 - val_acc: 0.9688\n",
      "18333/18333 [==============================] - 3s 166us/sample - loss: 0.1508 - acc: 0.9619\n",
      "[CV] ..................................... n_neurons=52, total= 1.6min\n",
      "[CV] n_neurons=53 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 13s 354us/sample - loss: 0.3796 - acc: 0.8926 - val_loss: 0.2216 - val_acc: 0.9370\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 9s 243us/sample - loss: 0.2009 - acc: 0.9413 - val_loss: 0.1765 - val_acc: 0.9498\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 9s 243us/sample - loss: 0.1555 - acc: 0.9555 - val_loss: 0.1538 - val_acc: 0.9600\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 10s 271us/sample - loss: 0.1298 - acc: 0.9626 - val_loss: 0.1416 - val_acc: 0.9592\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 12s 326us/sample - loss: 0.1133 - acc: 0.9675 - val_loss: 0.1311 - val_acc: 0.9646\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 307us/sample - loss: 0.0992 - acc: 0.9716 - val_loss: 0.1343 - val_acc: 0.9616\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 10s 268us/sample - loss: 0.0887 - acc: 0.9754 - val_loss: 0.1267 - val_acc: 0.9662\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 9s 240us/sample - loss: 0.0797 - acc: 0.9777 - val_loss: 0.1202 - val_acc: 0.9684\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 9s 245us/sample - loss: 0.0737 - acc: 0.9795 - val_loss: 0.1153 - val_acc: 0.9694\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 13s 357us/sample - loss: 0.0666 - acc: 0.9813 - val_loss: 0.1208 - val_acc: 0.9694\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 16s 429us/sample - loss: 0.0618 - acc: 0.9823 - val_loss: 0.1210 - val_acc: 0.9678\n",
      "18334/18334 [==============================] - 3s 144us/sample - loss: 0.1441 - acc: 0.9644\n",
      "[CV] ..................................... n_neurons=53, total= 2.1min\n",
      "[CV] n_neurons=53 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 406us/sample - loss: 0.3673 - acc: 0.8963 - val_loss: 0.2343 - val_acc: 0.9322\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 242us/sample - loss: 0.2061 - acc: 0.9402 - val_loss: 0.1782 - val_acc: 0.9520\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 265us/sample - loss: 0.1612 - acc: 0.9537 - val_loss: 0.1535 - val_acc: 0.9580\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 8s 229us/sample - loss: 0.1359 - acc: 0.9607 - val_loss: 0.1395 - val_acc: 0.9582\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 283us/sample - loss: 0.1180 - acc: 0.9656 - val_loss: 0.1395 - val_acc: 0.9586\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 248us/sample - loss: 0.1027 - acc: 0.9701 - val_loss: 0.1294 - val_acc: 0.9626\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 9s 239us/sample - loss: 0.0915 - acc: 0.9736 - val_loss: 0.1270 - val_acc: 0.9622\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 9s 242us/sample - loss: 0.0827 - acc: 0.9754 - val_loss: 0.1260 - val_acc: 0.9618\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 9s 242us/sample - loss: 0.0755 - acc: 0.9777 - val_loss: 0.1186 - val_acc: 0.9652\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 10s 284us/sample - loss: 0.0690 - acc: 0.9800 - val_loss: 0.1186 - val_acc: 0.9652\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 12s 316us/sample - loss: 0.0631 - acc: 0.9819 - val_loss: 0.1225 - val_acc: 0.9652\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.0587 - acc: 0.9828 - val_loss: 0.1238 - val_acc: 0.9668\n",
      "18333/18333 [==============================] - 3s 151us/sample - loss: 0.1524 - acc: 0.9618\n",
      "[CV] ..................................... n_neurons=53, total= 2.2min\n",
      "[CV] n_neurons=53 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 13s 341us/sample - loss: 0.3743 - acc: 0.8953 - val_loss: 0.2118 - val_acc: 0.9368\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 240us/sample - loss: 0.2020 - acc: 0.9407 - val_loss: 0.1609 - val_acc: 0.9534\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 9s 242us/sample - loss: 0.1549 - acc: 0.9545 - val_loss: 0.1408 - val_acc: 0.9608\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 9s 235us/sample - loss: 0.1288 - acc: 0.9618 - val_loss: 0.1287 - val_acc: 0.9620\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 9s 238us/sample - loss: 0.1094 - acc: 0.9677 - val_loss: 0.1218 - val_acc: 0.9674\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 9s 236us/sample - loss: 0.0972 - acc: 0.9717 - val_loss: 0.1206 - val_acc: 0.9648\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 9s 235us/sample - loss: 0.0868 - acc: 0.9738 - val_loss: 0.1107 - val_acc: 0.9694\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 9s 242us/sample - loss: 0.0780 - acc: 0.9770 - val_loss: 0.1184 - val_acc: 0.9668\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 9s 239us/sample - loss: 0.0708 - acc: 0.9796 - val_loss: 0.1163 - val_acc: 0.9672\n",
      "18333/18333 [==============================] - 2s 134us/sample - loss: 0.1380 - acc: 0.9641\n",
      "[CV] ..................................... n_neurons=53, total= 1.5min\n",
      "[CV] n_neurons=54 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 12s 330us/sample - loss: 0.3713 - acc: 0.8954 - val_loss: 0.2265 - val_acc: 0.9336\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 9s 253us/sample - loss: 0.2016 - acc: 0.9409 - val_loss: 0.1749 - val_acc: 0.9500\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 295us/sample - loss: 0.1571 - acc: 0.9537 - val_loss: 0.1538 - val_acc: 0.9550\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 9s 245us/sample - loss: 0.1301 - acc: 0.9620 - val_loss: 0.1372 - val_acc: 0.9606\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 9s 243us/sample - loss: 0.1122 - acc: 0.9682 - val_loss: 0.1243 - val_acc: 0.9628\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 291us/sample - loss: 0.0974 - acc: 0.9712 - val_loss: 0.1234 - val_acc: 0.9644\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 12s 322us/sample - loss: 0.0875 - acc: 0.9749 - val_loss: 0.1228 - val_acc: 0.9636\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 12s 322us/sample - loss: 0.0796 - acc: 0.9777 - val_loss: 0.1322 - val_acc: 0.9644\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 11s 313us/sample - loss: 0.0708 - acc: 0.9789 - val_loss: 0.1189 - val_acc: 0.9676\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 11s 305us/sample - loss: 0.0667 - acc: 0.9810 - val_loss: 0.1158 - val_acc: 0.9684\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 9s 237us/sample - loss: 0.0602 - acc: 0.9822 - val_loss: 0.1224 - val_acc: 0.9698\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 9s 251us/sample - loss: 0.0559 - acc: 0.9840 - val_loss: 0.1291 - val_acc: 0.9662\n",
      "18334/18334 [==============================] - 2s 131us/sample - loss: 0.1560 - acc: 0.9605\n",
      "[CV] ..................................... n_neurons=54, total= 2.2min\n",
      "[CV] n_neurons=54 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 49s 1ms/sample - loss: 0.3634 - acc: 0.8972 - val_loss: 0.2103 - val_acc: 0.9404\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 10s 281us/sample - loss: 0.1935 - acc: 0.9432 - val_loss: 0.1605 - val_acc: 0.9540\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 260us/sample - loss: 0.1468 - acc: 0.9573 - val_loss: 0.1373 - val_acc: 0.9600\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 9s 239us/sample - loss: 0.1206 - acc: 0.9650 - val_loss: 0.1294 - val_acc: 0.9610\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 325us/sample - loss: 0.1038 - acc: 0.9688 - val_loss: 0.1197 - val_acc: 0.9630\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.0891 - acc: 0.9740 - val_loss: 0.1138 - val_acc: 0.9642\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 338us/sample - loss: 0.0792 - acc: 0.9763 - val_loss: 0.1129 - val_acc: 0.9658\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 316us/sample - loss: 0.0721 - acc: 0.9786 - val_loss: 0.1163 - val_acc: 0.9660\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.0642 - acc: 0.9810 - val_loss: 0.1172 - val_acc: 0.9682\n",
      "18333/18333 [==============================] - 3s 171us/sample - loss: 0.1359 - acc: 0.9643\n",
      "[CV] ..................................... n_neurons=54, total= 2.4min\n",
      "[CV] n_neurons=54 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 432us/sample - loss: 0.3685 - acc: 0.8974 - val_loss: 0.2178 - val_acc: 0.9380\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 317us/sample - loss: 0.1987 - acc: 0.9419 - val_loss: 0.1607 - val_acc: 0.9534\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 318us/sample - loss: 0.1534 - acc: 0.9561 - val_loss: 0.1397 - val_acc: 0.9618\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 312us/sample - loss: 0.1263 - acc: 0.9635 - val_loss: 0.1287 - val_acc: 0.9646\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 305us/sample - loss: 0.1074 - acc: 0.9693 - val_loss: 0.1187 - val_acc: 0.9658\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 306us/sample - loss: 0.0931 - acc: 0.9736 - val_loss: 0.1221 - val_acc: 0.9668\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 311us/sample - loss: 0.0843 - acc: 0.9759 - val_loss: 0.1250 - val_acc: 0.9658\n",
      "18333/18333 [==============================] - 3s 185us/sample - loss: 0.1402 - acc: 0.9626\n",
      "[CV] ..................................... n_neurons=54, total= 1.6min\n",
      "[CV] n_neurons=55 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 15s 410us/sample - loss: 0.3721 - acc: 0.8957 - val_loss: 0.2159 - val_acc: 0.9362\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 12s 317us/sample - loss: 0.2047 - acc: 0.9403 - val_loss: 0.1711 - val_acc: 0.9498\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 307us/sample - loss: 0.1563 - acc: 0.9535 - val_loss: 0.1515 - val_acc: 0.9562\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 309us/sample - loss: 0.1277 - acc: 0.9626 - val_loss: 0.1316 - val_acc: 0.9598\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 12s 322us/sample - loss: 0.1089 - acc: 0.9681 - val_loss: 0.1210 - val_acc: 0.9658\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 12s 319us/sample - loss: 0.0940 - acc: 0.9734 - val_loss: 0.1195 - val_acc: 0.9650\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 306us/sample - loss: 0.0833 - acc: 0.9765 - val_loss: 0.1219 - val_acc: 0.9640\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 12s 327us/sample - loss: 0.0760 - acc: 0.9779 - val_loss: 0.1136 - val_acc: 0.9662\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 11s 313us/sample - loss: 0.0686 - acc: 0.9806 - val_loss: 0.1154 - val_acc: 0.9656\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 11s 313us/sample - loss: 0.0620 - acc: 0.9830 - val_loss: 0.1207 - val_acc: 0.9658\n",
      "18334/18334 [==============================] - 3s 166us/sample - loss: 0.1389 - acc: 0.9637\n",
      "[CV] ..................................... n_neurons=55, total= 2.2min\n",
      "[CV] n_neurons=55 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 14s 394us/sample - loss: 0.3589 - acc: 0.8989 - val_loss: 0.2082 - val_acc: 0.9406\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.1888 - acc: 0.9455 - val_loss: 0.1710 - val_acc: 0.9522\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 338us/sample - loss: 0.1451 - acc: 0.9588 - val_loss: 0.1432 - val_acc: 0.9598\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 328us/sample - loss: 0.1213 - acc: 0.9641 - val_loss: 0.1347 - val_acc: 0.9594\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 322us/sample - loss: 0.1039 - acc: 0.9694 - val_loss: 0.1279 - val_acc: 0.9610\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 327us/sample - loss: 0.0911 - acc: 0.9728 - val_loss: 0.1202 - val_acc: 0.9652\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 319us/sample - loss: 0.0799 - acc: 0.9765 - val_loss: 0.1140 - val_acc: 0.9650\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 317us/sample - loss: 0.0721 - acc: 0.9789 - val_loss: 0.1212 - val_acc: 0.9662\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 307us/sample - loss: 0.0656 - acc: 0.9812 - val_loss: 0.1071 - val_acc: 0.9692\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.0585 - acc: 0.9831 - val_loss: 0.1129 - val_acc: 0.9680\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 11s 312us/sample - loss: 0.0543 - acc: 0.9841 - val_loss: 0.1156 - val_acc: 0.9690\n",
      "18333/18333 [==============================] - 3s 158us/sample - loss: 0.1414 - acc: 0.9642\n",
      "[CV] ..................................... n_neurons=55, total= 2.3min\n",
      "[CV] n_neurons=55 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 410us/sample - loss: 0.3693 - acc: 0.8983 - val_loss: 0.2111 - val_acc: 0.9418\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 336us/sample - loss: 0.2007 - acc: 0.9429 - val_loss: 0.1674 - val_acc: 0.9534\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 321us/sample - loss: 0.1533 - acc: 0.9563 - val_loss: 0.1498 - val_acc: 0.9588\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 306us/sample - loss: 0.1274 - acc: 0.9635 - val_loss: 0.1376 - val_acc: 0.9618\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 332us/sample - loss: 0.1095 - acc: 0.9682 - val_loss: 0.1237 - val_acc: 0.9640\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 315us/sample - loss: 0.0957 - acc: 0.9721 - val_loss: 0.1223 - val_acc: 0.9640\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 309us/sample - loss: 0.0850 - acc: 0.9768 - val_loss: 0.1131 - val_acc: 0.9692\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 322us/sample - loss: 0.0774 - acc: 0.9778 - val_loss: 0.1171 - val_acc: 0.9690\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 13s 349us/sample - loss: 0.0701 - acc: 0.9803 - val_loss: 0.1181 - val_acc: 0.9692\n",
      "18333/18333 [==============================] - 3s 184us/sample - loss: 0.1372 - acc: 0.9641\n",
      "[CV] ..................................... n_neurons=55, total= 2.0min\n",
      "[CV] n_neurons=56 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 16s 423us/sample - loss: 0.3595 - acc: 0.8999 - val_loss: 0.2064 - val_acc: 0.9426\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 11s 294us/sample - loss: 0.1868 - acc: 0.9449 - val_loss: 0.1481 - val_acc: 0.9562\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 306us/sample - loss: 0.1448 - acc: 0.9574 - val_loss: 0.1368 - val_acc: 0.9622\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 307us/sample - loss: 0.1192 - acc: 0.9654 - val_loss: 0.1163 - val_acc: 0.9654\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 12s 322us/sample - loss: 0.1032 - acc: 0.9704 - val_loss: 0.1123 - val_acc: 0.9678\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 13s 345us/sample - loss: 0.0900 - acc: 0.9739 - val_loss: 0.1103 - val_acc: 0.9674\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 12s 322us/sample - loss: 0.0814 - acc: 0.9761 - val_loss: 0.1059 - val_acc: 0.9706\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 12s 328us/sample - loss: 0.0731 - acc: 0.9787 - val_loss: 0.1060 - val_acc: 0.9676\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 12s 328us/sample - loss: 0.0665 - acc: 0.9819 - val_loss: 0.1111 - val_acc: 0.9680\n",
      "18334/18334 [==============================] - 3s 171us/sample - loss: 0.1374 - acc: 0.9650\n",
      "[CV] ..................................... n_neurons=56, total= 2.0min\n",
      "[CV] n_neurons=56 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 406us/sample - loss: 0.3661 - acc: 0.8968 - val_loss: 0.2146 - val_acc: 0.9394\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.1956 - acc: 0.9442 - val_loss: 0.1603 - val_acc: 0.9546\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 319us/sample - loss: 0.1507 - acc: 0.9572 - val_loss: 0.1464 - val_acc: 0.9552\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 311us/sample - loss: 0.1240 - acc: 0.9644 - val_loss: 0.1217 - val_acc: 0.9658\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 321us/sample - loss: 0.1056 - acc: 0.9695 - val_loss: 0.1276 - val_acc: 0.9626\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 318us/sample - loss: 0.0937 - acc: 0.9731 - val_loss: 0.1115 - val_acc: 0.9666\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 338us/sample - loss: 0.0814 - acc: 0.9760 - val_loss: 0.1096 - val_acc: 0.9686\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 332us/sample - loss: 0.0734 - acc: 0.9793 - val_loss: 0.1160 - val_acc: 0.9660\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 335us/sample - loss: 0.0668 - acc: 0.9808 - val_loss: 0.1058 - val_acc: 0.9706\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 13s 349us/sample - loss: 0.0600 - acc: 0.9833 - val_loss: 0.1116 - val_acc: 0.9696\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 12s 333us/sample - loss: 0.0553 - acc: 0.9842 - val_loss: 0.1113 - val_acc: 0.9704\n",
      "18333/18333 [==============================] - 3s 188us/sample - loss: 0.1406 - acc: 0.9644\n",
      "[CV] ..................................... n_neurons=56, total= 2.4min\n",
      "[CV] n_neurons=56 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 419us/sample - loss: 0.3692 - acc: 0.8975 - val_loss: 0.2284 - val_acc: 0.9342\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 324us/sample - loss: 0.2012 - acc: 0.9419 - val_loss: 0.1672 - val_acc: 0.9540\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 322us/sample - loss: 0.1544 - acc: 0.9545 - val_loss: 0.1396 - val_acc: 0.9616\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 318us/sample - loss: 0.1280 - acc: 0.9628 - val_loss: 0.1290 - val_acc: 0.9642\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 313us/sample - loss: 0.1092 - acc: 0.9684 - val_loss: 0.1191 - val_acc: 0.9654\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 342us/sample - loss: 0.0972 - acc: 0.9724 - val_loss: 0.1137 - val_acc: 0.9670\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 340us/sample - loss: 0.0868 - acc: 0.9753 - val_loss: 0.1189 - val_acc: 0.9646\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 13s 345us/sample - loss: 0.0796 - acc: 0.9781 - val_loss: 0.1168 - val_acc: 0.9686\n",
      "18333/18333 [==============================] - 4s 213us/sample - loss: 0.1378 - acc: 0.9631\n",
      "[CV] ..................................... n_neurons=56, total= 1.8min\n",
      "[CV] n_neurons=57 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 17s 467us/sample - loss: 0.3688 - acc: 0.8964 - val_loss: 0.2085 - val_acc: 0.9424\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 12s 321us/sample - loss: 0.1947 - acc: 0.9440 - val_loss: 0.1658 - val_acc: 0.9542\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 12s 330us/sample - loss: 0.1505 - acc: 0.9573 - val_loss: 0.1397 - val_acc: 0.9618\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 12s 322us/sample - loss: 0.1239 - acc: 0.9646 - val_loss: 0.1258 - val_acc: 0.9638\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 12s 315us/sample - loss: 0.1076 - acc: 0.9690 - val_loss: 0.1321 - val_acc: 0.9624\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 12s 329us/sample - loss: 0.0939 - acc: 0.9731 - val_loss: 0.1191 - val_acc: 0.9678\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 305us/sample - loss: 0.0842 - acc: 0.9766 - val_loss: 0.1173 - val_acc: 0.9656\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 12s 324us/sample - loss: 0.0763 - acc: 0.9781 - val_loss: 0.1149 - val_acc: 0.9672\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 12s 321us/sample - loss: 0.0687 - acc: 0.9803 - val_loss: 0.1153 - val_acc: 0.9668\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 12s 332us/sample - loss: 0.0622 - acc: 0.9821 - val_loss: 0.1090 - val_acc: 0.9694\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 12s 328us/sample - loss: 0.0570 - acc: 0.9837 - val_loss: 0.1236 - val_acc: 0.9680\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 12s 326us/sample - loss: 0.0522 - acc: 0.9855 - val_loss: 0.1185 - val_acc: 0.9678\n",
      "18334/18334 [==============================] - 3s 172us/sample - loss: 0.1505 - acc: 0.9631\n",
      "[CV] ..................................... n_neurons=57, total= 2.6min\n",
      "[CV] n_neurons=57 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 430us/sample - loss: 0.3623 - acc: 0.9001 - val_loss: 0.2199 - val_acc: 0.9364\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 319us/sample - loss: 0.1945 - acc: 0.9442 - val_loss: 0.1653 - val_acc: 0.9512\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 13s 341us/sample - loss: 0.1475 - acc: 0.9571 - val_loss: 0.1519 - val_acc: 0.9562\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 338us/sample - loss: 0.1197 - acc: 0.9642 - val_loss: 0.1332 - val_acc: 0.9612\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 321us/sample - loss: 0.1035 - acc: 0.9695 - val_loss: 0.1252 - val_acc: 0.9638\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 341us/sample - loss: 0.0902 - acc: 0.9738 - val_loss: 0.1212 - val_acc: 0.9642\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 332us/sample - loss: 0.0803 - acc: 0.9768 - val_loss: 0.1172 - val_acc: 0.9658\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 325us/sample - loss: 0.0715 - acc: 0.9793 - val_loss: 0.1199 - val_acc: 0.9668\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 338us/sample - loss: 0.0645 - acc: 0.9811 - val_loss: 0.1251 - val_acc: 0.9668\n",
      "18333/18333 [==============================] - 3s 169us/sample - loss: 0.1534 - acc: 0.9614\n",
      "[CV] ..................................... n_neurons=57, total= 2.0min\n",
      "[CV] n_neurons=57 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 17s 465us/sample - loss: 0.3692 - acc: 0.8973 - val_loss: 0.2130 - val_acc: 0.9370\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 13s 363us/sample - loss: 0.1930 - acc: 0.9434 - val_loss: 0.1578 - val_acc: 0.9558\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 13s 343us/sample - loss: 0.1482 - acc: 0.9563 - val_loss: 0.1388 - val_acc: 0.9608\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 332us/sample - loss: 0.1226 - acc: 0.9640 - val_loss: 0.1376 - val_acc: 0.9630\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.1035 - acc: 0.9698 - val_loss: 0.1208 - val_acc: 0.9660\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 319us/sample - loss: 0.0902 - acc: 0.9732 - val_loss: 0.1187 - val_acc: 0.9680\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 13s 342us/sample - loss: 0.0796 - acc: 0.9765 - val_loss: 0.1156 - val_acc: 0.9668\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 323us/sample - loss: 0.0714 - acc: 0.9794 - val_loss: 0.1119 - val_acc: 0.9696\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 13s 348us/sample - loss: 0.0640 - acc: 0.9818 - val_loss: 0.1097 - val_acc: 0.9704\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 13s 364us/sample - loss: 0.0585 - acc: 0.9843 - val_loss: 0.1151 - val_acc: 0.9684\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 13s 364us/sample - loss: 0.0535 - acc: 0.9850 - val_loss: 0.1064 - val_acc: 0.9724\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 13s 342us/sample - loss: 0.0489 - acc: 0.9862 - val_loss: 0.1105 - val_acc: 0.9722\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 12s 324us/sample - loss: 0.0458 - acc: 0.9875 - val_loss: 0.1192 - val_acc: 0.9700\n",
      "18333/18333 [==============================] - 3s 185us/sample - loss: 0.1492 - acc: 0.9642\n",
      "[CV] ..................................... n_neurons=57, total= 3.0min\n",
      "[CV] n_neurons=58 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 16s 428us/sample - loss: 0.3669 - acc: 0.8955 - val_loss: 0.2292 - val_acc: 0.9350\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 12s 340us/sample - loss: 0.2021 - acc: 0.9406 - val_loss: 0.1697 - val_acc: 0.9502\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 13s 346us/sample - loss: 0.1516 - acc: 0.9564 - val_loss: 0.1469 - val_acc: 0.9576\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 13s 341us/sample - loss: 0.1225 - acc: 0.9641 - val_loss: 0.1370 - val_acc: 0.9584\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 11s 301us/sample - loss: 0.1029 - acc: 0.9696 - val_loss: 0.1274 - val_acc: 0.9632\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 10s 260us/sample - loss: 0.0909 - acc: 0.9736 - val_loss: 0.1262 - val_acc: 0.9644\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 12s 323us/sample - loss: 0.0802 - acc: 0.9775 - val_loss: 0.1176 - val_acc: 0.9668\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 12s 340us/sample - loss: 0.0725 - acc: 0.9799 - val_loss: 0.1189 - val_acc: 0.9648\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 13s 348us/sample - loss: 0.0659 - acc: 0.9810 - val_loss: 0.1145 - val_acc: 0.9658\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 11s 308us/sample - loss: 0.0597 - acc: 0.9832 - val_loss: 0.1189 - val_acc: 0.9664\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 9s 258us/sample - loss: 0.0555 - acc: 0.9850 - val_loss: 0.1243 - val_acc: 0.9676\n",
      "18334/18334 [==============================] - 3s 140us/sample - loss: 0.1360 - acc: 0.9648\n",
      "[CV] ..................................... n_neurons=58, total= 2.3min\n",
      "[CV] n_neurons=58 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 13s 354us/sample - loss: 0.3625 - acc: 0.8984 - val_loss: 0.2326 - val_acc: 0.9322\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 258us/sample - loss: 0.1975 - acc: 0.9431 - val_loss: 0.1717 - val_acc: 0.9534\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 264us/sample - loss: 0.1525 - acc: 0.9563 - val_loss: 0.1554 - val_acc: 0.9564\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 262us/sample - loss: 0.1258 - acc: 0.9638 - val_loss: 0.1252 - val_acc: 0.9650\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 314us/sample - loss: 0.1064 - acc: 0.9689 - val_loss: 0.1246 - val_acc: 0.9618\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.0919 - acc: 0.9731 - val_loss: 0.1215 - val_acc: 0.9648\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 338us/sample - loss: 0.0809 - acc: 0.9759 - val_loss: 0.1157 - val_acc: 0.9680\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 332us/sample - loss: 0.0738 - acc: 0.9792 - val_loss: 0.1136 - val_acc: 0.9680\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 10s 260us/sample - loss: 0.0659 - acc: 0.9810 - val_loss: 0.1085 - val_acc: 0.9694\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.0593 - acc: 0.9825 - val_loss: 0.1090 - val_acc: 0.9690\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.0544 - acc: 0.9843 - val_loss: 0.1230 - val_acc: 0.9664\n",
      "18333/18333 [==============================] - 3s 175us/sample - loss: 0.1493 - acc: 0.9614\n",
      "[CV] ..................................... n_neurons=58, total= 2.2min\n",
      "[CV] n_neurons=58 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 17s 452us/sample - loss: 0.3680 - acc: 0.8972 - val_loss: 0.2296 - val_acc: 0.9344\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 318us/sample - loss: 0.1930 - acc: 0.9438 - val_loss: 0.1603 - val_acc: 0.9550\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 338us/sample - loss: 0.1482 - acc: 0.9559 - val_loss: 0.1449 - val_acc: 0.9596\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 321us/sample - loss: 0.1214 - acc: 0.9643 - val_loss: 0.1352 - val_acc: 0.9610\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 276us/sample - loss: 0.1021 - acc: 0.9704 - val_loss: 0.1301 - val_acc: 0.9614\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 267us/sample - loss: 0.0899 - acc: 0.9734 - val_loss: 0.1218 - val_acc: 0.9656\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.0806 - acc: 0.9763 - val_loss: 0.1179 - val_acc: 0.9690\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 325us/sample - loss: 0.0718 - acc: 0.9794 - val_loss: 0.1219 - val_acc: 0.9662\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.0646 - acc: 0.9818 - val_loss: 0.1244 - val_acc: 0.9674\n",
      "18333/18333 [==============================] - 3s 183us/sample - loss: 0.1392 - acc: 0.9648\n",
      "[CV] ..................................... n_neurons=58, total= 2.0min\n",
      "[CV] n_neurons=59 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 17s 465us/sample - loss: 0.3563 - acc: 0.8994 - val_loss: 0.2104 - val_acc: 0.9382\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 13s 353us/sample - loss: 0.1853 - acc: 0.9448 - val_loss: 0.1552 - val_acc: 0.9566\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 13s 360us/sample - loss: 0.1421 - acc: 0.9586 - val_loss: 0.1343 - val_acc: 0.9640\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 13s 359us/sample - loss: 0.1161 - acc: 0.9666 - val_loss: 0.1261 - val_acc: 0.9656\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 13s 347us/sample - loss: 0.0990 - acc: 0.9706 - val_loss: 0.1196 - val_acc: 0.9692\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 13s 359us/sample - loss: 0.0873 - acc: 0.9750 - val_loss: 0.1120 - val_acc: 0.9682\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 13s 351us/sample - loss: 0.0761 - acc: 0.9780 - val_loss: 0.1154 - val_acc: 0.9694\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 301us/sample - loss: 0.0687 - acc: 0.9806 - val_loss: 0.1154 - val_acc: 0.9698\n",
      "18334/18334 [==============================] - 3s 171us/sample - loss: 0.1382 - acc: 0.9642\n",
      "[CV] ..................................... n_neurons=59, total= 1.9min\n",
      "[CV] n_neurons=59 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 14s 388us/sample - loss: 0.3627 - acc: 0.8999 - val_loss: 0.2098 - val_acc: 0.9384\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 9s 256us/sample - loss: 0.1941 - acc: 0.9444 - val_loss: 0.1648 - val_acc: 0.9544\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 267us/sample - loss: 0.1504 - acc: 0.9558 - val_loss: 0.1463 - val_acc: 0.9574\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 262us/sample - loss: 0.1244 - acc: 0.9644 - val_loss: 0.1287 - val_acc: 0.9620\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 9s 251us/sample - loss: 0.1053 - acc: 0.9699 - val_loss: 0.1256 - val_acc: 0.9640\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 261us/sample - loss: 0.0928 - acc: 0.9729 - val_loss: 0.1221 - val_acc: 0.9642\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 10s 269us/sample - loss: 0.0821 - acc: 0.9759 - val_loss: 0.1158 - val_acc: 0.9678\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 10s 279us/sample - loss: 0.0738 - acc: 0.9783 - val_loss: 0.1157 - val_acc: 0.9664\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 314us/sample - loss: 0.0661 - acc: 0.9806 - val_loss: 0.1124 - val_acc: 0.9708\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 9s 255us/sample - loss: 0.0599 - acc: 0.9826 - val_loss: 0.1096 - val_acc: 0.9720\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 9s 254us/sample - loss: 0.0534 - acc: 0.9845 - val_loss: 0.1191 - val_acc: 0.9694\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 9s 248us/sample - loss: 0.0494 - acc: 0.9863 - val_loss: 0.1118 - val_acc: 0.9720\n",
      "18333/18333 [==============================] - 2s 97us/sample - loss: 0.1367 - acc: 0.9669\n",
      "[CV] ..................................... n_neurons=59, total= 2.2min\n",
      "[CV] n_neurons=59 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 437us/sample - loss: 0.3628 - acc: 0.8995 - val_loss: 0.2066 - val_acc: 0.9438\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.1961 - acc: 0.9426 - val_loss: 0.1679 - val_acc: 0.9514\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 274us/sample - loss: 0.1487 - acc: 0.9578 - val_loss: 0.1345 - val_acc: 0.9626\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 349us/sample - loss: 0.1217 - acc: 0.9650 - val_loss: 0.1327 - val_acc: 0.9630\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 311us/sample - loss: 0.1047 - acc: 0.9692 - val_loss: 0.1130 - val_acc: 0.9684\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 274us/sample - loss: 0.0917 - acc: 0.9740 - val_loss: 0.1169 - val_acc: 0.9676\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 290us/sample - loss: 0.0802 - acc: 0.9775 - val_loss: 0.1233 - val_acc: 0.9664\n",
      "18333/18333 [==============================] - 3s 160us/sample - loss: 0.1485 - acc: 0.9620\n",
      "[CV] ..................................... n_neurons=59, total= 1.6min\n",
      "[CV] n_neurons=60 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 16s 427us/sample - loss: 0.3673 - acc: 0.8945 - val_loss: 0.2375 - val_acc: 0.9324\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 11s 304us/sample - loss: 0.1992 - acc: 0.9411 - val_loss: 0.1714 - val_acc: 0.9498\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 14s 370us/sample - loss: 0.1552 - acc: 0.9549 - val_loss: 0.1585 - val_acc: 0.9542\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 12s 338us/sample - loss: 0.1273 - acc: 0.9629 - val_loss: 0.1348 - val_acc: 0.9614\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 12s 316us/sample - loss: 0.1092 - acc: 0.9681 - val_loss: 0.1290 - val_acc: 0.9640\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 12s 338us/sample - loss: 0.0959 - acc: 0.9720 - val_loss: 0.1194 - val_acc: 0.9636\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 13s 360us/sample - loss: 0.0834 - acc: 0.9760 - val_loss: 0.1320 - val_acc: 0.9632\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 13s 360us/sample - loss: 0.0760 - acc: 0.9788 - val_loss: 0.1275 - val_acc: 0.9628\n",
      "18334/18334 [==============================] - 4s 193us/sample - loss: 0.1496 - acc: 0.9594\n",
      "[CV] ..................................... n_neurons=60, total= 1.9min\n",
      "[CV] n_neurons=60 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 21s 580us/sample - loss: 0.3596 - acc: 0.8998 - val_loss: 0.2058 - val_acc: 0.9442\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 14s 379us/sample - loss: 0.1858 - acc: 0.9467 - val_loss: 0.1576 - val_acc: 0.9558\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.1398 - acc: 0.9597 - val_loss: 0.1379 - val_acc: 0.9606\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 326us/sample - loss: 0.1162 - acc: 0.9668 - val_loss: 0.1248 - val_acc: 0.9630\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.0997 - acc: 0.9711 - val_loss: 0.1168 - val_acc: 0.9674\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 327us/sample - loss: 0.0874 - acc: 0.9743 - val_loss: 0.1118 - val_acc: 0.9680\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 13s 352us/sample - loss: 0.0762 - acc: 0.9773 - val_loss: 0.1147 - val_acc: 0.9670\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 339us/sample - loss: 0.0688 - acc: 0.9796 - val_loss: 0.1178 - val_acc: 0.9670\n",
      "18333/18333 [==============================] - 3s 180us/sample - loss: 0.1393 - acc: 0.9635\n",
      "[CV] ..................................... n_neurons=60, total= 2.0min\n",
      "[CV] n_neurons=60 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 18s 490us/sample - loss: 0.3679 - acc: 0.8969 - val_loss: 0.2108 - val_acc: 0.9422\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 321us/sample - loss: 0.1898 - acc: 0.9449 - val_loss: 0.1557 - val_acc: 0.9520\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 259us/sample - loss: 0.1445 - acc: 0.9583 - val_loss: 0.1341 - val_acc: 0.9624\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 281us/sample - loss: 0.1176 - acc: 0.9660 - val_loss: 0.1175 - val_acc: 0.9642\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 269us/sample - loss: 0.1003 - acc: 0.9712 - val_loss: 0.1157 - val_acc: 0.9676\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 284us/sample - loss: 0.0877 - acc: 0.9753 - val_loss: 0.1057 - val_acc: 0.9690\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 10s 265us/sample - loss: 0.0779 - acc: 0.9779 - val_loss: 0.1086 - val_acc: 0.9692\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 10s 263us/sample - loss: 0.0702 - acc: 0.9808 - val_loss: 0.1147 - val_acc: 0.9706\n",
      "18333/18333 [==============================] - 3s 138us/sample - loss: 0.1357 - acc: 0.9649\n",
      "[CV] ..................................... n_neurons=60, total= 1.6min\n",
      "[CV] n_neurons=61 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 14s 389us/sample - loss: 0.3694 - acc: 0.8966 - val_loss: 0.2223 - val_acc: 0.9378\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 10s 266us/sample - loss: 0.2001 - acc: 0.9414 - val_loss: 0.1675 - val_acc: 0.9534\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 10s 272us/sample - loss: 0.1489 - acc: 0.9568 - val_loss: 0.1442 - val_acc: 0.9588\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 10s 278us/sample - loss: 0.1199 - acc: 0.9654 - val_loss: 0.1330 - val_acc: 0.9612\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 10s 261us/sample - loss: 0.1015 - acc: 0.9701 - val_loss: 0.1218 - val_acc: 0.9644\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 312us/sample - loss: 0.0871 - acc: 0.9746 - val_loss: 0.1177 - val_acc: 0.9658\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 13s 346us/sample - loss: 0.0770 - acc: 0.9782 - val_loss: 0.1124 - val_acc: 0.9664\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 14s 379us/sample - loss: 0.0684 - acc: 0.9804 - val_loss: 0.1171 - val_acc: 0.9652\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 13s 351us/sample - loss: 0.0621 - acc: 0.9818 - val_loss: 0.1184 - val_acc: 0.9676\n",
      "18334/18334 [==============================] - 4s 194us/sample - loss: 0.1417 - acc: 0.9641\n",
      "[CV] ..................................... n_neurons=61, total= 1.9min\n",
      "[CV] n_neurons=61 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 428us/sample - loss: 0.3624 - acc: 0.8979 - val_loss: 0.2068 - val_acc: 0.9386\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 13s 352us/sample - loss: 0.1852 - acc: 0.9466 - val_loss: 0.1496 - val_acc: 0.9592\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 338us/sample - loss: 0.1408 - acc: 0.9593 - val_loss: 0.1346 - val_acc: 0.9630\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 363us/sample - loss: 0.1145 - acc: 0.9667 - val_loss: 0.1184 - val_acc: 0.9680\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 13s 352us/sample - loss: 0.0968 - acc: 0.9714 - val_loss: 0.1094 - val_acc: 0.9692\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 352us/sample - loss: 0.0839 - acc: 0.9759 - val_loss: 0.1068 - val_acc: 0.9700\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 13s 348us/sample - loss: 0.0736 - acc: 0.9783 - val_loss: 0.1061 - val_acc: 0.9700\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 326us/sample - loss: 0.0657 - acc: 0.9807 - val_loss: 0.1013 - val_acc: 0.9716\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 13s 341us/sample - loss: 0.0592 - acc: 0.9826 - val_loss: 0.0982 - val_acc: 0.9730\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 12s 325us/sample - loss: 0.0526 - acc: 0.9848 - val_loss: 0.1040 - val_acc: 0.9734\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 12s 327us/sample - loss: 0.0468 - acc: 0.9865 - val_loss: 0.1040 - val_acc: 0.9732\n",
      "18333/18333 [==============================] - 4s 208us/sample - loss: 0.1356 - acc: 0.9661\n",
      "[CV] ..................................... n_neurons=61, total= 2.5min\n",
      "[CV] n_neurons=61 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 444us/sample - loss: 0.3677 - acc: 0.8963 - val_loss: 0.2047 - val_acc: 0.9404\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 338us/sample - loss: 0.1895 - acc: 0.9443 - val_loss: 0.1529 - val_acc: 0.9564\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 323us/sample - loss: 0.1406 - acc: 0.9590 - val_loss: 0.1353 - val_acc: 0.9608\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 328us/sample - loss: 0.1126 - acc: 0.9673 - val_loss: 0.1215 - val_acc: 0.9648\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 322us/sample - loss: 0.0949 - acc: 0.9715 - val_loss: 0.1124 - val_acc: 0.9676\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 346us/sample - loss: 0.0825 - acc: 0.9762 - val_loss: 0.1232 - val_acc: 0.9656\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 323us/sample - loss: 0.0726 - acc: 0.9792 - val_loss: 0.1091 - val_acc: 0.9706\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 322us/sample - loss: 0.0651 - acc: 0.9811 - val_loss: 0.1063 - val_acc: 0.9692\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 329us/sample - loss: 0.0583 - acc: 0.9837 - val_loss: 0.1138 - val_acc: 0.9686\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 12s 340us/sample - loss: 0.0530 - acc: 0.9858 - val_loss: 0.1165 - val_acc: 0.9688\n",
      "18333/18333 [==============================] - 3s 171us/sample - loss: 0.1362 - acc: 0.9660\n",
      "[CV] ..................................... n_neurons=61, total= 2.3min\n",
      "[CV] n_neurons=62 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 17s 463us/sample - loss: 0.3620 - acc: 0.8986 - val_loss: 0.2042 - val_acc: 0.9420\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 13s 345us/sample - loss: 0.1909 - acc: 0.9438 - val_loss: 0.1605 - val_acc: 0.9558\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 13s 344us/sample - loss: 0.1467 - acc: 0.9563 - val_loss: 0.1435 - val_acc: 0.9610\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 12s 327us/sample - loss: 0.1193 - acc: 0.9657 - val_loss: 0.1261 - val_acc: 0.9664\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 12s 337us/sample - loss: 0.1012 - acc: 0.9712 - val_loss: 0.1383 - val_acc: 0.9602\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 12s 336us/sample - loss: 0.0864 - acc: 0.9750 - val_loss: 0.1218 - val_acc: 0.9676\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 13s 349us/sample - loss: 0.0758 - acc: 0.9779 - val_loss: 0.1294 - val_acc: 0.9648\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 12s 329us/sample - loss: 0.0693 - acc: 0.9804 - val_loss: 0.1220 - val_acc: 0.9674\n",
      "18334/18334 [==============================] - 3s 176us/sample - loss: 0.1291 - acc: 0.9660\n",
      "[CV] ..................................... n_neurons=62, total= 1.9min\n",
      "[CV] n_neurons=62 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 446us/sample - loss: 0.3507 - acc: 0.9035 - val_loss: 0.2065 - val_acc: 0.9416\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 328us/sample - loss: 0.1865 - acc: 0.9468 - val_loss: 0.1617 - val_acc: 0.9574\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 13s 349us/sample - loss: 0.1430 - acc: 0.9582 - val_loss: 0.1412 - val_acc: 0.9616\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 359us/sample - loss: 0.1172 - acc: 0.9655 - val_loss: 0.1298 - val_acc: 0.9620\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 13s 362us/sample - loss: 0.0995 - acc: 0.9710 - val_loss: 0.1222 - val_acc: 0.9664\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 338us/sample - loss: 0.0866 - acc: 0.9744 - val_loss: 0.1165 - val_acc: 0.9666\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.0751 - acc: 0.9782 - val_loss: 0.1241 - val_acc: 0.9674\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 296us/sample - loss: 0.0674 - acc: 0.9807 - val_loss: 0.1264 - val_acc: 0.9654\n",
      "18333/18333 [==============================] - 3s 172us/sample - loss: 0.1360 - acc: 0.9636\n",
      "[CV] ..................................... n_neurons=62, total= 1.9min\n",
      "[CV] n_neurons=62 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 404us/sample - loss: 0.3623 - acc: 0.8992 - val_loss: 0.2034 - val_acc: 0.9416\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.1897 - acc: 0.9441 - val_loss: 0.1555 - val_acc: 0.9566\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.1430 - acc: 0.9580 - val_loss: 0.1386 - val_acc: 0.9594\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.1165 - acc: 0.9657 - val_loss: 0.1222 - val_acc: 0.9642\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 306us/sample - loss: 0.0987 - acc: 0.9701 - val_loss: 0.1159 - val_acc: 0.9666\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.0847 - acc: 0.9749 - val_loss: 0.1134 - val_acc: 0.9692\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 305us/sample - loss: 0.0763 - acc: 0.9771 - val_loss: 0.1071 - val_acc: 0.9686\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 303us/sample - loss: 0.0673 - acc: 0.9810 - val_loss: 0.1076 - val_acc: 0.9694\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.0600 - acc: 0.9828 - val_loss: 0.1067 - val_acc: 0.9706\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.0562 - acc: 0.9845 - val_loss: 0.1049 - val_acc: 0.9702\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.0504 - acc: 0.9861 - val_loss: 0.1087 - val_acc: 0.9688\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.0471 - acc: 0.9872 - val_loss: 0.1112 - val_acc: 0.9714\n",
      "18333/18333 [==============================] - 3s 167us/sample - loss: 0.1385 - acc: 0.9668\n",
      "[CV] ..................................... n_neurons=62, total= 2.4min\n",
      "[CV] n_neurons=63 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 15s 409us/sample - loss: 0.3673 - acc: 0.8968 - val_loss: 0.2158 - val_acc: 0.9392\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 11s 306us/sample - loss: 0.1966 - acc: 0.9423 - val_loss: 0.1611 - val_acc: 0.9546\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 305us/sample - loss: 0.1484 - acc: 0.9565 - val_loss: 0.1512 - val_acc: 0.9560\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 304us/sample - loss: 0.1227 - acc: 0.9646 - val_loss: 0.1342 - val_acc: 0.9608\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 12s 316us/sample - loss: 0.1037 - acc: 0.9704 - val_loss: 0.1253 - val_acc: 0.9636\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 303us/sample - loss: 0.0900 - acc: 0.9736 - val_loss: 0.1168 - val_acc: 0.9640\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 304us/sample - loss: 0.0791 - acc: 0.9771 - val_loss: 0.1152 - val_acc: 0.9662\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 309us/sample - loss: 0.0701 - acc: 0.9803 - val_loss: 0.1132 - val_acc: 0.9674\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 11s 307us/sample - loss: 0.0635 - acc: 0.9814 - val_loss: 0.1212 - val_acc: 0.9650\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 12s 319us/sample - loss: 0.0569 - acc: 0.9840 - val_loss: 0.1083 - val_acc: 0.9708\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 11s 309us/sample - loss: 0.0518 - acc: 0.9859 - val_loss: 0.1118 - val_acc: 0.9688\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 11s 305us/sample - loss: 0.0476 - acc: 0.9870 - val_loss: 0.1178 - val_acc: 0.9662\n",
      "18334/18334 [==============================] - 3s 156us/sample - loss: 0.1408 - acc: 0.9656\n",
      "[CV] ..................................... n_neurons=63, total= 2.5min\n",
      "[CV] n_neurons=63 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 413us/sample - loss: 0.3604 - acc: 0.8995 - val_loss: 0.2141 - val_acc: 0.9370\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 307us/sample - loss: 0.1932 - acc: 0.9442 - val_loss: 0.1665 - val_acc: 0.9506\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 303us/sample - loss: 0.1468 - acc: 0.9565 - val_loss: 0.1405 - val_acc: 0.9606\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 303us/sample - loss: 0.1205 - acc: 0.9655 - val_loss: 0.1253 - val_acc: 0.9656\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.1015 - acc: 0.9705 - val_loss: 0.1203 - val_acc: 0.9640\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.0879 - acc: 0.9741 - val_loss: 0.1122 - val_acc: 0.9694\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.0779 - acc: 0.9772 - val_loss: 0.1169 - val_acc: 0.9668\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 303us/sample - loss: 0.0691 - acc: 0.9804 - val_loss: 0.1110 - val_acc: 0.9690\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 305us/sample - loss: 0.0634 - acc: 0.9812 - val_loss: 0.1134 - val_acc: 0.9676\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.0559 - acc: 0.9836 - val_loss: 0.1111 - val_acc: 0.9692\n",
      "18333/18333 [==============================] - 3s 162us/sample - loss: 0.1350 - acc: 0.9645\n",
      "[CV] ..................................... n_neurons=63, total= 2.1min\n",
      "[CV] n_neurons=63 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 402us/sample - loss: 0.3599 - acc: 0.8998 - val_loss: 0.2043 - val_acc: 0.9418\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 311us/sample - loss: 0.1918 - acc: 0.9430 - val_loss: 0.1570 - val_acc: 0.9540\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.1453 - acc: 0.9569 - val_loss: 0.1336 - val_acc: 0.9634\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.1188 - acc: 0.9644 - val_loss: 0.1276 - val_acc: 0.9630\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.1005 - acc: 0.9702 - val_loss: 0.1176 - val_acc: 0.9664\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 307us/sample - loss: 0.0881 - acc: 0.9743 - val_loss: 0.1168 - val_acc: 0.9682\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 308us/sample - loss: 0.0770 - acc: 0.9771 - val_loss: 0.1183 - val_acc: 0.9670\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 307us/sample - loss: 0.0687 - acc: 0.9798 - val_loss: 0.1127 - val_acc: 0.9670\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 308us/sample - loss: 0.0613 - acc: 0.9827 - val_loss: 0.1095 - val_acc: 0.9706\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 307us/sample - loss: 0.0557 - acc: 0.9844 - val_loss: 0.1186 - val_acc: 0.9688\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 11s 308us/sample - loss: 0.0516 - acc: 0.9851 - val_loss: 0.1181 - val_acc: 0.9696\n",
      "18333/18333 [==============================] - 3s 162us/sample - loss: 0.1381 - acc: 0.9663s - l\n",
      "[CV] ..................................... n_neurons=63, total= 2.3min\n",
      "[CV] n_neurons=64 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 15s 414us/sample - loss: 0.3593 - acc: 0.9001 - val_loss: 0.2142 - val_acc: 0.9384\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 12s 319us/sample - loss: 0.1862 - acc: 0.9462 - val_loss: 0.1535 - val_acc: 0.9556\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 290us/sample - loss: 0.1401 - acc: 0.9597 - val_loss: 0.1363 - val_acc: 0.9604\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 79s 2ms/sample - loss: 0.1126 - acc: 0.9671 - val_loss: 0.1299 - val_acc: 0.9652\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 113s 3ms/sample - loss: 0.0961 - acc: 0.9723 - val_loss: 0.1148 - val_acc: 0.9666\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 16s 433us/sample - loss: 0.0830 - acc: 0.9760 - val_loss: 0.1082 - val_acc: 0.9694\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 15s 405us/sample - loss: 0.0716 - acc: 0.9790 - val_loss: 0.1101 - val_acc: 0.9686\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 10s 280us/sample - loss: 0.0644 - acc: 0.9818 - val_loss: 0.1062 - val_acc: 0.9724\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 10s 269us/sample - loss: 0.0587 - acc: 0.9837 - val_loss: 0.1023 - val_acc: 0.9718\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 10s 276us/sample - loss: 0.0525 - acc: 0.9849 - val_loss: 0.1072 - val_acc: 0.9720\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 10s 274us/sample - loss: 0.0482 - acc: 0.9865 - val_loss: 0.1056 - val_acc: 0.9698\n",
      "18334/18334 [==============================] - 3s 144us/sample - loss: 0.1346 - acc: 0.9652\n",
      "[CV] ..................................... n_neurons=64, total= 5.2min\n",
      "[CV] n_neurons=64 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 14s 377us/sample - loss: 0.3532 - acc: 0.9012 - val_loss: 0.2033 - val_acc: 0.9414\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 10s 269us/sample - loss: 0.1861 - acc: 0.9464 - val_loss: 0.1621 - val_acc: 0.9542\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 269us/sample - loss: 0.1418 - acc: 0.9589 - val_loss: 0.1410 - val_acc: 0.9584\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 269us/sample - loss: 0.1142 - acc: 0.9656 - val_loss: 0.1276 - val_acc: 0.9616\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 275us/sample - loss: 0.0972 - acc: 0.9719 - val_loss: 0.1260 - val_acc: 0.9648\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 349us/sample - loss: 0.0833 - acc: 0.9748 - val_loss: 0.1192 - val_acc: 0.9668\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 13s 348us/sample - loss: 0.0739 - acc: 0.9787 - val_loss: 0.1132 - val_acc: 0.9680\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 10s 284us/sample - loss: 0.0654 - acc: 0.9809 - val_loss: 0.1150 - val_acc: 0.9686\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 10s 268us/sample - loss: 0.0594 - acc: 0.9828 - val_loss: 0.1194 - val_acc: 0.9686\n",
      "18333/18333 [==============================] - 3s 145us/sample - loss: 0.1405 - acc: 0.9625\n",
      "[CV] ..................................... n_neurons=64, total= 1.8min\n",
      "[CV] n_neurons=64 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 437us/sample - loss: 0.3604 - acc: 0.8996 - val_loss: 0.2056 - val_acc: 0.9408\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 14s 374us/sample - loss: 0.1924 - acc: 0.9429 - val_loss: 0.1615 - val_acc: 0.9540\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 14s 375us/sample - loss: 0.1433 - acc: 0.9585 - val_loss: 0.1349 - val_acc: 0.9596\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 350us/sample - loss: 0.1132 - acc: 0.9676 - val_loss: 0.1217 - val_acc: 0.9654\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 13s 346us/sample - loss: 0.0949 - acc: 0.9730 - val_loss: 0.1225 - val_acc: 0.9664\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 351us/sample - loss: 0.0821 - acc: 0.9764 - val_loss: 0.1167 - val_acc: 0.9660\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 308us/sample - loss: 0.0726 - acc: 0.9797 - val_loss: 0.1100 - val_acc: 0.9688\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 10s 286us/sample - loss: 0.0648 - acc: 0.9822 - val_loss: 0.1135 - val_acc: 0.9668\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.0591 - acc: 0.9839 - val_loss: 0.1151 - val_acc: 0.9686\n",
      "18333/18333 [==============================] - 3s 147us/sample - loss: 0.1347 - acc: 0.9661\n",
      "[CV] ..................................... n_neurons=64, total= 2.1min\n",
      "[CV] n_neurons=65 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 17s 462us/sample - loss: 0.3602 - acc: 0.8982 - val_loss: 0.2082 - val_acc: 0.9430\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 14s 374us/sample - loss: 0.1857 - acc: 0.9463 - val_loss: 0.1565 - val_acc: 0.9568\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 13s 353us/sample - loss: 0.1417 - acc: 0.9589 - val_loss: 0.1301 - val_acc: 0.9640\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 291us/sample - loss: 0.1156 - acc: 0.9661 - val_loss: 0.1305 - val_acc: 0.9618\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 11s 309us/sample - loss: 0.0973 - acc: 0.9714 - val_loss: 0.1243 - val_acc: 0.9646\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 10s 284us/sample - loss: 0.0843 - acc: 0.9758 - val_loss: 0.1165 - val_acc: 0.9656\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 287us/sample - loss: 0.0740 - acc: 0.9783 - val_loss: 0.1200 - val_acc: 0.9676\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 13s 343us/sample - loss: 0.0658 - acc: 0.9802 - val_loss: 0.1184 - val_acc: 0.9682\n",
      "18334/18334 [==============================] - 9s 502us/sample - loss: 0.1300 - acc: 0.9654\n",
      "[CV] ..................................... n_neurons=65, total= 1.9min\n",
      "[CV] n_neurons=65 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 401us/sample - loss: 0.3578 - acc: 0.9022 - val_loss: 0.2057 - val_acc: 0.9404\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 13s 361us/sample - loss: 0.1865 - acc: 0.9463 - val_loss: 0.1475 - val_acc: 0.9558\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 14s 383us/sample - loss: 0.1412 - acc: 0.9588 - val_loss: 0.1287 - val_acc: 0.9624\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 356us/sample - loss: 0.1167 - acc: 0.9659 - val_loss: 0.1219 - val_acc: 0.9634\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 13s 356us/sample - loss: 0.0991 - acc: 0.9710 - val_loss: 0.1263 - val_acc: 0.9638\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 331us/sample - loss: 0.0870 - acc: 0.9737 - val_loss: 0.1180 - val_acc: 0.9656\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 322us/sample - loss: 0.0762 - acc: 0.9784 - val_loss: 0.1086 - val_acc: 0.9676\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 288us/sample - loss: 0.0679 - acc: 0.9799 - val_loss: 0.1130 - val_acc: 0.9672\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 309us/sample - loss: 0.0605 - acc: 0.9816 - val_loss: 0.1102 - val_acc: 0.9690\n",
      "18333/18333 [==============================] - 3s 166us/sample - loss: 0.1377 - acc: 0.9654\n",
      "[CV] ..................................... n_neurons=65, total= 2.2min\n",
      "[CV] n_neurons=65 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 413us/sample - loss: 0.3668 - acc: 0.8957 - val_loss: 0.1944 - val_acc: 0.9450\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.1878 - acc: 0.9456 - val_loss: 0.1543 - val_acc: 0.9572\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 279us/sample - loss: 0.1402 - acc: 0.9584 - val_loss: 0.1258 - val_acc: 0.9646\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 282us/sample - loss: 0.1144 - acc: 0.9669 - val_loss: 0.1162 - val_acc: 0.9686\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 18s 479us/sample - loss: 0.0976 - acc: 0.9721 - val_loss: 0.1186 - val_acc: 0.9666\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 363us/sample - loss: 0.0852 - acc: 0.9758 - val_loss: 0.1106 - val_acc: 0.9698\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 16s 446us/sample - loss: 0.0747 - acc: 0.9783 - val_loss: 0.1044 - val_acc: 0.9738\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 15s 418us/sample - loss: 0.0665 - acc: 0.9815 - val_loss: 0.1065 - val_acc: 0.9710\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 14s 386us/sample - loss: 0.0598 - acc: 0.9832 - val_loss: 0.1048 - val_acc: 0.9730\n",
      "18333/18333 [==============================] - 4s 207us/sample - loss: 0.1297 - acc: 0.9669\n",
      "[CV] ..................................... n_neurons=65, total= 2.2min\n",
      "[CV] n_neurons=66 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 17s 470us/sample - loss: 0.3594 - acc: 0.8997 - val_loss: 0.2053 - val_acc: 0.9452\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 13s 341us/sample - loss: 0.1939 - acc: 0.9454 - val_loss: 0.1673 - val_acc: 0.9558\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 13s 364us/sample - loss: 0.1483 - acc: 0.9573 - val_loss: 0.1347 - val_acc: 0.9596\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 14s 369us/sample - loss: 0.1203 - acc: 0.9652 - val_loss: 0.1403 - val_acc: 0.9604\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 13s 344us/sample - loss: 0.1028 - acc: 0.9710 - val_loss: 0.1176 - val_acc: 0.9662\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 14s 378us/sample - loss: 0.0892 - acc: 0.9744 - val_loss: 0.1176 - val_acc: 0.9668\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 15s 409us/sample - loss: 0.0772 - acc: 0.9775 - val_loss: 0.1151 - val_acc: 0.9656\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 17s 460us/sample - loss: 0.0682 - acc: 0.9805 - val_loss: 0.1127 - val_acc: 0.9700\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 14s 387us/sample - loss: 0.0621 - acc: 0.9827 - val_loss: 0.1092 - val_acc: 0.9690\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 13s 365us/sample - loss: 0.0560 - acc: 0.9844 - val_loss: 0.1085 - val_acc: 0.9696\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 10s 274us/sample - loss: 0.0519 - acc: 0.9862 - val_loss: 0.1131 - val_acc: 0.9692\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 11s 288us/sample - loss: 0.0464 - acc: 0.9869 - val_loss: 0.1149 - val_acc: 0.9696\n",
      "18334/18334 [==============================] - 3s 152us/sample - loss: 0.1431 - acc: 0.9652\n",
      "[CV] ..................................... n_neurons=66, total= 2.9min\n",
      "[CV] n_neurons=66 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 14s 394us/sample - loss: 0.3420 - acc: 0.9038 - val_loss: 0.2119 - val_acc: 0.9394\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 308us/sample - loss: 0.1829 - acc: 0.9469 - val_loss: 0.1562 - val_acc: 0.9560\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 316us/sample - loss: 0.1404 - acc: 0.9602 - val_loss: 0.1381 - val_acc: 0.9616\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 287us/sample - loss: 0.1153 - acc: 0.9673 - val_loss: 0.1222 - val_acc: 0.9656\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 298us/sample - loss: 0.0986 - acc: 0.9716 - val_loss: 0.1224 - val_acc: 0.9634\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 15s 398us/sample - loss: 0.0846 - acc: 0.9750 - val_loss: 0.1167 - val_acc: 0.9690\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.0755 - acc: 0.9785 - val_loss: 0.1101 - val_acc: 0.9688\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 15s 419us/sample - loss: 0.0669 - acc: 0.9804 - val_loss: 0.1178 - val_acc: 0.9698\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 338us/sample - loss: 0.0611 - acc: 0.9825 - val_loss: 0.1132 - val_acc: 0.9696\n",
      "18333/18333 [==============================] - 3s 177us/sample - loss: 0.1370 - acc: 0.9666\n",
      "[CV] ..................................... n_neurons=66, total= 2.0min\n",
      "[CV] n_neurons=66 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 17s 455us/sample - loss: 0.3568 - acc: 0.9017 - val_loss: 0.2139 - val_acc: 0.9400\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 332us/sample - loss: 0.1841 - acc: 0.9453 - val_loss: 0.1616 - val_acc: 0.9520\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 334us/sample - loss: 0.1391 - acc: 0.9585 - val_loss: 0.1412 - val_acc: 0.9594\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 332us/sample - loss: 0.1134 - acc: 0.9670 - val_loss: 0.1183 - val_acc: 0.9674\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 333us/sample - loss: 0.0954 - acc: 0.9728 - val_loss: 0.1282 - val_acc: 0.9642\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 337us/sample - loss: 0.0834 - acc: 0.9756 - val_loss: 0.1179 - val_acc: 0.9676\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 335us/sample - loss: 0.0736 - acc: 0.9791 - val_loss: 0.1114 - val_acc: 0.9692\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 334us/sample - loss: 0.0661 - acc: 0.9810 - val_loss: 0.1176 - val_acc: 0.9666\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 339us/sample - loss: 0.0595 - acc: 0.9833 - val_loss: 0.1121 - val_acc: 0.9688\n",
      "18333/18333 [==============================] - 3s 175us/sample - loss: 0.1297 - acc: 0.9658\n",
      "[CV] ..................................... n_neurons=66, total= 2.1min\n",
      "[CV] n_neurons=67 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 19s 516us/sample - loss: 0.3565 - acc: 0.8993 - val_loss: 0.2088 - val_acc: 0.9414\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 13s 365us/sample - loss: 0.1833 - acc: 0.9466 - val_loss: 0.1595 - val_acc: 0.9544\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 13s 351us/sample - loss: 0.1393 - acc: 0.9596 - val_loss: 0.1423 - val_acc: 0.9592\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 13s 350us/sample - loss: 0.1143 - acc: 0.9668 - val_loss: 0.1275 - val_acc: 0.9636\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 13s 361us/sample - loss: 0.0972 - acc: 0.9713 - val_loss: 0.1217 - val_acc: 0.9648\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 14s 372us/sample - loss: 0.0853 - acc: 0.9749 - val_loss: 0.1065 - val_acc: 0.9700\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 13s 362us/sample - loss: 0.0744 - acc: 0.9775 - val_loss: 0.1199 - val_acc: 0.9634\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 13s 357us/sample - loss: 0.0667 - acc: 0.9809 - val_loss: 0.1191 - val_acc: 0.9670\n",
      "18334/18334 [==============================] - 3s 188us/sample - loss: 0.1414 - acc: 0.9614\n",
      "[CV] ..................................... n_neurons=67, total= 2.0min\n",
      "[CV] n_neurons=67 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 18s 494us/sample - loss: 0.3569 - acc: 0.8981 - val_loss: 0.2157 - val_acc: 0.9368\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 14s 376us/sample - loss: 0.1892 - acc: 0.9456 - val_loss: 0.1501 - val_acc: 0.9580\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 13s 353us/sample - loss: 0.1430 - acc: 0.9590 - val_loss: 0.1327 - val_acc: 0.9614\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 14s 372us/sample - loss: 0.1155 - acc: 0.9666 - val_loss: 0.1256 - val_acc: 0.9620\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 335us/sample - loss: 0.0961 - acc: 0.9716 - val_loss: 0.1139 - val_acc: 0.9678\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 349us/sample - loss: 0.0824 - acc: 0.9756 - val_loss: 0.1152 - val_acc: 0.9658\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 14s 381us/sample - loss: 0.0725 - acc: 0.9793 - val_loss: 0.1044 - val_acc: 0.9704\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 13s 361us/sample - loss: 0.0627 - acc: 0.9821 - val_loss: 0.1104 - val_acc: 0.9702\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 338us/sample - loss: 0.0559 - acc: 0.9839 - val_loss: 0.1116 - val_acc: 0.9710\n",
      "18333/18333 [==============================] - 3s 180us/sample - loss: 0.1266 - acc: 0.9670\n",
      "[CV] ..................................... n_neurons=67, total= 2.2min\n",
      "[CV] n_neurons=67 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 18s 493us/sample - loss: 0.3628 - acc: 0.8982 - val_loss: 0.2150 - val_acc: 0.9386\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 10s 283us/sample - loss: 0.1937 - acc: 0.9442 - val_loss: 0.1674 - val_acc: 0.9504\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 10s 283us/sample - loss: 0.1469 - acc: 0.9567 - val_loss: 0.1335 - val_acc: 0.9630\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 286us/sample - loss: 0.1179 - acc: 0.9658 - val_loss: 0.1243 - val_acc: 0.9630\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 282us/sample - loss: 0.0999 - acc: 0.9710 - val_loss: 0.1104 - val_acc: 0.9688\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 282us/sample - loss: 0.0868 - acc: 0.9753 - val_loss: 0.1120 - val_acc: 0.9692\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 10s 280us/sample - loss: 0.0758 - acc: 0.9785 - val_loss: 0.1053 - val_acc: 0.9694\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 290us/sample - loss: 0.0677 - acc: 0.9807 - val_loss: 0.1043 - val_acc: 0.9706\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 290us/sample - loss: 0.0609 - acc: 0.9832 - val_loss: 0.0989 - val_acc: 0.9738\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 10s 280us/sample - loss: 0.0544 - acc: 0.9853 - val_loss: 0.1002 - val_acc: 0.9722\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 10s 284us/sample - loss: 0.0495 - acc: 0.9863 - val_loss: 0.1035 - val_acc: 0.9710\n",
      "18333/18333 [==============================] - 3s 163us/sample - loss: 0.1395 - acc: 0.9663\n",
      "[CV] ..................................... n_neurons=67, total= 2.2min\n",
      "[CV] n_neurons=68 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 15s 416us/sample - loss: 0.3525 - acc: 0.9005 - val_loss: 0.2005 - val_acc: 0.9456\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 11s 295us/sample - loss: 0.1844 - acc: 0.9464 - val_loss: 0.1546 - val_acc: 0.9580\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 10s 284us/sample - loss: 0.1404 - acc: 0.9588 - val_loss: 0.1330 - val_acc: 0.9630\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 292us/sample - loss: 0.1136 - acc: 0.9665 - val_loss: 0.1183 - val_acc: 0.9666\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 11s 290us/sample - loss: 0.0968 - acc: 0.9714 - val_loss: 0.1113 - val_acc: 0.9674\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 10s 285us/sample - loss: 0.0845 - acc: 0.9752 - val_loss: 0.1144 - val_acc: 0.9684\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 13s 341us/sample - loss: 0.0748 - acc: 0.9786 - val_loss: 0.1082 - val_acc: 0.9702\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 13s 366us/sample - loss: 0.0668 - acc: 0.9806 - val_loss: 0.1136 - val_acc: 0.9680\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 14s 377us/sample - loss: 0.0598 - acc: 0.9830 - val_loss: 0.1095 - val_acc: 0.9702\n",
      "18334/18334 [==============================] - 3s 187us/sample - loss: 0.1350 - acc: 0.9643\n",
      "[CV] ..................................... n_neurons=68, total= 2.0min\n",
      "[CV] n_neurons=68 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 18s 487us/sample - loss: 0.3507 - acc: 0.9015 - val_loss: 0.2027 - val_acc: 0.9406\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 13s 366us/sample - loss: 0.1812 - acc: 0.9474 - val_loss: 0.1564 - val_acc: 0.9568\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 14s 370us/sample - loss: 0.1356 - acc: 0.9604 - val_loss: 0.1346 - val_acc: 0.9576\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 367us/sample - loss: 0.1096 - acc: 0.9680 - val_loss: 0.1198 - val_acc: 0.9628\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 13s 356us/sample - loss: 0.0914 - acc: 0.9737 - val_loss: 0.1180 - val_acc: 0.9646\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 348us/sample - loss: 0.0801 - acc: 0.9768 - val_loss: 0.1138 - val_acc: 0.9666\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 13s 359us/sample - loss: 0.0705 - acc: 0.9788 - val_loss: 0.1125 - val_acc: 0.9690\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 13s 356us/sample - loss: 0.0625 - acc: 0.9820 - val_loss: 0.1171 - val_acc: 0.9672\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 13s 361us/sample - loss: 0.0565 - acc: 0.9838 - val_loss: 0.1194 - val_acc: 0.9654\n",
      "18333/18333 [==============================] - 3s 187us/sample - loss: 0.1366 - acc: 0.9641\n",
      "[CV] ..................................... n_neurons=68, total= 2.2min\n",
      "[CV] n_neurons=68 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 18s 478us/sample - loss: 0.3508 - acc: 0.9034 - val_loss: 0.1936 - val_acc: 0.9450\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 13s 364us/sample - loss: 0.1805 - acc: 0.9470 - val_loss: 0.1424 - val_acc: 0.9582\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 13s 359us/sample - loss: 0.1368 - acc: 0.9600 - val_loss: 0.1232 - val_acc: 0.9634\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 360us/sample - loss: 0.1106 - acc: 0.9683 - val_loss: 0.1271 - val_acc: 0.9654\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 14s 369us/sample - loss: 0.0943 - acc: 0.9728 - val_loss: 0.1115 - val_acc: 0.9664\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 14s 378us/sample - loss: 0.0816 - acc: 0.9766 - val_loss: 0.1040 - val_acc: 0.9698\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 14s 369us/sample - loss: 0.0716 - acc: 0.9801 - val_loss: 0.1130 - val_acc: 0.9694\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 14s 385us/sample - loss: 0.0637 - acc: 0.9822 - val_loss: 0.1119 - val_acc: 0.9700\n",
      "18333/18333 [==============================] - 3s 190us/sample - loss: 0.1331 - acc: 0.9651\n",
      "[CV] ..................................... n_neurons=68, total= 2.1min\n",
      "[CV] n_neurons=69 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 21s 566us/sample - loss: 0.3442 - acc: 0.9034 - val_loss: 0.1964 - val_acc: 0.9444\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 14s 390us/sample - loss: 0.1757 - acc: 0.9491 - val_loss: 0.1574 - val_acc: 0.9528\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 14s 369us/sample - loss: 0.1328 - acc: 0.9605 - val_loss: 0.1363 - val_acc: 0.9620\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 13s 360us/sample - loss: 0.1089 - acc: 0.9680 - val_loss: 0.1204 - val_acc: 0.9662\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 13s 356us/sample - loss: 0.0926 - acc: 0.9733 - val_loss: 0.1218 - val_acc: 0.9664\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 14s 382us/sample - loss: 0.0802 - acc: 0.9759 - val_loss: 0.1158 - val_acc: 0.9666\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 294us/sample - loss: 0.0707 - acc: 0.9799 - val_loss: 0.1174 - val_acc: 0.9656\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 295us/sample - loss: 0.0640 - acc: 0.9817 - val_loss: 0.1171 - val_acc: 0.9682\n",
      "18334/18334 [==============================] - 3s 180us/sample - loss: 0.1359 - acc: 0.9651\n",
      "[CV] ..................................... n_neurons=69, total= 2.1min\n",
      "[CV] n_neurons=69 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 430us/sample - loss: 0.3428 - acc: 0.9059 - val_loss: 0.2156 - val_acc: 0.9388\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 291us/sample - loss: 0.1880 - acc: 0.9456 - val_loss: 0.1602 - val_acc: 0.9554\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 297us/sample - loss: 0.1439 - acc: 0.9587 - val_loss: 0.1377 - val_acc: 0.9622\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 337us/sample - loss: 0.1180 - acc: 0.9661 - val_loss: 0.1253 - val_acc: 0.9646\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.1006 - acc: 0.9708 - val_loss: 0.1172 - val_acc: 0.9670\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.0867 - acc: 0.9750 - val_loss: 0.1187 - val_acc: 0.9648\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.0769 - acc: 0.9783 - val_loss: 0.1149 - val_acc: 0.9696\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.0693 - acc: 0.9794 - val_loss: 0.1198 - val_acc: 0.9688\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 303us/sample - loss: 0.0619 - acc: 0.9821 - val_loss: 0.1064 - val_acc: 0.9690\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.0551 - acc: 0.9841 - val_loss: 0.1116 - val_acc: 0.9716\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.0498 - acc: 0.9859 - val_loss: 0.1159 - val_acc: 0.9692\n",
      "18333/18333 [==============================] - 3s 162us/sample - loss: 0.1314 - acc: 0.9665\n",
      "[CV] ..................................... n_neurons=69, total= 2.3min\n",
      "[CV] n_neurons=69 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 419us/sample - loss: 0.3602 - acc: 0.8982 - val_loss: 0.2093 - val_acc: 0.9416\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 288us/sample - loss: 0.1815 - acc: 0.9467 - val_loss: 0.1609 - val_acc: 0.9556\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 290us/sample - loss: 0.1349 - acc: 0.9603 - val_loss: 0.1286 - val_acc: 0.9620\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.1087 - acc: 0.9683 - val_loss: 0.1229 - val_acc: 0.9660\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 309us/sample - loss: 0.0918 - acc: 0.9743 - val_loss: 0.1054 - val_acc: 0.9692\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 309us/sample - loss: 0.0796 - acc: 0.9770 - val_loss: 0.1040 - val_acc: 0.9690\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 14s 368us/sample - loss: 0.0701 - acc: 0.9798 - val_loss: 0.1028 - val_acc: 0.9700\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 327us/sample - loss: 0.0617 - acc: 0.9824 - val_loss: 0.1106 - val_acc: 0.9682\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 336us/sample - loss: 0.0565 - acc: 0.9840 - val_loss: 0.1077 - val_acc: 0.9702\n",
      "18333/18333 [==============================] - 3s 161us/sample - loss: 0.1321 - acc: 0.9672\n",
      "[CV] ..................................... n_neurons=69, total= 2.0min\n",
      "[CV] n_neurons=70 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 15s 412us/sample - loss: 0.3509 - acc: 0.9001 - val_loss: 0.2063 - val_acc: 0.9410\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 11s 297us/sample - loss: 0.1807 - acc: 0.9470 - val_loss: 0.1606 - val_acc: 0.9518\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 297us/sample - loss: 0.1359 - acc: 0.9607 - val_loss: 0.1435 - val_acc: 0.9572\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 294us/sample - loss: 0.1090 - acc: 0.9678 - val_loss: 0.1297 - val_acc: 0.9614\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 10s 286us/sample - loss: 0.0933 - acc: 0.9730 - val_loss: 0.1130 - val_acc: 0.9660\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 288us/sample - loss: 0.0800 - acc: 0.9771 - val_loss: 0.1152 - val_acc: 0.9650\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 12s 323us/sample - loss: 0.0704 - acc: 0.9797 - val_loss: 0.1040 - val_acc: 0.9708\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 311us/sample - loss: 0.0634 - acc: 0.9822 - val_loss: 0.1099 - val_acc: 0.9694\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 10s 284us/sample - loss: 0.0568 - acc: 0.9841 - val_loss: 0.1107 - val_acc: 0.9700\n",
      "18334/18334 [==============================] - 3s 150us/sample - loss: 0.1315 - acc: 0.9645\n",
      "[CV] ..................................... n_neurons=70, total= 1.9min\n",
      "[CV] n_neurons=70 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 404us/sample - loss: 0.3599 - acc: 0.9010 - val_loss: 0.2184 - val_acc: 0.9394\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 288us/sample - loss: 0.1913 - acc: 0.9452 - val_loss: 0.1680 - val_acc: 0.9504\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 294us/sample - loss: 0.1438 - acc: 0.9587 - val_loss: 0.1430 - val_acc: 0.9584\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 10s 285us/sample - loss: 0.1154 - acc: 0.9663 - val_loss: 0.1237 - val_acc: 0.9632\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.0981 - acc: 0.9714 - val_loss: 0.1175 - val_acc: 0.9660\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 284us/sample - loss: 0.0845 - acc: 0.9753 - val_loss: 0.1110 - val_acc: 0.9668\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.0745 - acc: 0.9786 - val_loss: 0.1082 - val_acc: 0.9684\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.0656 - acc: 0.9809 - val_loss: 0.1089 - val_acc: 0.9706\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.0583 - acc: 0.9837 - val_loss: 0.1082 - val_acc: 0.9688\n",
      "18333/18333 [==============================] - 3s 160us/sample - loss: 0.1309 - acc: 0.9645\n",
      "[CV] ..................................... n_neurons=70, total= 1.8min\n",
      "[CV] n_neurons=70 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 419us/sample - loss: 0.3492 - acc: 0.9027 - val_loss: 0.1934 - val_acc: 0.9460\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 10s 281us/sample - loss: 0.1784 - acc: 0.9489 - val_loss: 0.1502 - val_acc: 0.9578\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 288us/sample - loss: 0.1345 - acc: 0.9606 - val_loss: 0.1227 - val_acc: 0.9666\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.1099 - acc: 0.9686 - val_loss: 0.1263 - val_acc: 0.9664\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 10s 285us/sample - loss: 0.0930 - acc: 0.9735 - val_loss: 0.1187 - val_acc: 0.9668\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 10s 286us/sample - loss: 0.0804 - acc: 0.9767 - val_loss: 0.1008 - val_acc: 0.9732\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 288us/sample - loss: 0.0705 - acc: 0.9798 - val_loss: 0.1040 - val_acc: 0.9728\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.0641 - acc: 0.9822 - val_loss: 0.1040 - val_acc: 0.9738\n",
      "18333/18333 [==============================] - 3s 156us/sample - loss: 0.1229 - acc: 0.9678\n",
      "[CV] ..................................... n_neurons=70, total= 1.7min\n",
      "[CV] n_neurons=71 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 15s 411us/sample - loss: 0.3452 - acc: 0.9020 - val_loss: 0.2002 - val_acc: 0.9436\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 10s 284us/sample - loss: 0.1782 - acc: 0.9482 - val_loss: 0.1508 - val_acc: 0.9558\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 289us/sample - loss: 0.1324 - acc: 0.9614 - val_loss: 0.1278 - val_acc: 0.9632\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 10s 276us/sample - loss: 0.1072 - acc: 0.9683 - val_loss: 0.1236 - val_acc: 0.9632\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 10s 283us/sample - loss: 0.0892 - acc: 0.9741 - val_loss: 0.1151 - val_acc: 0.9666\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 287us/sample - loss: 0.0768 - acc: 0.9788 - val_loss: 0.1092 - val_acc: 0.9660\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 290us/sample - loss: 0.0665 - acc: 0.9809 - val_loss: 0.1067 - val_acc: 0.9708\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 288us/sample - loss: 0.0589 - acc: 0.9832 - val_loss: 0.1137 - val_acc: 0.9706\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 11s 289us/sample - loss: 0.0528 - acc: 0.9845 - val_loss: 0.1066 - val_acc: 0.9676\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 11s 291us/sample - loss: 0.0478 - acc: 0.9866 - val_loss: 0.1154 - val_acc: 0.9692\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 10s 285us/sample - loss: 0.0438 - acc: 0.9878 - val_loss: 0.1216 - val_acc: 0.9690\n",
      "18334/18334 [==============================] - 3s 163us/sample - loss: 0.1402 - acc: 0.9676\n",
      "[CV] ..................................... n_neurons=71, total= 2.2min\n",
      "[CV] n_neurons=71 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 414us/sample - loss: 0.3462 - acc: 0.9029 - val_loss: 0.2006 - val_acc: 0.9440\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.1804 - acc: 0.9485 - val_loss: 0.1492 - val_acc: 0.9586\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 309us/sample - loss: 0.1354 - acc: 0.9604 - val_loss: 0.1264 - val_acc: 0.9670\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 318us/sample - loss: 0.1101 - acc: 0.9682 - val_loss: 0.1375 - val_acc: 0.9604\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 290us/sample - loss: 0.0937 - acc: 0.9725 - val_loss: 0.1172 - val_acc: 0.9672\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 15s 417us/sample - loss: 0.0824 - acc: 0.9756 - val_loss: 0.1141 - val_acc: 0.9660\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 14s 388us/sample - loss: 0.0721 - acc: 0.9791 - val_loss: 0.1100 - val_acc: 0.9694\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 14s 383us/sample - loss: 0.0637 - acc: 0.9813 - val_loss: 0.1143 - val_acc: 0.9680\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 15s 420us/sample - loss: 0.0584 - acc: 0.9829 - val_loss: 0.1137 - val_acc: 0.9682\n",
      "18333/18333 [==============================] - 3s 187us/sample - loss: 0.1312 - acc: 0.9667\n",
      "[CV] ..................................... n_neurons=71, total= 2.2min\n",
      "[CV] n_neurons=71 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 17s 461us/sample - loss: 0.3476 - acc: 0.9027 - val_loss: 0.1956 - val_acc: 0.9442\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 291us/sample - loss: 0.1721 - acc: 0.9493 - val_loss: 0.1379 - val_acc: 0.9622\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.1282 - acc: 0.9620 - val_loss: 0.1273 - val_acc: 0.9650\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 290us/sample - loss: 0.1034 - acc: 0.9701 - val_loss: 0.1192 - val_acc: 0.9674\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 311us/sample - loss: 0.0864 - acc: 0.9752 - val_loss: 0.1168 - val_acc: 0.9676\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 303us/sample - loss: 0.0744 - acc: 0.9783 - val_loss: 0.1135 - val_acc: 0.9688\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 13s 357us/sample - loss: 0.0657 - acc: 0.9813 - val_loss: 0.1101 - val_acc: 0.9722\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 305us/sample - loss: 0.0577 - acc: 0.9843 - val_loss: 0.1024 - val_acc: 0.9720\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 301us/sample - loss: 0.0517 - acc: 0.9856 - val_loss: 0.1082 - val_acc: 0.9720\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 296us/sample - loss: 0.0474 - acc: 0.9867 - val_loss: 0.1063 - val_acc: 0.9732\n",
      "18333/18333 [==============================] - 3s 169us/sample - loss: 0.1228 - acc: 0.9687\n",
      "[CV] ..................................... n_neurons=71, total= 2.2min\n",
      "[CV] n_neurons=72 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 15s 415us/sample - loss: 0.3466 - acc: 0.9033 - val_loss: 0.2093 - val_acc: 0.9424\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 10s 273us/sample - loss: 0.1736 - acc: 0.9477 - val_loss: 0.1471 - val_acc: 0.9600\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 293us/sample - loss: 0.1304 - acc: 0.9620 - val_loss: 0.1289 - val_acc: 0.9632\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 292us/sample - loss: 0.1047 - acc: 0.9691 - val_loss: 0.1191 - val_acc: 0.9642\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 11s 292us/sample - loss: 0.0886 - acc: 0.9737 - val_loss: 0.1145 - val_acc: 0.9688\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 288us/sample - loss: 0.0762 - acc: 0.9771 - val_loss: 0.1046 - val_acc: 0.9730\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 313us/sample - loss: 0.0658 - acc: 0.9809 - val_loss: 0.1036 - val_acc: 0.9710\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 295us/sample - loss: 0.0586 - acc: 0.9834 - val_loss: 0.1002 - val_acc: 0.9734\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 11s 305us/sample - loss: 0.0515 - acc: 0.9851 - val_loss: 0.1052 - val_acc: 0.9722\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 11s 290us/sample - loss: 0.0466 - acc: 0.9867 - val_loss: 0.1228 - val_acc: 0.9706\n",
      "18334/18334 [==============================] - 3s 157us/sample - loss: 0.1393 - acc: 0.9646\n",
      "[CV] ..................................... n_neurons=72, total= 2.0min\n",
      "[CV] n_neurons=72 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 414us/sample - loss: 0.3361 - acc: 0.9062 - val_loss: 0.1917 - val_acc: 0.9454\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 290us/sample - loss: 0.1773 - acc: 0.9486 - val_loss: 0.1462 - val_acc: 0.9578\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 293us/sample - loss: 0.1339 - acc: 0.9618 - val_loss: 0.1221 - val_acc: 0.9636\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.1104 - acc: 0.9678 - val_loss: 0.1159 - val_acc: 0.9618\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 294us/sample - loss: 0.0936 - acc: 0.9729 - val_loss: 0.1186 - val_acc: 0.9648\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 294us/sample - loss: 0.0809 - acc: 0.9769 - val_loss: 0.1036 - val_acc: 0.9698\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.0706 - acc: 0.9801 - val_loss: 0.1053 - val_acc: 0.9686\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 296us/sample - loss: 0.0637 - acc: 0.9814 - val_loss: 0.1021 - val_acc: 0.9706\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 303us/sample - loss: 0.0564 - acc: 0.9834 - val_loss: 0.1020 - val_acc: 0.9712\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.0504 - acc: 0.9861 - val_loss: 0.1004 - val_acc: 0.9730\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 11s 293us/sample - loss: 0.0458 - acc: 0.9869 - val_loss: 0.1002 - val_acc: 0.9720\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.0409 - acc: 0.9885 - val_loss: 0.1094 - val_acc: 0.9698\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.0377 - acc: 0.9896 - val_loss: 0.1157 - val_acc: 0.9706\n",
      "18333/18333 [==============================] - 3s 159us/sample - loss: 0.1423 - acc: 0.9662\n",
      "[CV] ..................................... n_neurons=72, total= 2.6min\n",
      "[CV] n_neurons=72 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 414us/sample - loss: 0.3528 - acc: 0.9002 - val_loss: 0.1996 - val_acc: 0.9424\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 290us/sample - loss: 0.1807 - acc: 0.9471 - val_loss: 0.1594 - val_acc: 0.9548\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.1342 - acc: 0.9604 - val_loss: 0.1327 - val_acc: 0.9612\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 293us/sample - loss: 0.1079 - acc: 0.9690 - val_loss: 0.1200 - val_acc: 0.9658\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 297us/sample - loss: 0.0913 - acc: 0.9739 - val_loss: 0.1124 - val_acc: 0.9668\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.0798 - acc: 0.9771 - val_loss: 0.1114 - val_acc: 0.9680\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.0692 - acc: 0.9801 - val_loss: 0.1076 - val_acc: 0.9700\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 289us/sample - loss: 0.0609 - acc: 0.9828 - val_loss: 0.1121 - val_acc: 0.9690\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 294us/sample - loss: 0.0547 - acc: 0.9846 - val_loss: 0.1024 - val_acc: 0.9712\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 295us/sample - loss: 0.0496 - acc: 0.9858 - val_loss: 0.1042 - val_acc: 0.9706\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.0439 - acc: 0.9880 - val_loss: 0.1195 - val_acc: 0.9678\n",
      "18333/18333 [==============================] - 3s 163us/sample - loss: 0.1377 - acc: 0.9665\n",
      "[CV] ..................................... n_neurons=72, total= 2.2min\n",
      "[CV] n_neurons=73 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 15s 412us/sample - loss: 0.3520 - acc: 0.8994 - val_loss: 0.1991 - val_acc: 0.9450\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 11s 289us/sample - loss: 0.1796 - acc: 0.9477 - val_loss: 0.1498 - val_acc: 0.9576\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 291us/sample - loss: 0.1343 - acc: 0.9611 - val_loss: 0.1251 - val_acc: 0.9630\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 290us/sample - loss: 0.1080 - acc: 0.9694 - val_loss: 0.1140 - val_acc: 0.9640\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 11s 290us/sample - loss: 0.0904 - acc: 0.9747 - val_loss: 0.1163 - val_acc: 0.9650\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 295us/sample - loss: 0.0777 - acc: 0.9776 - val_loss: 0.1180 - val_acc: 0.9648\n",
      "18334/18334 [==============================] - 3s 166us/sample - loss: 0.1342 - acc: 0.9638\n",
      "[CV] ..................................... n_neurons=73, total= 1.3min\n",
      "[CV] n_neurons=73 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 423us/sample - loss: 0.3466 - acc: 0.9049 - val_loss: 0.2059 - val_acc: 0.9410\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.1818 - acc: 0.9471 - val_loss: 0.1604 - val_acc: 0.9550\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.1365 - acc: 0.9607 - val_loss: 0.1363 - val_acc: 0.9594\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 291us/sample - loss: 0.1109 - acc: 0.9676 - val_loss: 0.1242 - val_acc: 0.9634\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 294us/sample - loss: 0.0938 - acc: 0.9726 - val_loss: 0.1236 - val_acc: 0.9626\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 294us/sample - loss: 0.0813 - acc: 0.9759 - val_loss: 0.1152 - val_acc: 0.9660\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.0714 - acc: 0.9789 - val_loss: 0.1116 - val_acc: 0.9696\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 296us/sample - loss: 0.0623 - acc: 0.9816 - val_loss: 0.1175 - val_acc: 0.9678\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 293us/sample - loss: 0.0561 - acc: 0.9835 - val_loss: 0.1087 - val_acc: 0.9698\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 298us/sample - loss: 0.0500 - acc: 0.9854 - val_loss: 0.1119 - val_acc: 0.9698\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 11s 297us/sample - loss: 0.0440 - acc: 0.9872 - val_loss: 0.1060 - val_acc: 0.9744\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 11s 297us/sample - loss: 0.0392 - acc: 0.9879 - val_loss: 0.1125 - val_acc: 0.9716\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 11s 293us/sample - loss: 0.0363 - acc: 0.9898 - val_loss: 0.1112 - val_acc: 0.9728\n",
      "18333/18333 [==============================] - 3s 163us/sample - loss: 0.1312 - acc: 0.9677\n",
      "[CV] ..................................... n_neurons=73, total= 2.6min\n",
      "[CV] n_neurons=73 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 15s 416us/sample - loss: 0.3519 - acc: 0.9019 - val_loss: 0.2144 - val_acc: 0.9392\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 292us/sample - loss: 0.1835 - acc: 0.9460 - val_loss: 0.1428 - val_acc: 0.9560\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 293us/sample - loss: 0.1360 - acc: 0.9597 - val_loss: 0.1278 - val_acc: 0.9630\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 307us/sample - loss: 0.1095 - acc: 0.9675 - val_loss: 0.1088 - val_acc: 0.9662\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 293us/sample - loss: 0.0899 - acc: 0.9741 - val_loss: 0.1100 - val_acc: 0.9682\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 291us/sample - loss: 0.0783 - acc: 0.9775 - val_loss: 0.1104 - val_acc: 0.9686\n",
      "18333/18333 [==============================] - 3s 162us/sample - loss: 0.1324 - acc: 0.9648\n",
      "[CV] ..................................... n_neurons=73, total= 1.3min\n",
      "[CV] n_neurons=74 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 14s 392us/sample - loss: 0.3552 - acc: 0.8999 - val_loss: 0.2064 - val_acc: 0.9398\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 11s 308us/sample - loss: 0.1893 - acc: 0.9443 - val_loss: 0.1542 - val_acc: 0.9560\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 303us/sample - loss: 0.1421 - acc: 0.9584 - val_loss: 0.1298 - val_acc: 0.9618\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 294us/sample - loss: 0.1132 - acc: 0.9673 - val_loss: 0.1275 - val_acc: 0.9640\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 11s 293us/sample - loss: 0.0961 - acc: 0.9724 - val_loss: 0.1103 - val_acc: 0.9680\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 302us/sample - loss: 0.0811 - acc: 0.9773 - val_loss: 0.1052 - val_acc: 0.9678\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 296us/sample - loss: 0.0720 - acc: 0.9792 - val_loss: 0.1123 - val_acc: 0.9684\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 298us/sample - loss: 0.0642 - acc: 0.9815 - val_loss: 0.1135 - val_acc: 0.9702\n",
      "18334/18334 [==============================] - 3s 186us/sample - loss: 0.1354 - acc: 0.9648\n",
      "[CV] ..................................... n_neurons=74, total= 1.7min\n",
      "[CV] n_neurons=74 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 435us/sample - loss: 0.3355 - acc: 0.9067 - val_loss: 0.2195 - val_acc: 0.9356\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 301us/sample - loss: 0.1720 - acc: 0.9500 - val_loss: 0.1397 - val_acc: 0.9616\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.1285 - acc: 0.9629 - val_loss: 0.1175 - val_acc: 0.9682\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 307us/sample - loss: 0.1041 - acc: 0.9697 - val_loss: 0.1112 - val_acc: 0.9674\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.0887 - acc: 0.9749 - val_loss: 0.1057 - val_acc: 0.9690\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 301us/sample - loss: 0.0754 - acc: 0.9786 - val_loss: 0.1075 - val_acc: 0.9682\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 314us/sample - loss: 0.0663 - acc: 0.9811 - val_loss: 0.0975 - val_acc: 0.9698\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 297us/sample - loss: 0.0580 - acc: 0.9826 - val_loss: 0.1045 - val_acc: 0.9714\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 297us/sample - loss: 0.0514 - acc: 0.9845 - val_loss: 0.0968 - val_acc: 0.9726\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.0468 - acc: 0.9865 - val_loss: 0.1067 - val_acc: 0.9716\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.0416 - acc: 0.9887 - val_loss: 0.0978 - val_acc: 0.9750\n",
      "18333/18333 [==============================] - 3s 160us/sample - loss: 0.1289 - acc: 0.9686\n",
      "[CV] ..................................... n_neurons=74, total= 2.3min\n",
      "[CV] n_neurons=74 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 434us/sample - loss: 0.3416 - acc: 0.9041 - val_loss: 0.1945 - val_acc: 0.9426\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 305us/sample - loss: 0.1700 - acc: 0.9485 - val_loss: 0.1476 - val_acc: 0.9582\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 297us/sample - loss: 0.1270 - acc: 0.9626 - val_loss: 0.1252 - val_acc: 0.9630\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 295us/sample - loss: 0.1020 - acc: 0.9705 - val_loss: 0.1107 - val_acc: 0.9686\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.0855 - acc: 0.9748 - val_loss: 0.1041 - val_acc: 0.9714\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 306us/sample - loss: 0.0726 - acc: 0.9789 - val_loss: 0.1096 - val_acc: 0.9706\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 301us/sample - loss: 0.0646 - acc: 0.9815 - val_loss: 0.1064 - val_acc: 0.9716\n",
      "18333/18333 [==============================] - 3s 167us/sample - loss: 0.1268 - acc: 0.9678\n",
      "[CV] ..................................... n_neurons=74, total= 1.5min\n",
      "[CV] n_neurons=75 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 16s 448us/sample - loss: 0.3443 - acc: 0.9027 - val_loss: 0.1935 - val_acc: 0.9438\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 12s 318us/sample - loss: 0.1788 - acc: 0.9483 - val_loss: 0.1439 - val_acc: 0.9586\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 313us/sample - loss: 0.1338 - acc: 0.9613 - val_loss: 0.1294 - val_acc: 0.9644\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 303us/sample - loss: 0.1076 - acc: 0.9690 - val_loss: 0.1176 - val_acc: 0.9646\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 11s 307us/sample - loss: 0.0910 - acc: 0.9746 - val_loss: 0.1230 - val_acc: 0.9626\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 12s 322us/sample - loss: 0.0783 - acc: 0.9776 - val_loss: 0.1139 - val_acc: 0.9668\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 13s 344us/sample - loss: 0.0692 - acc: 0.9799 - val_loss: 0.1136 - val_acc: 0.9706\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 304us/sample - loss: 0.0613 - acc: 0.9827 - val_loss: 0.1126 - val_acc: 0.9706\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 11s 310us/sample - loss: 0.0552 - acc: 0.9839 - val_loss: 0.1121 - val_acc: 0.9692\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 11s 304us/sample - loss: 0.0486 - acc: 0.9862 - val_loss: 0.1109 - val_acc: 0.9692\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 11s 306us/sample - loss: 0.0433 - acc: 0.9880 - val_loss: 0.1179 - val_acc: 0.9688\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 11s 307us/sample - loss: 0.0403 - acc: 0.9886 - val_loss: 0.1253 - val_acc: 0.9698\n",
      "18334/18334 [==============================] - 3s 168us/sample - loss: 0.1472 - acc: 0.9645\n",
      "[CV] ..................................... n_neurons=75, total= 2.6min\n",
      "[CV] n_neurons=75 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 424us/sample - loss: 0.3398 - acc: 0.9054 - val_loss: 0.2003 - val_acc: 0.9418\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 301us/sample - loss: 0.1743 - acc: 0.9485 - val_loss: 0.1486 - val_acc: 0.9584\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 13s 355us/sample - loss: 0.1282 - acc: 0.9624 - val_loss: 0.1212 - val_acc: 0.9640\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 308us/sample - loss: 0.1054 - acc: 0.9689 - val_loss: 0.1143 - val_acc: 0.9672\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 301us/sample - loss: 0.0877 - acc: 0.9735 - val_loss: 0.1090 - val_acc: 0.9678\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 301us/sample - loss: 0.0773 - acc: 0.9770 - val_loss: 0.1099 - val_acc: 0.9680\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 339us/sample - loss: 0.0677 - acc: 0.9806 - val_loss: 0.1109 - val_acc: 0.9692\n",
      "18333/18333 [==============================] - 3s 168us/sample - loss: 0.1308 - acc: 0.9654\n",
      "[CV] ..................................... n_neurons=75, total= 1.6min\n",
      "[CV] n_neurons=75 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 428us/sample - loss: 0.3477 - acc: 0.9006 - val_loss: 0.2082 - val_acc: 0.9422\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 299us/sample - loss: 0.1877 - acc: 0.9443 - val_loss: 0.1557 - val_acc: 0.9562\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 303us/sample - loss: 0.1403 - acc: 0.9582 - val_loss: 0.1274 - val_acc: 0.9632\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 305us/sample - loss: 0.1113 - acc: 0.9675 - val_loss: 0.1248 - val_acc: 0.9640\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 298us/sample - loss: 0.0926 - acc: 0.9729 - val_loss: 0.1122 - val_acc: 0.9686\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 298us/sample - loss: 0.0801 - acc: 0.9767 - val_loss: 0.1059 - val_acc: 0.9712\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 301us/sample - loss: 0.0693 - acc: 0.9799 - val_loss: 0.1066 - val_acc: 0.9696\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.0604 - acc: 0.9826 - val_loss: 0.1183 - val_acc: 0.9682\n",
      "18333/18333 [==============================] - 3s 168us/sample - loss: 0.1290 - acc: 0.9677\n",
      "[CV] ..................................... n_neurons=75, total= 1.7min\n",
      "[CV] n_neurons=76 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 16s 429us/sample - loss: 0.3414 - acc: 0.9029 - val_loss: 0.2033 - val_acc: 0.9412\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 11s 299us/sample - loss: 0.1762 - acc: 0.9491 - val_loss: 0.1644 - val_acc: 0.9560\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 296us/sample - loss: 0.1344 - acc: 0.9612 - val_loss: 0.1337 - val_acc: 0.9620\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 298us/sample - loss: 0.1094 - acc: 0.9690 - val_loss: 0.1330 - val_acc: 0.9638\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 11s 295us/sample - loss: 0.0922 - acc: 0.9739 - val_loss: 0.1206 - val_acc: 0.9676\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 300us/sample - loss: 0.0807 - acc: 0.9769 - val_loss: 0.1253 - val_acc: 0.9664\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 295us/sample - loss: 0.0695 - acc: 0.9799 - val_loss: 0.1148 - val_acc: 0.9664\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 300us/sample - loss: 0.0620 - acc: 0.9826 - val_loss: 0.1173 - val_acc: 0.9680\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 11s 300us/sample - loss: 0.0555 - acc: 0.9841 - val_loss: 0.1221 - val_acc: 0.9680\n",
      "18334/18334 [==============================] - 3s 169us/sample - loss: 0.1353 - acc: 0.9661\n",
      "[CV] ..................................... n_neurons=76, total= 1.9min\n",
      "[CV] n_neurons=76 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 437us/sample - loss: 0.3493 - acc: 0.9034 - val_loss: 0.1987 - val_acc: 0.9422\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 309us/sample - loss: 0.1812 - acc: 0.9479 - val_loss: 0.1469 - val_acc: 0.9576\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 309us/sample - loss: 0.1351 - acc: 0.9619 - val_loss: 0.1338 - val_acc: 0.9616\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 300us/sample - loss: 0.1073 - acc: 0.9686 - val_loss: 0.1121 - val_acc: 0.9662\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 302us/sample - loss: 0.0901 - acc: 0.9733 - val_loss: 0.1052 - val_acc: 0.9694\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.0769 - acc: 0.9774 - val_loss: 0.1066 - val_acc: 0.9682\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.0665 - acc: 0.9809 - val_loss: 0.1063 - val_acc: 0.9698\n",
      "18333/18333 [==============================] - 3s 165us/sample - loss: 0.1243 - acc: 0.9671\n",
      "[CV] ..................................... n_neurons=76, total= 1.6min\n",
      "[CV] n_neurons=76 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 444us/sample - loss: 0.3568 - acc: 0.8989 - val_loss: 0.2043 - val_acc: 0.9420\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.1839 - acc: 0.9459 - val_loss: 0.1454 - val_acc: 0.9600\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 313us/sample - loss: 0.1354 - acc: 0.9608 - val_loss: 0.1275 - val_acc: 0.9608\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 301us/sample - loss: 0.1089 - acc: 0.9686 - val_loss: 0.1239 - val_acc: 0.9634\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 308us/sample - loss: 0.0911 - acc: 0.9736 - val_loss: 0.1083 - val_acc: 0.9664\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 306us/sample - loss: 0.0778 - acc: 0.9782 - val_loss: 0.1182 - val_acc: 0.9664\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 303us/sample - loss: 0.0695 - acc: 0.9802 - val_loss: 0.1199 - val_acc: 0.9658\n",
      "18333/18333 [==============================] - 3s 169us/sample - loss: 0.1357 - acc: 0.9622\n",
      "[CV] ..................................... n_neurons=76, total= 1.6min\n",
      "[CV] n_neurons=77 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 16s 428us/sample - loss: 0.3413 - acc: 0.9046 - val_loss: 0.2000 - val_acc: 0.9464\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 11s 307us/sample - loss: 0.1758 - acc: 0.9478 - val_loss: 0.1488 - val_acc: 0.9604\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 307us/sample - loss: 0.1296 - acc: 0.9617 - val_loss: 0.1193 - val_acc: 0.9646\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 307us/sample - loss: 0.1040 - acc: 0.9696 - val_loss: 0.1243 - val_acc: 0.9646\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 12s 318us/sample - loss: 0.0861 - acc: 0.9744 - val_loss: 0.1146 - val_acc: 0.9672\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 303us/sample - loss: 0.0756 - acc: 0.9780 - val_loss: 0.1040 - val_acc: 0.9688\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 306us/sample - loss: 0.0661 - acc: 0.9803 - val_loss: 0.1079 - val_acc: 0.9680\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 310us/sample - loss: 0.0572 - acc: 0.9833 - val_loss: 0.1011 - val_acc: 0.9714\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 11s 304us/sample - loss: 0.0500 - acc: 0.9857 - val_loss: 0.1101 - val_acc: 0.9708\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 11s 311us/sample - loss: 0.0446 - acc: 0.9870 - val_loss: 0.1193 - val_acc: 0.9696\n",
      "18334/18334 [==============================] - 3s 166us/sample - loss: 0.1382 - acc: 0.9648\n",
      "[CV] ..................................... n_neurons=77, total= 2.1min\n",
      "[CV] n_neurons=77 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 432us/sample - loss: 0.3425 - acc: 0.9042 - val_loss: 0.2030 - val_acc: 0.9412\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 318us/sample - loss: 0.1781 - acc: 0.9486 - val_loss: 0.1429 - val_acc: 0.9590\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 314us/sample - loss: 0.1318 - acc: 0.9608 - val_loss: 0.1347 - val_acc: 0.9626\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 315us/sample - loss: 0.1063 - acc: 0.9687 - val_loss: 0.1233 - val_acc: 0.9654\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 308us/sample - loss: 0.0897 - acc: 0.9736 - val_loss: 0.1125 - val_acc: 0.9694\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 308us/sample - loss: 0.0768 - acc: 0.9773 - val_loss: 0.1100 - val_acc: 0.9686\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.0653 - acc: 0.9809 - val_loss: 0.1168 - val_acc: 0.9680\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 306us/sample - loss: 0.0574 - acc: 0.9827 - val_loss: 0.1162 - val_acc: 0.9702\n",
      "18333/18333 [==============================] - 3s 170us/sample - loss: 0.1327 - acc: 0.9656\n",
      "[CV] ..................................... n_neurons=77, total= 1.8min\n",
      "[CV] n_neurons=77 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 17s 454us/sample - loss: 0.3470 - acc: 0.9011 - val_loss: 0.1880 - val_acc: 0.9484\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 319us/sample - loss: 0.1780 - acc: 0.9474 - val_loss: 0.1447 - val_acc: 0.9586\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 325us/sample - loss: 0.1317 - acc: 0.9614 - val_loss: 0.1233 - val_acc: 0.9648\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 314us/sample - loss: 0.1058 - acc: 0.9693 - val_loss: 0.1233 - val_acc: 0.9644\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.0884 - acc: 0.9746 - val_loss: 0.1112 - val_acc: 0.9682\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 305us/sample - loss: 0.0758 - acc: 0.9781 - val_loss: 0.1204 - val_acc: 0.9686\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.0664 - acc: 0.9815 - val_loss: 0.1138 - val_acc: 0.9690\n",
      "18333/18333 [==============================] - 3s 165us/sample - loss: 0.1368 - acc: 0.9642\n",
      "[CV] ..................................... n_neurons=77, total= 1.6min\n",
      "[CV] n_neurons=78 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 18s 483us/sample - loss: 0.3464 - acc: 0.9015 - val_loss: 0.2071 - val_acc: 0.9438\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 13s 349us/sample - loss: 0.1798 - acc: 0.9482 - val_loss: 0.1522 - val_acc: 0.9572\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 15s 396us/sample - loss: 0.1349 - acc: 0.9614 - val_loss: 0.1385 - val_acc: 0.9618\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 15s 399us/sample - loss: 0.1104 - acc: 0.9677 - val_loss: 0.1400 - val_acc: 0.9590\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 14s 391us/sample - loss: 0.0923 - acc: 0.9743 - val_loss: 0.1270 - val_acc: 0.9664\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 13s 365us/sample - loss: 0.0803 - acc: 0.9770 - val_loss: 0.1185 - val_acc: 0.9660\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 13s 359us/sample - loss: 0.0706 - acc: 0.9799 - val_loss: 0.1108 - val_acc: 0.9692\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 12s 319us/sample - loss: 0.0616 - acc: 0.9822 - val_loss: 0.1223 - val_acc: 0.9678\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 12s 315us/sample - loss: 0.0540 - acc: 0.9846 - val_loss: 0.1135 - val_acc: 0.9704\n",
      "18334/18334 [==============================] - 3s 173us/sample - loss: 0.1409 - acc: 0.9649\n",
      "[CV] ..................................... n_neurons=78, total= 2.3min\n",
      "[CV] n_neurons=78 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 17s 456us/sample - loss: 0.3443 - acc: 0.9051 - val_loss: 0.2051 - val_acc: 0.9444\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 317us/sample - loss: 0.1796 - acc: 0.9484 - val_loss: 0.1571 - val_acc: 0.9554\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 311us/sample - loss: 0.1336 - acc: 0.9618 - val_loss: 0.1391 - val_acc: 0.9584\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 315us/sample - loss: 0.1075 - acc: 0.9697 - val_loss: 0.1222 - val_acc: 0.9664\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 311us/sample - loss: 0.0899 - acc: 0.9742 - val_loss: 0.1181 - val_acc: 0.9674\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 309us/sample - loss: 0.0759 - acc: 0.9777 - val_loss: 0.1168 - val_acc: 0.9660\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 313us/sample - loss: 0.0663 - acc: 0.9805 - val_loss: 0.1160 - val_acc: 0.9686\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 317us/sample - loss: 0.0585 - acc: 0.9830 - val_loss: 0.1147 - val_acc: 0.9682\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 314us/sample - loss: 0.0512 - acc: 0.9847 - val_loss: 0.1313 - val_acc: 0.9628\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.0456 - acc: 0.9868 - val_loss: 0.1235 - val_acc: 0.9674\n",
      "18333/18333 [==============================] - 3s 165us/sample - loss: 0.1308 - acc: 0.9676\n",
      "[CV] ..................................... n_neurons=78, total= 2.2min\n",
      "[CV] n_neurons=78 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 444us/sample - loss: 0.3517 - acc: 0.8998 - val_loss: 0.2052 - val_acc: 0.9392\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 317us/sample - loss: 0.1796 - acc: 0.9474 - val_loss: 0.1428 - val_acc: 0.9568\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 312us/sample - loss: 0.1320 - acc: 0.9618 - val_loss: 0.1229 - val_acc: 0.9656\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 312us/sample - loss: 0.1043 - acc: 0.9692 - val_loss: 0.1117 - val_acc: 0.9646\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.0866 - acc: 0.9752 - val_loss: 0.1050 - val_acc: 0.9694\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 311us/sample - loss: 0.0737 - acc: 0.9788 - val_loss: 0.0996 - val_acc: 0.9706\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 318us/sample - loss: 0.0640 - acc: 0.9819 - val_loss: 0.1001 - val_acc: 0.9722\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 317us/sample - loss: 0.0558 - acc: 0.9837 - val_loss: 0.1043 - val_acc: 0.9712\n",
      "18333/18333 [==============================] - 3s 172us/sample - loss: 0.1287 - acc: 0.9659\n",
      "[CV] ..................................... n_neurons=78, total= 1.8min\n",
      "[CV] n_neurons=79 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 16s 445us/sample - loss: 0.3369 - acc: 0.9056 - val_loss: 0.1970 - val_acc: 0.9448\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 12s 316us/sample - loss: 0.1719 - acc: 0.9490 - val_loss: 0.1403 - val_acc: 0.9596\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 314us/sample - loss: 0.1281 - acc: 0.9623 - val_loss: 0.1322 - val_acc: 0.9600\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 12s 320us/sample - loss: 0.1046 - acc: 0.9694 - val_loss: 0.1228 - val_acc: 0.9642\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 12s 316us/sample - loss: 0.0877 - acc: 0.9741 - val_loss: 0.1084 - val_acc: 0.9674\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 12s 321us/sample - loss: 0.0761 - acc: 0.9784 - val_loss: 0.1124 - val_acc: 0.9690\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 12s 321us/sample - loss: 0.0664 - acc: 0.9811 - val_loss: 0.1026 - val_acc: 0.9728\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 12s 320us/sample - loss: 0.0576 - acc: 0.9833 - val_loss: 0.1069 - val_acc: 0.9716\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 11s 296us/sample - loss: 0.0513 - acc: 0.9856 - val_loss: 0.1136 - val_acc: 0.9694\n",
      "18334/18334 [==============================] - 2s 117us/sample - loss: 0.1298 - acc: 0.9677\n",
      "[CV] ..................................... n_neurons=79, total= 2.0min\n",
      "[CV] n_neurons=79 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 446us/sample - loss: 0.3395 - acc: 0.9041 - val_loss: 0.2027 - val_acc: 0.9434\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 314us/sample - loss: 0.1786 - acc: 0.9473 - val_loss: 0.1571 - val_acc: 0.9542\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 315us/sample - loss: 0.1315 - acc: 0.9612 - val_loss: 0.1254 - val_acc: 0.9638\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 315us/sample - loss: 0.1069 - acc: 0.9691 - val_loss: 0.1172 - val_acc: 0.9650\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 315us/sample - loss: 0.0881 - acc: 0.9740 - val_loss: 0.1161 - val_acc: 0.9652\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 323us/sample - loss: 0.0765 - acc: 0.9777 - val_loss: 0.1037 - val_acc: 0.9708\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 328us/sample - loss: 0.0656 - acc: 0.9804 - val_loss: 0.1124 - val_acc: 0.9664\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 328us/sample - loss: 0.0573 - acc: 0.9834 - val_loss: 0.1153 - val_acc: 0.9678\n",
      "18333/18333 [==============================] - 3s 177us/sample - loss: 0.1373 - acc: 0.9641\n",
      "[CV] ..................................... n_neurons=79, total= 1.8min\n",
      "[CV] n_neurons=79 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 449us/sample - loss: 0.3476 - acc: 0.9024 - val_loss: 0.1960 - val_acc: 0.9434\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 312us/sample - loss: 0.1790 - acc: 0.9478 - val_loss: 0.1563 - val_acc: 0.9546\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 314us/sample - loss: 0.1328 - acc: 0.9609 - val_loss: 0.1299 - val_acc: 0.9612\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 317us/sample - loss: 0.1057 - acc: 0.9689 - val_loss: 0.1174 - val_acc: 0.9642\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 319us/sample - loss: 0.0878 - acc: 0.9747 - val_loss: 0.1053 - val_acc: 0.9698\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 330us/sample - loss: 0.0758 - acc: 0.9789 - val_loss: 0.1020 - val_acc: 0.9710\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 332us/sample - loss: 0.0665 - acc: 0.9808 - val_loss: 0.1039 - val_acc: 0.9710\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 322us/sample - loss: 0.0579 - acc: 0.9833 - val_loss: 0.0985 - val_acc: 0.9718\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.0516 - acc: 0.9854 - val_loss: 0.1013 - val_acc: 0.9712\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 12s 332us/sample - loss: 0.0463 - acc: 0.9878 - val_loss: 0.1109 - val_acc: 0.9718\n",
      "18333/18333 [==============================] - 3s 176us/sample - loss: 0.1329 - acc: 0.9672\n",
      "[CV] ..................................... n_neurons=79, total= 2.2min\n",
      "[CV] n_neurons=80 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 16s 436us/sample - loss: 0.3419 - acc: 0.9036 - val_loss: 0.1993 - val_acc: 0.9452\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 11s 311us/sample - loss: 0.1785 - acc: 0.9485 - val_loss: 0.1560 - val_acc: 0.9566\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 311us/sample - loss: 0.1353 - acc: 0.9605 - val_loss: 0.1299 - val_acc: 0.9604\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 12s 323us/sample - loss: 0.1081 - acc: 0.9692 - val_loss: 0.1209 - val_acc: 0.9660\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 11s 309us/sample - loss: 0.0916 - acc: 0.9741 - val_loss: 0.1167 - val_acc: 0.9682\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 313us/sample - loss: 0.0781 - acc: 0.9774 - val_loss: 0.1090 - val_acc: 0.9684\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 12s 324us/sample - loss: 0.0704 - acc: 0.9808 - val_loss: 0.1152 - val_acc: 0.9664\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 313us/sample - loss: 0.0615 - acc: 0.9825 - val_loss: 0.1056 - val_acc: 0.9706\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 12s 315us/sample - loss: 0.0544 - acc: 0.9849 - val_loss: 0.1074 - val_acc: 0.9718\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 11s 302us/sample - loss: 0.0481 - acc: 0.9867 - val_loss: 0.1134 - val_acc: 0.9704\n",
      "18334/18334 [==============================] - 3s 176us/sample - loss: 0.1332 - acc: 0.9669\n",
      "[CV] ..................................... n_neurons=80, total= 2.2min\n",
      "[CV] n_neurons=80 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 446us/sample - loss: 0.3327 - acc: 0.9053 - val_loss: 0.1908 - val_acc: 0.9476\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 304us/sample - loss: 0.1664 - acc: 0.9515 - val_loss: 0.1407 - val_acc: 0.9570\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 308us/sample - loss: 0.1216 - acc: 0.9632 - val_loss: 0.1206 - val_acc: 0.9640\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 303us/sample - loss: 0.0960 - acc: 0.9717 - val_loss: 0.1162 - val_acc: 0.9652\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.0819 - acc: 0.9758 - val_loss: 0.1010 - val_acc: 0.9706\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 311us/sample - loss: 0.0692 - acc: 0.9797 - val_loss: 0.1027 - val_acc: 0.9694\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 318us/sample - loss: 0.0596 - acc: 0.9825 - val_loss: 0.1020 - val_acc: 0.9694\n",
      "18333/18333 [==============================] - 3s 176us/sample - loss: 0.1274 - acc: 0.9665\n",
      "[CV] ..................................... n_neurons=80, total= 1.6min\n",
      "[CV] n_neurons=80 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 440us/sample - loss: 0.3477 - acc: 0.9030 - val_loss: 0.2026 - val_acc: 0.9440\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 314us/sample - loss: 0.1745 - acc: 0.9486 - val_loss: 0.1385 - val_acc: 0.9610\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 313us/sample - loss: 0.1271 - acc: 0.9624 - val_loss: 0.1220 - val_acc: 0.9654\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 315us/sample - loss: 0.1018 - acc: 0.9696 - val_loss: 0.1144 - val_acc: 0.9672\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 316us/sample - loss: 0.0844 - acc: 0.9755 - val_loss: 0.1051 - val_acc: 0.9690\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 318us/sample - loss: 0.0716 - acc: 0.9791 - val_loss: 0.1071 - val_acc: 0.9706\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 330us/sample - loss: 0.0628 - acc: 0.9824 - val_loss: 0.1147 - val_acc: 0.9692\n",
      "18333/18333 [==============================] - 3s 173us/sample - loss: 0.1293 - acc: 0.9658\n",
      "[CV] ..................................... n_neurons=80, total= 1.6min\n",
      "[CV] n_neurons=81 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 16s 447us/sample - loss: 0.3422 - acc: 0.9027 - val_loss: 0.1866 - val_acc: 0.9474\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 10s 273us/sample - loss: 0.1735 - acc: 0.9496 - val_loss: 0.1417 - val_acc: 0.9606\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 312us/sample - loss: 0.1287 - acc: 0.9618 - val_loss: 0.1266 - val_acc: 0.9648\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 12s 322us/sample - loss: 0.1034 - acc: 0.9705 - val_loss: 0.1196 - val_acc: 0.9666\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 12s 317us/sample - loss: 0.0879 - acc: 0.9741 - val_loss: 0.1165 - val_acc: 0.9672\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 11s 308us/sample - loss: 0.0753 - acc: 0.9787 - val_loss: 0.1096 - val_acc: 0.9682\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 12s 322us/sample - loss: 0.0663 - acc: 0.9806 - val_loss: 0.1046 - val_acc: 0.9720\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 12s 315us/sample - loss: 0.0575 - acc: 0.9831 - val_loss: 0.1089 - val_acc: 0.9698\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 11s 310us/sample - loss: 0.0506 - acc: 0.9860 - val_loss: 0.1051 - val_acc: 0.9738\n",
      "18334/18334 [==============================] - 3s 176us/sample - loss: 0.1270 - acc: 0.9680\n",
      "[CV] ..................................... n_neurons=81, total= 2.0min\n",
      "[CV] n_neurons=81 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 17s 451us/sample - loss: 0.3372 - acc: 0.9055 - val_loss: 0.1920 - val_acc: 0.9436\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 319us/sample - loss: 0.1717 - acc: 0.9501 - val_loss: 0.1445 - val_acc: 0.9580\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 312us/sample - loss: 0.1273 - acc: 0.9632 - val_loss: 0.1202 - val_acc: 0.9638\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 321us/sample - loss: 0.1009 - acc: 0.9704 - val_loss: 0.1080 - val_acc: 0.9686\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 317us/sample - loss: 0.0841 - acc: 0.9750 - val_loss: 0.1139 - val_acc: 0.9654\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 314us/sample - loss: 0.0719 - acc: 0.9790 - val_loss: 0.1065 - val_acc: 0.9686\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 309us/sample - loss: 0.0618 - acc: 0.9817 - val_loss: 0.1064 - val_acc: 0.9702\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 312us/sample - loss: 0.0547 - acc: 0.9840 - val_loss: 0.1084 - val_acc: 0.9682\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 321us/sample - loss: 0.0479 - acc: 0.9861 - val_loss: 0.1154 - val_acc: 0.9694\n",
      "18333/18333 [==============================] - 3s 175us/sample - loss: 0.1387 - acc: 0.9643\n",
      "[CV] ..................................... n_neurons=81, total= 2.0min\n",
      "[CV] n_neurons=81 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 438us/sample - loss: 0.3527 - acc: 0.9005 - val_loss: 0.2187 - val_acc: 0.9394\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.1831 - acc: 0.9474 - val_loss: 0.1513 - val_acc: 0.9570\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 11s 307us/sample - loss: 0.1327 - acc: 0.9614 - val_loss: 0.1227 - val_acc: 0.9650\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.1064 - acc: 0.9686 - val_loss: 0.1160 - val_acc: 0.9656\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 316us/sample - loss: 0.0884 - acc: 0.9744 - val_loss: 0.1111 - val_acc: 0.9684\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 312us/sample - loss: 0.0740 - acc: 0.9788 - val_loss: 0.1114 - val_acc: 0.9704\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 308us/sample - loss: 0.0668 - acc: 0.9811 - val_loss: 0.1050 - val_acc: 0.9720\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 313us/sample - loss: 0.0578 - acc: 0.9843 - val_loss: 0.1052 - val_acc: 0.9712\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.0514 - acc: 0.9860 - val_loss: 0.1148 - val_acc: 0.9702\n",
      "18333/18333 [==============================] - 3s 180us/sample - loss: 0.1305 - acc: 0.9679\n",
      "[CV] ..................................... n_neurons=81, total= 2.0min\n",
      "[CV] n_neurons=82 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 16s 444us/sample - loss: 0.3410 - acc: 0.9040 - val_loss: 0.1947 - val_acc: 0.9462\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 12s 314us/sample - loss: 0.1713 - acc: 0.9503 - val_loss: 0.1389 - val_acc: 0.9600\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 313us/sample - loss: 0.1264 - acc: 0.9629 - val_loss: 0.1272 - val_acc: 0.9654\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 312us/sample - loss: 0.1016 - acc: 0.9700 - val_loss: 0.1139 - val_acc: 0.9686\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 12s 316us/sample - loss: 0.0852 - acc: 0.9751 - val_loss: 0.1121 - val_acc: 0.9692\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 12s 321us/sample - loss: 0.0716 - acc: 0.9795 - val_loss: 0.1097 - val_acc: 0.9706\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 11s 313us/sample - loss: 0.0628 - acc: 0.9818 - val_loss: 0.1024 - val_acc: 0.9726\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 11s 312us/sample - loss: 0.0544 - acc: 0.9844 - val_loss: 0.1048 - val_acc: 0.9726\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 12s 316us/sample - loss: 0.0468 - acc: 0.9858 - val_loss: 0.1137 - val_acc: 0.9702\n",
      "18334/18334 [==============================] - 3s 180us/sample - loss: 0.1333 - acc: 0.9667\n",
      "[CV] ..................................... n_neurons=82, total= 2.0min\n",
      "[CV] n_neurons=82 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 448us/sample - loss: 0.3441 - acc: 0.9038 - val_loss: 0.1982 - val_acc: 0.9454\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 335us/sample - loss: 0.1775 - acc: 0.9490 - val_loss: 0.1525 - val_acc: 0.9586\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 316us/sample - loss: 0.1329 - acc: 0.9623 - val_loss: 0.1343 - val_acc: 0.9604\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 319us/sample - loss: 0.1069 - acc: 0.9698 - val_loss: 0.1207 - val_acc: 0.9642\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 317us/sample - loss: 0.0902 - acc: 0.9743 - val_loss: 0.1068 - val_acc: 0.9696\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 321us/sample - loss: 0.0776 - acc: 0.9781 - val_loss: 0.1109 - val_acc: 0.9684\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 319us/sample - loss: 0.0673 - acc: 0.9807 - val_loss: 0.1070 - val_acc: 0.9696\n",
      "18333/18333 [==============================] - 3s 182us/sample - loss: 0.1306 - acc: 0.9653\n",
      "[CV] ..................................... n_neurons=82, total= 1.7min\n",
      "[CV] n_neurons=82 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 16s 449us/sample - loss: 0.3460 - acc: 0.9035 - val_loss: 0.1901 - val_acc: 0.9452\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 332us/sample - loss: 0.1722 - acc: 0.9500 - val_loss: 0.1446 - val_acc: 0.9602\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 331us/sample - loss: 0.1274 - acc: 0.9626 - val_loss: 0.1224 - val_acc: 0.9648\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 325us/sample - loss: 0.1009 - acc: 0.9702 - val_loss: 0.1120 - val_acc: 0.9704\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 314us/sample - loss: 0.0850 - acc: 0.9755 - val_loss: 0.1080 - val_acc: 0.9674\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 11s 312us/sample - loss: 0.0730 - acc: 0.9789 - val_loss: 0.1049 - val_acc: 0.9718\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.0634 - acc: 0.9823 - val_loss: 0.1013 - val_acc: 0.9732\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 308us/sample - loss: 0.0549 - acc: 0.9845 - val_loss: 0.1083 - val_acc: 0.9710\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 316us/sample - loss: 0.0484 - acc: 0.9861 - val_loss: 0.0990 - val_acc: 0.9732\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 12s 324us/sample - loss: 0.0438 - acc: 0.9877 - val_loss: 0.0999 - val_acc: 0.9752\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 11s 310us/sample - loss: 0.0402 - acc: 0.9894 - val_loss: 0.1063 - val_acc: 0.9726\n",
      "18333/18333 [==============================] - 3s 176us/sample - loss: 0.1278 - acc: 0.9700\n",
      "[CV] ..................................... n_neurons=82, total= 2.4min\n",
      "[CV] n_neurons=83 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 16s 443us/sample - loss: 0.3446 - acc: 0.9035 - val_loss: 0.2054 - val_acc: 0.9430\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 12s 320us/sample - loss: 0.1773 - acc: 0.9488 - val_loss: 0.1559 - val_acc: 0.9544\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 12s 327us/sample - loss: 0.1311 - acc: 0.9619 - val_loss: 0.1307 - val_acc: 0.9614\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 12s 338us/sample - loss: 0.1050 - acc: 0.9691 - val_loss: 0.1309 - val_acc: 0.9610\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 12s 330us/sample - loss: 0.0874 - acc: 0.9744 - val_loss: 0.1118 - val_acc: 0.9688\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 12s 338us/sample - loss: 0.0737 - acc: 0.9787 - val_loss: 0.1117 - val_acc: 0.9696\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 15s 403us/sample - loss: 0.0646 - acc: 0.9810 - val_loss: 0.1188 - val_acc: 0.9678\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 14s 382us/sample - loss: 0.0562 - acc: 0.9838 - val_loss: 0.1119 - val_acc: 0.9694\n",
      "18334/18334 [==============================] - 4s 207us/sample - loss: 0.1270 - acc: 0.9673\n",
      "[CV] ..................................... n_neurons=83, total= 2.0min\n",
      "[CV] n_neurons=83 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 23s 619us/sample - loss: 0.3444 - acc: 0.9036 - val_loss: 0.1983 - val_acc: 0.9428\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 341us/sample - loss: 0.1747 - acc: 0.9501 - val_loss: 0.1488 - val_acc: 0.9574\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 13s 353us/sample - loss: 0.1272 - acc: 0.9636 - val_loss: 0.1310 - val_acc: 0.9616\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 349us/sample - loss: 0.1018 - acc: 0.9695 - val_loss: 0.1185 - val_acc: 0.9646\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 13s 345us/sample - loss: 0.0853 - acc: 0.9749 - val_loss: 0.1100 - val_acc: 0.9662\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 349us/sample - loss: 0.0720 - acc: 0.9791 - val_loss: 0.1042 - val_acc: 0.9700\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 328us/sample - loss: 0.0630 - acc: 0.9818 - val_loss: 0.1018 - val_acc: 0.9720\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 322us/sample - loss: 0.0556 - acc: 0.9839 - val_loss: 0.1050 - val_acc: 0.9708\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.0489 - acc: 0.9853 - val_loss: 0.1017 - val_acc: 0.9724\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 12s 326us/sample - loss: 0.0420 - acc: 0.9884 - val_loss: 0.1121 - val_acc: 0.9728\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.0372 - acc: 0.9896 - val_loss: 0.1038 - val_acc: 0.9742\n",
      "18333/18333 [==============================] - 3s 186us/sample - loss: 0.1299 - acc: 0.9700\n",
      "[CV] ..................................... n_neurons=83, total= 2.6min\n",
      "[CV] n_neurons=83 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 17s 469us/sample - loss: 0.3437 - acc: 0.9023 - val_loss: 0.1881 - val_acc: 0.9450\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 325us/sample - loss: 0.1741 - acc: 0.9481 - val_loss: 0.1384 - val_acc: 0.9602\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 323us/sample - loss: 0.1282 - acc: 0.9611 - val_loss: 0.1151 - val_acc: 0.9654\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 317us/sample - loss: 0.1025 - acc: 0.9700 - val_loss: 0.1110 - val_acc: 0.9664\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 315us/sample - loss: 0.0850 - acc: 0.9751 - val_loss: 0.1012 - val_acc: 0.9690\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 316us/sample - loss: 0.0721 - acc: 0.9794 - val_loss: 0.0965 - val_acc: 0.9698\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 324us/sample - loss: 0.0621 - acc: 0.9821 - val_loss: 0.1019 - val_acc: 0.9706\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 323us/sample - loss: 0.0546 - acc: 0.9849 - val_loss: 0.0982 - val_acc: 0.9712\n",
      "18333/18333 [==============================] - 3s 187us/sample - loss: 0.1216 - acc: 0.9683\n",
      "[CV] ..................................... n_neurons=83, total= 1.9min\n",
      "[CV] n_neurons=84 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 17s 464us/sample - loss: 0.3277 - acc: 0.9077 - val_loss: 0.1810 - val_acc: 0.9482\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 12s 323us/sample - loss: 0.1655 - acc: 0.9516 - val_loss: 0.1388 - val_acc: 0.9606\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 12s 323us/sample - loss: 0.1236 - acc: 0.9641 - val_loss: 0.1218 - val_acc: 0.9656\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 12s 328us/sample - loss: 0.0984 - acc: 0.9710 - val_loss: 0.1100 - val_acc: 0.9676\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 12s 329us/sample - loss: 0.0827 - acc: 0.9762 - val_loss: 0.1153 - val_acc: 0.9660\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 12s 332us/sample - loss: 0.0699 - acc: 0.9796 - val_loss: 0.1135 - val_acc: 0.9674\n",
      "18334/18334 [==============================] - 3s 188us/sample - loss: 0.1337 - acc: 0.9639\n",
      "[CV] ..................................... n_neurons=84, total= 1.5min\n",
      "[CV] n_neurons=84 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 17s 457us/sample - loss: 0.3343 - acc: 0.9066 - val_loss: 0.1944 - val_acc: 0.9434\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 13s 358us/sample - loss: 0.1704 - acc: 0.9507 - val_loss: 0.1435 - val_acc: 0.9596\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 13s 343us/sample - loss: 0.1266 - acc: 0.9632 - val_loss: 0.1256 - val_acc: 0.9630\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 341us/sample - loss: 0.1001 - acc: 0.9701 - val_loss: 0.1186 - val_acc: 0.9620\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 330us/sample - loss: 0.0828 - acc: 0.9761 - val_loss: 0.1151 - val_acc: 0.9682\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 328us/sample - loss: 0.0703 - acc: 0.9795 - val_loss: 0.1079 - val_acc: 0.9676\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 13s 347us/sample - loss: 0.0610 - acc: 0.9825 - val_loss: 0.1100 - val_acc: 0.9686\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 12s 326us/sample - loss: 0.0526 - acc: 0.9848 - val_loss: 0.1120 - val_acc: 0.9682\n",
      "18333/18333 [==============================] - 3s 188us/sample - loss: 0.1302 - acc: 0.9670\n",
      "[CV] ..................................... n_neurons=84, total= 1.9min\n",
      "[CV] n_neurons=84 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 17s 462us/sample - loss: 0.3420 - acc: 0.9045 - val_loss: 0.1858 - val_acc: 0.9470\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 328us/sample - loss: 0.1689 - acc: 0.9506 - val_loss: 0.1490 - val_acc: 0.9578\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 323us/sample - loss: 0.1251 - acc: 0.9633 - val_loss: 0.1211 - val_acc: 0.9642\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 325us/sample - loss: 0.0993 - acc: 0.9711 - val_loss: 0.1193 - val_acc: 0.9670\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.0839 - acc: 0.9758 - val_loss: 0.1061 - val_acc: 0.9696\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.0725 - acc: 0.9789 - val_loss: 0.1041 - val_acc: 0.9692\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 322us/sample - loss: 0.0615 - acc: 0.9814 - val_loss: 0.1109 - val_acc: 0.9686\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 11s 311us/sample - loss: 0.0545 - acc: 0.9846 - val_loss: 0.1019 - val_acc: 0.9736\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 330us/sample - loss: 0.0495 - acc: 0.9860 - val_loss: 0.1010 - val_acc: 0.9738\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 12s 325us/sample - loss: 0.0428 - acc: 0.9876 - val_loss: 0.1062 - val_acc: 0.9716\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 12s 323us/sample - loss: 0.0387 - acc: 0.9892 - val_loss: 0.1165 - val_acc: 0.9694\n",
      "18333/18333 [==============================] - 4s 192us/sample - loss: 0.1297 - acc: 0.9695\n",
      "[CV] ..................................... n_neurons=84, total= 2.5min\n",
      "[CV] n_neurons=85 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 17s 462us/sample - loss: 0.3423 - acc: 0.9037 - val_loss: 0.1989 - val_acc: 0.9418\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 12s 319us/sample - loss: 0.1726 - acc: 0.9505 - val_loss: 0.1565 - val_acc: 0.9584\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 11s 306us/sample - loss: 0.1284 - acc: 0.9626 - val_loss: 0.1222 - val_acc: 0.9652\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 11s 302us/sample - loss: 0.1030 - acc: 0.9696 - val_loss: 0.1149 - val_acc: 0.9678\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 11s 307us/sample - loss: 0.0852 - acc: 0.9744 - val_loss: 0.1180 - val_acc: 0.9680\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 12s 332us/sample - loss: 0.0736 - acc: 0.9786 - val_loss: 0.1154 - val_acc: 0.9674\n",
      "18334/18334 [==============================] - 4s 202us/sample - loss: 0.1306 - acc: 0.9636\n",
      "[CV] ..................................... n_neurons=85, total= 1.5min\n",
      "[CV] n_neurons=85 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 21s 568us/sample - loss: 0.3327 - acc: 0.9061 - val_loss: 0.1882 - val_acc: 0.9442\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 341us/sample - loss: 0.1681 - acc: 0.9500 - val_loss: 0.1466 - val_acc: 0.9548\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 329us/sample - loss: 0.1246 - acc: 0.9630 - val_loss: 0.1224 - val_acc: 0.9620\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 349us/sample - loss: 0.0992 - acc: 0.9710 - val_loss: 0.1158 - val_acc: 0.9686\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 337us/sample - loss: 0.0823 - acc: 0.9761 - val_loss: 0.1112 - val_acc: 0.9680\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 337us/sample - loss: 0.0713 - acc: 0.9798 - val_loss: 0.1113 - val_acc: 0.9678\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 339us/sample - loss: 0.0616 - acc: 0.9824 - val_loss: 0.1169 - val_acc: 0.9674\n",
      "18333/18333 [==============================] - 3s 187us/sample - loss: 0.1318 - acc: 0.9648\n",
      "[CV] ..................................... n_neurons=85, total= 1.8min\n",
      "[CV] n_neurons=85 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 18s 493us/sample - loss: 0.3407 - acc: 0.9043 - val_loss: 0.2021 - val_acc: 0.9412\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 334us/sample - loss: 0.1693 - acc: 0.9504 - val_loss: 0.1363 - val_acc: 0.9608\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 15s 421us/sample - loss: 0.1233 - acc: 0.9638 - val_loss: 0.1157 - val_acc: 0.9660\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 15s 411us/sample - loss: 0.0985 - acc: 0.9713 - val_loss: 0.1131 - val_acc: 0.9660\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 14s 386us/sample - loss: 0.0825 - acc: 0.9756 - val_loss: 0.1056 - val_acc: 0.9706\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 14s 391us/sample - loss: 0.0716 - acc: 0.9797 - val_loss: 0.1054 - val_acc: 0.9716\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 19s 516us/sample - loss: 0.0612 - acc: 0.9826 - val_loss: 0.1048 - val_acc: 0.9708\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 13s 361us/sample - loss: 0.0548 - acc: 0.9845 - val_loss: 0.0956 - val_acc: 0.9746\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 340us/sample - loss: 0.0467 - acc: 0.9866 - val_loss: 0.1018 - val_acc: 0.9716\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 16s 440us/sample - loss: 0.0419 - acc: 0.9885 - val_loss: 0.1056 - val_acc: 0.9728\n",
      "18333/18333 [==============================] - 4s 210us/sample - loss: 0.1371 - acc: 0.9678\n",
      "[CV] ..................................... n_neurons=85, total= 2.7min\n",
      "[CV] n_neurons=86 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 19s 512us/sample - loss: 0.3302 - acc: 0.9049 - val_loss: 0.1919 - val_acc: 0.9442\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 13s 345us/sample - loss: 0.1692 - acc: 0.9504 - val_loss: 0.1455 - val_acc: 0.9612\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 14s 377us/sample - loss: 0.1235 - acc: 0.9642 - val_loss: 0.1239 - val_acc: 0.9650\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 13s 360us/sample - loss: 0.0983 - acc: 0.9713 - val_loss: 0.1122 - val_acc: 0.9662\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 14s 385us/sample - loss: 0.0834 - acc: 0.9749 - val_loss: 0.1061 - val_acc: 0.9672\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 12s 325us/sample - loss: 0.0701 - acc: 0.9798 - val_loss: 0.1104 - val_acc: 0.9666\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 12s 324us/sample - loss: 0.0623 - acc: 0.9818 - val_loss: 0.1038 - val_acc: 0.9694\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 12s 324us/sample - loss: 0.0544 - acc: 0.9849 - val_loss: 0.0991 - val_acc: 0.9716\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 12s 324us/sample - loss: 0.0483 - acc: 0.9866 - val_loss: 0.1066 - val_acc: 0.9682\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 12s 320us/sample - loss: 0.0428 - acc: 0.9879 - val_loss: 0.1087 - val_acc: 0.9718\n",
      "18334/18334 [==============================] - 4s 201us/sample - loss: 0.1238 - acc: 0.9687\n",
      "[CV] ..................................... n_neurons=86, total= 2.5min\n",
      "[CV] n_neurons=86 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 18s 478us/sample - loss: 0.3300 - acc: 0.9069 - val_loss: 0.1904 - val_acc: 0.9444\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 327us/sample - loss: 0.1653 - acc: 0.9525 - val_loss: 0.1412 - val_acc: 0.9608\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.1221 - acc: 0.9643 - val_loss: 0.1232 - val_acc: 0.9646\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 316us/sample - loss: 0.0951 - acc: 0.9729 - val_loss: 0.1117 - val_acc: 0.9670\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 321us/sample - loss: 0.0788 - acc: 0.9778 - val_loss: 0.1052 - val_acc: 0.9678\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 321us/sample - loss: 0.0659 - acc: 0.9812 - val_loss: 0.1076 - val_acc: 0.9706\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.0583 - acc: 0.9836 - val_loss: 0.1069 - val_acc: 0.9702\n",
      "18333/18333 [==============================] - 3s 187us/sample - loss: 0.1178 - acc: 0.9681\n",
      "[CV] ..................................... n_neurons=86, total= 1.7min\n",
      "[CV] n_neurons=86 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 17s 472us/sample - loss: 0.3389 - acc: 0.9047 - val_loss: 0.2033 - val_acc: 0.9408\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 322us/sample - loss: 0.1693 - acc: 0.9507 - val_loss: 0.1472 - val_acc: 0.9558\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 321us/sample - loss: 0.1250 - acc: 0.9633 - val_loss: 0.1179 - val_acc: 0.9650\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 320us/sample - loss: 0.1011 - acc: 0.9712 - val_loss: 0.1080 - val_acc: 0.9666\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 12s 319us/sample - loss: 0.0838 - acc: 0.9755 - val_loss: 0.1035 - val_acc: 0.9678\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 322us/sample - loss: 0.0733 - acc: 0.9785 - val_loss: 0.1003 - val_acc: 0.9716\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 12s 337us/sample - loss: 0.0627 - acc: 0.9824 - val_loss: 0.0985 - val_acc: 0.9706\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 14s 388us/sample - loss: 0.0547 - acc: 0.9851 - val_loss: 0.1124 - val_acc: 0.9688\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 12s 333us/sample - loss: 0.0490 - acc: 0.9863 - val_loss: 0.0965 - val_acc: 0.9746\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 12s 327us/sample - loss: 0.0432 - acc: 0.9875 - val_loss: 0.0989 - val_acc: 0.9734\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 15s 415us/sample - loss: 0.0391 - acc: 0.9896 - val_loss: 0.1103 - val_acc: 0.9724\n",
      "18333/18333 [==============================] - 5s 252us/sample - loss: 0.1345 - acc: 0.9687\n",
      "[CV] ..................................... n_neurons=86, total= 2.6min\n",
      "[CV] n_neurons=87 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 24s 658us/sample - loss: 0.3313 - acc: 0.9059 - val_loss: 0.1916 - val_acc: 0.9434\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 15s 418us/sample - loss: 0.1691 - acc: 0.9499 - val_loss: 0.1557 - val_acc: 0.9548\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 15s 419us/sample - loss: 0.1256 - acc: 0.9628 - val_loss: 0.1315 - val_acc: 0.9630\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 15s 419us/sample - loss: 0.1016 - acc: 0.9701 - val_loss: 0.1178 - val_acc: 0.9660\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 15s 417us/sample - loss: 0.0833 - acc: 0.9755 - val_loss: 0.1145 - val_acc: 0.9660\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 15s 418us/sample - loss: 0.0715 - acc: 0.9795 - val_loss: 0.1047 - val_acc: 0.9698\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 15s 419us/sample - loss: 0.0619 - acc: 0.9822 - val_loss: 0.1119 - val_acc: 0.9702\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 16s 425us/sample - loss: 0.0544 - acc: 0.9847 - val_loss: 0.1029 - val_acc: 0.9716\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 15s 420us/sample - loss: 0.0486 - acc: 0.9861 - val_loss: 0.1043 - val_acc: 0.9704\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 15s 420us/sample - loss: 0.0422 - acc: 0.9877 - val_loss: 0.1047 - val_acc: 0.9756\n",
      "18334/18334 [==============================] - 5s 255us/sample - loss: 0.1266 - acc: 0.9689\n",
      "[CV] ..................................... n_neurons=87, total= 3.0min\n",
      "[CV] n_neurons=87 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 24s 648us/sample - loss: 0.3365 - acc: 0.9054 - val_loss: 0.2015 - val_acc: 0.9438\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 17s 455us/sample - loss: 0.1727 - acc: 0.9494 - val_loss: 0.1455 - val_acc: 0.9582\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 15s 417us/sample - loss: 0.1281 - acc: 0.9622 - val_loss: 0.1249 - val_acc: 0.9646\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 16s 431us/sample - loss: 0.1032 - acc: 0.9700 - val_loss: 0.1220 - val_acc: 0.9660\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 15s 420us/sample - loss: 0.0852 - acc: 0.9749 - val_loss: 0.1108 - val_acc: 0.9680\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 15s 420us/sample - loss: 0.0737 - acc: 0.9786 - val_loss: 0.1038 - val_acc: 0.9696\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 16s 428us/sample - loss: 0.0624 - acc: 0.9821 - val_loss: 0.1068 - val_acc: 0.9722\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 15s 419us/sample - loss: 0.0561 - acc: 0.9839 - val_loss: 0.1100 - val_acc: 0.9708\n",
      "18333/18333 [==============================] - 5s 254us/sample - loss: 0.1267 - acc: 0.9675\n",
      "[CV] ..................................... n_neurons=87, total= 2.5min\n",
      "[CV] n_neurons=87 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 24s 653us/sample - loss: 0.3358 - acc: 0.9057 - val_loss: 0.1783 - val_acc: 0.9506\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 16s 438us/sample - loss: 0.1652 - acc: 0.9503 - val_loss: 0.1286 - val_acc: 0.9638\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 15s 409us/sample - loss: 0.1206 - acc: 0.9634 - val_loss: 0.1189 - val_acc: 0.9664\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 359us/sample - loss: 0.0960 - acc: 0.9719 - val_loss: 0.1105 - val_acc: 0.9672\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 13s 349us/sample - loss: 0.0801 - acc: 0.9764 - val_loss: 0.1049 - val_acc: 0.9692\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 14s 372us/sample - loss: 0.0671 - acc: 0.9806 - val_loss: 0.0988 - val_acc: 0.9734\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 15s 415us/sample - loss: 0.0579 - acc: 0.9833 - val_loss: 0.1038 - val_acc: 0.9714\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 16s 426us/sample - loss: 0.0494 - acc: 0.9859 - val_loss: 0.1103 - val_acc: 0.9716\n",
      "18333/18333 [==============================] - 5s 248us/sample - loss: 0.1278 - acc: 0.9681\n",
      "[CV] ..................................... n_neurons=87, total= 2.4min\n",
      "[CV] n_neurons=88 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 25s 694us/sample - loss: 0.3428 - acc: 0.9039 - val_loss: 0.2089 - val_acc: 0.9440\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 19s 526us/sample - loss: 0.1748 - acc: 0.9493 - val_loss: 0.1606 - val_acc: 0.9542\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 17s 456us/sample - loss: 0.1272 - acc: 0.9628 - val_loss: 0.1313 - val_acc: 0.9628\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 17s 471us/sample - loss: 0.1025 - acc: 0.9695 - val_loss: 0.1225 - val_acc: 0.9664\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 14s 380us/sample - loss: 0.0839 - acc: 0.9759 - val_loss: 0.1166 - val_acc: 0.9690\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 14s 378us/sample - loss: 0.0715 - acc: 0.9794 - val_loss: 0.1179 - val_acc: 0.9678\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 12s 333us/sample - loss: 0.0625 - acc: 0.9822 - val_loss: 0.1211 - val_acc: 0.9694\n",
      "18334/18334 [==============================] - 4s 205us/sample - loss: 0.1283 - acc: 0.9665\n",
      "[CV] ..................................... n_neurons=88, total= 2.3min\n",
      "[CV] n_neurons=88 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 18s 503us/sample - loss: 0.3295 - acc: 0.9077 - val_loss: 0.1826 - val_acc: 0.9502\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 13s 345us/sample - loss: 0.1660 - acc: 0.9514 - val_loss: 0.1456 - val_acc: 0.9590\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 13s 343us/sample - loss: 0.1237 - acc: 0.9633 - val_loss: 0.1203 - val_acc: 0.9668\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 348us/sample - loss: 0.0970 - acc: 0.9715 - val_loss: 0.1102 - val_acc: 0.9680\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 13s 343us/sample - loss: 0.0801 - acc: 0.9761 - val_loss: 0.1018 - val_acc: 0.9702\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 12s 336us/sample - loss: 0.0682 - acc: 0.9804 - val_loss: 0.1026 - val_acc: 0.9728\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 13s 351us/sample - loss: 0.0589 - acc: 0.9836 - val_loss: 0.1066 - val_acc: 0.9720\n",
      "18333/18333 [==============================] - 4s 202us/sample - loss: 0.1226 - acc: 0.9676\n",
      "[CV] ..................................... n_neurons=88, total= 1.8min\n",
      "[CV] n_neurons=88 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 19s 512us/sample - loss: 0.3394 - acc: 0.9041 - val_loss: 0.1968 - val_acc: 0.9438\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 12s 339us/sample - loss: 0.1714 - acc: 0.9493 - val_loss: 0.1405 - val_acc: 0.9612\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 12s 340us/sample - loss: 0.1260 - acc: 0.9626 - val_loss: 0.1178 - val_acc: 0.9664\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 12s 338us/sample - loss: 0.1000 - acc: 0.9697 - val_loss: 0.1162 - val_acc: 0.9680\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 13s 342us/sample - loss: 0.0826 - acc: 0.9767 - val_loss: 0.1109 - val_acc: 0.9696\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 347us/sample - loss: 0.0713 - acc: 0.9791 - val_loss: 0.1083 - val_acc: 0.9722\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 13s 354us/sample - loss: 0.0611 - acc: 0.9822 - val_loss: 0.1024 - val_acc: 0.9752\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 13s 344us/sample - loss: 0.0534 - acc: 0.9846 - val_loss: 0.1092 - val_acc: 0.9710\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 13s 353us/sample - loss: 0.0483 - acc: 0.9864 - val_loss: 0.1053 - val_acc: 0.9728\n",
      "18333/18333 [==============================] - 4s 201us/sample - loss: 0.1162 - acc: 0.9712\n",
      "[CV] ..................................... n_neurons=88, total= 2.2min\n",
      "[CV] n_neurons=89 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 18s 494us/sample - loss: 0.3347 - acc: 0.9048 - val_loss: 0.2048 - val_acc: 0.9416\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 13s 347us/sample - loss: 0.1717 - acc: 0.9496 - val_loss: 0.1483 - val_acc: 0.9566\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 12s 332us/sample - loss: 0.1254 - acc: 0.9633 - val_loss: 0.1192 - val_acc: 0.9654\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 13s 353us/sample - loss: 0.1005 - acc: 0.9708 - val_loss: 0.1116 - val_acc: 0.9676\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 13s 353us/sample - loss: 0.0814 - acc: 0.9759 - val_loss: 0.1078 - val_acc: 0.9690\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 13s 348us/sample - loss: 0.0690 - acc: 0.9799 - val_loss: 0.1129 - val_acc: 0.9678\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 19s 515us/sample - loss: 0.0597 - acc: 0.9827 - val_loss: 0.1082 - val_acc: 0.9692\n",
      "18334/18334 [==============================] - 4s 194us/sample - loss: 0.1271 - acc: 0.9660\n",
      "[CV] ..................................... n_neurons=89, total= 1.9min\n",
      "[CV] n_neurons=89 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 20s 535us/sample - loss: 0.3351 - acc: 0.9056 - val_loss: 0.1847 - val_acc: 0.9464\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 18s 479us/sample - loss: 0.1697 - acc: 0.9505 - val_loss: 0.1413 - val_acc: 0.9584\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 15s 405us/sample - loss: 0.1235 - acc: 0.9638 - val_loss: 0.1203 - val_acc: 0.9642\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 15s 397us/sample - loss: 0.0995 - acc: 0.9709 - val_loss: 0.1048 - val_acc: 0.9680\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 15s 415us/sample - loss: 0.0810 - acc: 0.9771 - val_loss: 0.1052 - val_acc: 0.9666\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 15s 398us/sample - loss: 0.0690 - acc: 0.9795 - val_loss: 0.1005 - val_acc: 0.9692\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 15s 399us/sample - loss: 0.0588 - acc: 0.9822 - val_loss: 0.1025 - val_acc: 0.9712\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 15s 400us/sample - loss: 0.0513 - acc: 0.9848 - val_loss: 0.1014 - val_acc: 0.9708\n",
      "18333/18333 [==============================] - 4s 214us/sample - loss: 0.1183 - acc: 0.9699\n",
      "[CV] ..................................... n_neurons=89, total= 2.4min\n",
      "[CV] n_neurons=89 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 20s 543us/sample - loss: 0.3445 - acc: 0.9011 - val_loss: 0.1883 - val_acc: 0.9498\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 14s 390us/sample - loss: 0.1679 - acc: 0.9511 - val_loss: 0.1338 - val_acc: 0.9616\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 15s 402us/sample - loss: 0.1215 - acc: 0.9640 - val_loss: 0.1225 - val_acc: 0.9626\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 15s 398us/sample - loss: 0.0966 - acc: 0.9721 - val_loss: 0.1141 - val_acc: 0.9676\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 15s 403us/sample - loss: 0.0817 - acc: 0.9760 - val_loss: 0.1059 - val_acc: 0.9694\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 15s 397us/sample - loss: 0.0697 - acc: 0.9804 - val_loss: 0.0987 - val_acc: 0.9724\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 15s 408us/sample - loss: 0.0607 - acc: 0.9828 - val_loss: 0.0962 - val_acc: 0.9738\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 15s 399us/sample - loss: 0.0526 - acc: 0.9846 - val_loss: 0.0945 - val_acc: 0.9732\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 14s 388us/sample - loss: 0.0459 - acc: 0.9875 - val_loss: 0.0991 - val_acc: 0.9744\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 14s 388us/sample - loss: 0.0408 - acc: 0.9886 - val_loss: 0.1012 - val_acc: 0.9746\n",
      "18333/18333 [==============================] - 4s 215us/sample - loss: 0.1275 - acc: 0.9692\n",
      "[CV] ..................................... n_neurons=89, total= 2.7min\n",
      "[CV] n_neurons=90 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 20s 548us/sample - loss: 0.3262 - acc: 0.9079 - val_loss: 0.1784 - val_acc: 0.9490\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 15s 397us/sample - loss: 0.1602 - acc: 0.9530 - val_loss: 0.1400 - val_acc: 0.9602\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 15s 403us/sample - loss: 0.1171 - acc: 0.9654 - val_loss: 0.1214 - val_acc: 0.9652\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 15s 398us/sample - loss: 0.0937 - acc: 0.9733 - val_loss: 0.1110 - val_acc: 0.9686\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 15s 405us/sample - loss: 0.0769 - acc: 0.9780 - val_loss: 0.1152 - val_acc: 0.9684\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 16s 446us/sample - loss: 0.0660 - acc: 0.9807 - val_loss: 0.1053 - val_acc: 0.9708\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 14s 385us/sample - loss: 0.0574 - acc: 0.9833 - val_loss: 0.1014 - val_acc: 0.9716\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 13s 368us/sample - loss: 0.0485 - acc: 0.9861 - val_loss: 0.1060 - val_acc: 0.9714\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 13s 361us/sample - loss: 0.0435 - acc: 0.9881 - val_loss: 0.1065 - val_acc: 0.9720\n",
      "18334/18334 [==============================] - 4s 226us/sample - loss: 0.1232 - acc: 0.9690\n",
      "[CV] ..................................... n_neurons=90, total= 2.5min\n",
      "[CV] n_neurons=90 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 20s 544us/sample - loss: 0.3294 - acc: 0.9075 - val_loss: 0.1909 - val_acc: 0.9482\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 14s 372us/sample - loss: 0.1637 - acc: 0.9529 - val_loss: 0.1368 - val_acc: 0.9610\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 14s 371us/sample - loss: 0.1210 - acc: 0.9643 - val_loss: 0.1295 - val_acc: 0.9610\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 14s 386us/sample - loss: 0.0973 - acc: 0.9710 - val_loss: 0.1123 - val_acc: 0.9688\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 18s 479us/sample - loss: 0.0813 - acc: 0.9765 - val_loss: 0.1142 - val_acc: 0.9666\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 16s 438us/sample - loss: 0.0702 - acc: 0.9791 - val_loss: 0.1042 - val_acc: 0.9702\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 17s 455us/sample - loss: 0.0608 - acc: 0.9830 - val_loss: 0.1047 - val_acc: 0.9720\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 14s 371us/sample - loss: 0.0526 - acc: 0.9843 - val_loss: 0.1086 - val_acc: 0.9710\n",
      "18333/18333 [==============================] - 6s 344us/sample - loss: 0.1238 - acc: 0.9678\n",
      "[CV] ..................................... n_neurons=90, total= 2.4min\n",
      "[CV] n_neurons=90 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 22s 611us/sample - loss: 0.3344 - acc: 0.9065 - val_loss: 0.1756 - val_acc: 0.9498\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 16s 447us/sample - loss: 0.1640 - acc: 0.9511 - val_loss: 0.1438 - val_acc: 0.9582\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 18s 495us/sample - loss: 0.1200 - acc: 0.9644 - val_loss: 0.1226 - val_acc: 0.9640\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 14s 395us/sample - loss: 0.0959 - acc: 0.9732 - val_loss: 0.1056 - val_acc: 0.9694\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 24s 661us/sample - loss: 0.0789 - acc: 0.9769 - val_loss: 0.1107 - val_acc: 0.9688\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 15s 403us/sample - loss: 0.0677 - acc: 0.9807 - val_loss: 0.1005 - val_acc: 0.9736\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 14s 392us/sample - loss: 0.0580 - acc: 0.9836 - val_loss: 0.0962 - val_acc: 0.9706\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 14s 395us/sample - loss: 0.0512 - acc: 0.9857 - val_loss: 0.1040 - val_acc: 0.9714\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 13s 364us/sample - loss: 0.0442 - acc: 0.9876 - val_loss: 0.1018 - val_acc: 0.9726\n",
      "18333/18333 [==============================] - 4s 204us/sample - loss: 0.1221 - acc: 0.9702\n",
      "[CV] ..................................... n_neurons=90, total= 2.8min\n",
      "[CV] n_neurons=91 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 25s 694us/sample - loss: 0.3271 - acc: 0.9055 - val_loss: 0.1853 - val_acc: 0.9504\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 19s 523us/sample - loss: 0.1664 - acc: 0.9509 - val_loss: 0.1447 - val_acc: 0.9582\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 14s 395us/sample - loss: 0.1231 - acc: 0.9635 - val_loss: 0.1278 - val_acc: 0.9642\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 14s 394us/sample - loss: 0.0985 - acc: 0.9709 - val_loss: 0.1084 - val_acc: 0.9680\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 14s 380us/sample - loss: 0.0832 - acc: 0.9751 - val_loss: 0.1143 - val_acc: 0.9686\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 14s 386us/sample - loss: 0.0708 - acc: 0.9796 - val_loss: 0.1176 - val_acc: 0.9688\n",
      "18334/18334 [==============================] - 4s 236us/sample - loss: 0.1350 - acc: 0.9636\n",
      "[CV] ..................................... n_neurons=91, total= 2.0min\n",
      "[CV] n_neurons=91 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 32s 869us/sample - loss: 0.3218 - acc: 0.9079 - val_loss: 0.1780 - val_acc: 0.9508\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 20s 536us/sample - loss: 0.1584 - acc: 0.9535 - val_loss: 0.1394 - val_acc: 0.9578\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 22s 601us/sample - loss: 0.1166 - acc: 0.9657 - val_loss: 0.1166 - val_acc: 0.9646\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 22s 610us/sample - loss: 0.0913 - acc: 0.9732 - val_loss: 0.1057 - val_acc: 0.9680\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 21s 561us/sample - loss: 0.0749 - acc: 0.9784 - val_loss: 0.1018 - val_acc: 0.9692\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 20s 548us/sample - loss: 0.0637 - acc: 0.9821 - val_loss: 0.0962 - val_acc: 0.9710\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 15s 402us/sample - loss: 0.0535 - acc: 0.9840 - val_loss: 0.1006 - val_acc: 0.9702\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 15s 415us/sample - loss: 0.0465 - acc: 0.9864 - val_loss: 0.0985 - val_acc: 0.9726\n",
      "18333/18333 [==============================] - 4s 237us/sample - loss: 0.1256 - acc: 0.9685\n",
      "[CV] ..................................... n_neurons=91, total= 3.1min\n",
      "[CV] n_neurons=91 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 22s 607us/sample - loss: 0.3447 - acc: 0.9025 - val_loss: 0.1925 - val_acc: 0.9448\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 16s 435us/sample - loss: 0.1695 - acc: 0.9510 - val_loss: 0.1393 - val_acc: 0.9572\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 16s 437us/sample - loss: 0.1240 - acc: 0.9644 - val_loss: 0.1235 - val_acc: 0.9610\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 351us/sample - loss: 0.0995 - acc: 0.9719 - val_loss: 0.1116 - val_acc: 0.9666\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 13s 349us/sample - loss: 0.0816 - acc: 0.9775 - val_loss: 0.1077 - val_acc: 0.9670\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 349us/sample - loss: 0.0705 - acc: 0.9807 - val_loss: 0.1047 - val_acc: 0.9710\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 13s 348us/sample - loss: 0.0612 - acc: 0.9827 - val_loss: 0.1049 - val_acc: 0.9696\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 13s 354us/sample - loss: 0.0536 - acc: 0.9854 - val_loss: 0.1022 - val_acc: 0.9732\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 15s 404us/sample - loss: 0.0469 - acc: 0.9879 - val_loss: 0.1025 - val_acc: 0.9724\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 17s 460us/sample - loss: 0.0422 - acc: 0.9884 - val_loss: 0.1085 - val_acc: 0.9730\n",
      "18333/18333 [==============================] - 5s 259us/sample - loss: 0.1255 - acc: 0.9703\n",
      "[CV] ..................................... n_neurons=91, total= 2.8min\n",
      "[CV] n_neurons=92 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 22s 607us/sample - loss: 0.3316 - acc: 0.9064 - val_loss: 0.1984 - val_acc: 0.9450\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 13s 357us/sample - loss: 0.1661 - acc: 0.9510 - val_loss: 0.1463 - val_acc: 0.9552\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 13s 354us/sample - loss: 0.1206 - acc: 0.9651 - val_loss: 0.1302 - val_acc: 0.9606\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 13s 353us/sample - loss: 0.0956 - acc: 0.9717 - val_loss: 0.1147 - val_acc: 0.9698\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 13s 351us/sample - loss: 0.0800 - acc: 0.9772 - val_loss: 0.1069 - val_acc: 0.9704\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 13s 348us/sample - loss: 0.0686 - acc: 0.9804 - val_loss: 0.1116 - val_acc: 0.9686\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 13s 363us/sample - loss: 0.0604 - acc: 0.9829 - val_loss: 0.1215 - val_acc: 0.9680\n",
      "18334/18334 [==============================] - 4s 206us/sample - loss: 0.1356 - acc: 0.9663\n",
      "[CV] ..................................... n_neurons=92, total= 1.9min\n",
      "[CV] n_neurons=92 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 20s 554us/sample - loss: 0.3261 - acc: 0.9080 - val_loss: 0.1877 - val_acc: 0.9424\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 13s 358us/sample - loss: 0.1650 - acc: 0.9522 - val_loss: 0.1410 - val_acc: 0.9568\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 13s 355us/sample - loss: 0.1219 - acc: 0.9646 - val_loss: 0.1227 - val_acc: 0.9644\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 346us/sample - loss: 0.0955 - acc: 0.9728 - val_loss: 0.1112 - val_acc: 0.9680\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 13s 355us/sample - loss: 0.0785 - acc: 0.9770 - val_loss: 0.1024 - val_acc: 0.9702\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 361us/sample - loss: 0.0659 - acc: 0.9805 - val_loss: 0.1067 - val_acc: 0.9702\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 13s 344us/sample - loss: 0.0576 - acc: 0.9828 - val_loss: 0.1013 - val_acc: 0.9726\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 14s 384us/sample - loss: 0.0497 - acc: 0.9854 - val_loss: 0.1030 - val_acc: 0.9720\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 13s 355us/sample - loss: 0.0439 - acc: 0.9872 - val_loss: 0.1021 - val_acc: 0.9742\n",
      "18333/18333 [==============================] - 4s 204us/sample - loss: 0.1191 - acc: 0.9705\n",
      "[CV] ..................................... n_neurons=92, total= 2.3min\n",
      "[CV] n_neurons=92 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 20s 540us/sample - loss: 0.3386 - acc: 0.9042 - val_loss: 0.2061 - val_acc: 0.9414\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 13s 358us/sample - loss: 0.1744 - acc: 0.9492 - val_loss: 0.1381 - val_acc: 0.9620\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 14s 388us/sample - loss: 0.1293 - acc: 0.9627 - val_loss: 0.1384 - val_acc: 0.9598\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 363us/sample - loss: 0.1025 - acc: 0.9696 - val_loss: 0.1172 - val_acc: 0.9662\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 13s 357us/sample - loss: 0.0864 - acc: 0.9755 - val_loss: 0.1050 - val_acc: 0.9714\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 359us/sample - loss: 0.0754 - acc: 0.9783 - val_loss: 0.1018 - val_acc: 0.9708\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 13s 352us/sample - loss: 0.0645 - acc: 0.9813 - val_loss: 0.1058 - val_acc: 0.9708\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 13s 347us/sample - loss: 0.0567 - acc: 0.9837 - val_loss: 0.0968 - val_acc: 0.9722\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 13s 360us/sample - loss: 0.0508 - acc: 0.9861 - val_loss: 0.1045 - val_acc: 0.9732\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 16s 426us/sample - loss: 0.0450 - acc: 0.9880 - val_loss: 0.0935 - val_acc: 0.9734\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 16s 431us/sample - loss: 0.0400 - acc: 0.9894 - val_loss: 0.1004 - val_acc: 0.9738\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 14s 382us/sample - loss: 0.0356 - acc: 0.9902 - val_loss: 0.1020 - val_acc: 0.9748\n",
      "18333/18333 [==============================] - 5s 289us/sample - loss: 0.1320 - acc: 0.9699\n",
      "[CV] ..................................... n_neurons=92, total= 3.1min\n",
      "[CV] n_neurons=93 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 21s 568us/sample - loss: 0.3223 - acc: 0.9081 - val_loss: 0.2164 - val_acc: 0.9374\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 13s 367us/sample - loss: 0.1666 - acc: 0.9508 - val_loss: 0.1475 - val_acc: 0.9530\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 13s 346us/sample - loss: 0.1220 - acc: 0.9636 - val_loss: 0.1247 - val_acc: 0.9646\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 13s 357us/sample - loss: 0.0977 - acc: 0.9714 - val_loss: 0.1232 - val_acc: 0.9654\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 13s 353us/sample - loss: 0.0816 - acc: 0.9764 - val_loss: 0.1130 - val_acc: 0.9676\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 13s 361us/sample - loss: 0.0689 - acc: 0.9802 - val_loss: 0.1128 - val_acc: 0.9686\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 13s 362us/sample - loss: 0.0596 - acc: 0.9825 - val_loss: 0.1034 - val_acc: 0.9724\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 13s 357us/sample - loss: 0.0508 - acc: 0.9847 - val_loss: 0.1113 - val_acc: 0.9702\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 13s 353us/sample - loss: 0.0455 - acc: 0.9864 - val_loss: 0.1105 - val_acc: 0.9710\n",
      "18334/18334 [==============================] - 4s 221us/sample - loss: 0.1311 - acc: 0.9677\n",
      "[CV] ..................................... n_neurons=93, total= 2.4min\n",
      "[CV] n_neurons=93 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 19s 516us/sample - loss: 0.3353 - acc: 0.9037 - val_loss: 0.2128 - val_acc: 0.9366\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 13s 362us/sample - loss: 0.1703 - acc: 0.9514 - val_loss: 0.1387 - val_acc: 0.9612\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 14s 392us/sample - loss: 0.1249 - acc: 0.9643 - val_loss: 0.1278 - val_acc: 0.9642\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 14s 395us/sample - loss: 0.0993 - acc: 0.9708 - val_loss: 0.1157 - val_acc: 0.9658\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 14s 370us/sample - loss: 0.0817 - acc: 0.9761 - val_loss: 0.1124 - val_acc: 0.9670\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 14s 379us/sample - loss: 0.0694 - acc: 0.9801 - val_loss: 0.1092 - val_acc: 0.9702\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 13s 359us/sample - loss: 0.0588 - acc: 0.9831 - val_loss: 0.1053 - val_acc: 0.9712\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 13s 362us/sample - loss: 0.0513 - acc: 0.9850 - val_loss: 0.1105 - val_acc: 0.9702\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 13s 363us/sample - loss: 0.0438 - acc: 0.9876 - val_loss: 0.1125 - val_acc: 0.9704\n",
      "18333/18333 [==============================] - 4s 204us/sample - loss: 0.1300 - acc: 0.9686\n",
      "[CV] ..................................... n_neurons=93, total= 2.4min\n",
      "[CV] n_neurons=93 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 19s 532us/sample - loss: 0.3272 - acc: 0.9068 - val_loss: 0.1808 - val_acc: 0.9482\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 13s 356us/sample - loss: 0.1598 - acc: 0.9534 - val_loss: 0.1337 - val_acc: 0.9620\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 13s 364us/sample - loss: 0.1155 - acc: 0.9659 - val_loss: 0.1081 - val_acc: 0.9692\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 14s 371us/sample - loss: 0.0917 - acc: 0.9736 - val_loss: 0.1046 - val_acc: 0.9686\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 13s 362us/sample - loss: 0.0768 - acc: 0.9773 - val_loss: 0.0943 - val_acc: 0.9734\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 349us/sample - loss: 0.0653 - acc: 0.9813 - val_loss: 0.0912 - val_acc: 0.9750\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 15s 408us/sample - loss: 0.0552 - acc: 0.9840 - val_loss: 0.0917 - val_acc: 0.9756\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 15s 412us/sample - loss: 0.0492 - acc: 0.9862 - val_loss: 0.0984 - val_acc: 0.9738\n",
      "18333/18333 [==============================] - 4s 212us/sample - loss: 0.1172 - acc: 0.9708\n",
      "[CV] ..................................... n_neurons=93, total= 2.2min\n",
      "[CV] n_neurons=94 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 32s 876us/sample - loss: 0.3303 - acc: 0.9058 - val_loss: 0.1970 - val_acc: 0.9454\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 13s 357us/sample - loss: 0.1668 - acc: 0.9514 - val_loss: 0.1369 - val_acc: 0.9614\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 14s 371us/sample - loss: 0.1223 - acc: 0.9641 - val_loss: 0.1292 - val_acc: 0.9640\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 13s 362us/sample - loss: 0.0975 - acc: 0.9714 - val_loss: 0.1118 - val_acc: 0.9676\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 14s 371us/sample - loss: 0.0813 - acc: 0.9763 - val_loss: 0.1068 - val_acc: 0.9698\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 14s 389us/sample - loss: 0.0677 - acc: 0.9801 - val_loss: 0.1130 - val_acc: 0.9698\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 14s 386us/sample - loss: 0.0594 - acc: 0.9828 - val_loss: 0.1015 - val_acc: 0.9722\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 14s 393us/sample - loss: 0.0513 - acc: 0.9858 - val_loss: 0.1136 - val_acc: 0.9694\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 14s 386us/sample - loss: 0.0454 - acc: 0.9877 - val_loss: 0.1119 - val_acc: 0.9720\n",
      "18334/18334 [==============================] - 5s 263us/sample - loss: 0.1290 - acc: 0.9679\n",
      "[CV] ..................................... n_neurons=94, total= 2.7min\n",
      "[CV] n_neurons=94 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 21s 585us/sample - loss: 0.3315 - acc: 0.9064 - val_loss: 0.1831 - val_acc: 0.9484\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 21s 566us/sample - loss: 0.1672 - acc: 0.9513 - val_loss: 0.1408 - val_acc: 0.9596\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 30s 815us/sample - loss: 0.1218 - acc: 0.9638 - val_loss: 0.1135 - val_acc: 0.9662\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 15s 417us/sample - loss: 0.0941 - acc: 0.9722 - val_loss: 0.1180 - val_acc: 0.9626\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 15s 421us/sample - loss: 0.0789 - acc: 0.9771 - val_loss: 0.1056 - val_acc: 0.9694\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 21s 565us/sample - loss: 0.0656 - acc: 0.9807 - val_loss: 0.1062 - val_acc: 0.9680\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 19s 518us/sample - loss: 0.0571 - acc: 0.9833 - val_loss: 0.1010 - val_acc: 0.9728\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 19s 525us/sample - loss: 0.0481 - acc: 0.9863 - val_loss: 0.1115 - val_acc: 0.9698\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 20s 550us/sample - loss: 0.0422 - acc: 0.9875 - val_loss: 0.1033 - val_acc: 0.9710\n",
      "18333/18333 [==============================] - 6s 322us/sample - loss: 0.1194 - acc: 0.9707s - loss: 0\n",
      "[CV] ..................................... n_neurons=94, total= 3.4min\n",
      "[CV] n_neurons=94 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 40s 1ms/sample - loss: 0.3352 - acc: 0.9056 - val_loss: 0.1939 - val_acc: 0.9404\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 25s 673us/sample - loss: 0.1633 - acc: 0.9522 - val_loss: 0.1400 - val_acc: 0.9592\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 21s 582us/sample - loss: 0.1181 - acc: 0.9645 - val_loss: 0.1123 - val_acc: 0.9686\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 14s 383us/sample - loss: 0.0938 - acc: 0.9723 - val_loss: 0.0982 - val_acc: 0.9726\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 15s 397us/sample - loss: 0.0782 - acc: 0.9768 - val_loss: 0.1007 - val_acc: 0.9712\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 16s 429us/sample - loss: 0.0653 - acc: 0.9809 - val_loss: 0.0961 - val_acc: 0.9710\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 15s 406us/sample - loss: 0.0574 - acc: 0.9831 - val_loss: 0.0945 - val_acc: 0.9726\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 14s 394us/sample - loss: 0.0490 - acc: 0.9860 - val_loss: 0.0898 - val_acc: 0.9740\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 18s 481us/sample - loss: 0.0431 - acc: 0.9880 - val_loss: 0.0940 - val_acc: 0.9736\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 16s 430us/sample - loss: 0.0382 - acc: 0.9890 - val_loss: 0.0942 - val_acc: 0.9752\n",
      "18333/18333 [==============================] - 8s 441us/sample - loss: 0.1181 - acc: 0.9709\n",
      "[CV] ..................................... n_neurons=94, total= 3.6min\n",
      "[CV] n_neurons=95 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 21s 574us/sample - loss: 0.3304 - acc: 0.9074 - val_loss: 0.1845 - val_acc: 0.9478\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 14s 370us/sample - loss: 0.1651 - acc: 0.9521 - val_loss: 0.1386 - val_acc: 0.9588\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 13s 367us/sample - loss: 0.1210 - acc: 0.9649 - val_loss: 0.1262 - val_acc: 0.9630\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 14s 380us/sample - loss: 0.0964 - acc: 0.9722 - val_loss: 0.1096 - val_acc: 0.9676\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 16s 434us/sample - loss: 0.0786 - acc: 0.9777 - val_loss: 0.1015 - val_acc: 0.9708\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 17s 477us/sample - loss: 0.0673 - acc: 0.9806 - val_loss: 0.1113 - val_acc: 0.9682\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 17s 469us/sample - loss: 0.0580 - acc: 0.9838 - val_loss: 0.1119 - val_acc: 0.9686\n",
      "18334/18334 [==============================] - 5s 283us/sample - loss: 0.1325 - acc: 0.9654\n",
      "[CV] ..................................... n_neurons=95, total= 2.2min\n",
      "[CV] n_neurons=95 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 21s 575us/sample - loss: 0.3320 - acc: 0.9058 - val_loss: 0.1929 - val_acc: 0.9438\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 16s 426us/sample - loss: 0.1650 - acc: 0.9527 - val_loss: 0.1319 - val_acc: 0.9594\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 17s 454us/sample - loss: 0.1203 - acc: 0.9653 - val_loss: 0.1176 - val_acc: 0.9640\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 16s 431us/sample - loss: 0.0939 - acc: 0.9724 - val_loss: 0.1129 - val_acc: 0.9664\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 17s 456us/sample - loss: 0.0782 - acc: 0.9770 - val_loss: 0.1055 - val_acc: 0.9690\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 16s 434us/sample - loss: 0.0672 - acc: 0.9807 - val_loss: 0.1082 - val_acc: 0.9688\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 16s 445us/sample - loss: 0.0568 - acc: 0.9837 - val_loss: 0.1084 - val_acc: 0.9692\n",
      "18333/18333 [==============================] - 5s 255us/sample - loss: 0.1293 - acc: 0.9679\n",
      "[CV] ..................................... n_neurons=95, total= 2.3min\n",
      "[CV] n_neurons=95 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 24s 648us/sample - loss: 0.3318 - acc: 0.9057 - val_loss: 0.1833 - val_acc: 0.9486\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 17s 454us/sample - loss: 0.1665 - acc: 0.9511 - val_loss: 0.1314 - val_acc: 0.9640\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 16s 441us/sample - loss: 0.1193 - acc: 0.9654 - val_loss: 0.1315 - val_acc: 0.9618\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 356us/sample - loss: 0.0945 - acc: 0.9732 - val_loss: 0.1061 - val_acc: 0.9680\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 13s 361us/sample - loss: 0.0773 - acc: 0.9774 - val_loss: 0.1009 - val_acc: 0.9696\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 360us/sample - loss: 0.0653 - acc: 0.9810 - val_loss: 0.1177 - val_acc: 0.9656\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 13s 360us/sample - loss: 0.0575 - acc: 0.9836 - val_loss: 0.1068 - val_acc: 0.9702\n",
      "18333/18333 [==============================] - 4s 205us/sample - loss: 0.1314 - acc: 0.9663\n",
      "[CV] ..................................... n_neurons=95, total= 2.1min\n",
      "[CV] n_neurons=96 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 19s 508us/sample - loss: 0.3272 - acc: 0.9074 - val_loss: 0.1758 - val_acc: 0.9500\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 13s 360us/sample - loss: 0.1651 - acc: 0.9516 - val_loss: 0.1429 - val_acc: 0.9590\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 13s 360us/sample - loss: 0.1229 - acc: 0.9641 - val_loss: 0.1166 - val_acc: 0.9654\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 13s 360us/sample - loss: 0.0987 - acc: 0.9714 - val_loss: 0.1078 - val_acc: 0.9692\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 13s 360us/sample - loss: 0.0809 - acc: 0.9767 - val_loss: 0.1105 - val_acc: 0.9666\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 13s 363us/sample - loss: 0.0708 - acc: 0.9802 - val_loss: 0.1066 - val_acc: 0.9664\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 13s 360us/sample - loss: 0.0602 - acc: 0.9832 - val_loss: 0.1090 - val_acc: 0.9684\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 13s 360us/sample - loss: 0.0527 - acc: 0.9856 - val_loss: 0.1006 - val_acc: 0.9714\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 13s 360us/sample - loss: 0.0480 - acc: 0.9871 - val_loss: 0.1098 - val_acc: 0.9702\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 13s 365us/sample - loss: 0.0421 - acc: 0.9880 - val_loss: 0.1033 - val_acc: 0.9720\n",
      "18334/18334 [==============================] - 4s 204us/sample - loss: 0.1289 - acc: 0.9688\n",
      "[CV] ..................................... n_neurons=96, total= 2.5min\n",
      "[CV] n_neurons=96 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 19s 509us/sample - loss: 0.3284 - acc: 0.9083 - val_loss: 0.1791 - val_acc: 0.9500\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 13s 360us/sample - loss: 0.1665 - acc: 0.9530 - val_loss: 0.1339 - val_acc: 0.9600\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 13s 361us/sample - loss: 0.1209 - acc: 0.9644 - val_loss: 0.1133 - val_acc: 0.9674\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 13s 362us/sample - loss: 0.0949 - acc: 0.9720 - val_loss: 0.1057 - val_acc: 0.9680\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 13s 362us/sample - loss: 0.0790 - acc: 0.9773 - val_loss: 0.1084 - val_acc: 0.9692\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 13s 361us/sample - loss: 0.0661 - acc: 0.9808 - val_loss: 0.1037 - val_acc: 0.9684\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 14s 379us/sample - loss: 0.0569 - acc: 0.9837 - val_loss: 0.1008 - val_acc: 0.9746\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 14s 376us/sample - loss: 0.0491 - acc: 0.9860 - val_loss: 0.0976 - val_acc: 0.9724\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 14s 382us/sample - loss: 0.0414 - acc: 0.9881 - val_loss: 0.0968 - val_acc: 0.9758\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 14s 374us/sample - loss: 0.0372 - acc: 0.9890 - val_loss: 0.1048 - val_acc: 0.9740\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 14s 390us/sample - loss: 0.0323 - acc: 0.9909 - val_loss: 0.1113 - val_acc: 0.9724\n",
      "18333/18333 [==============================] - 4s 221us/sample - loss: 0.1365 - acc: 0.9685\n",
      "[CV] ..................................... n_neurons=96, total= 2.8min\n",
      "[CV] n_neurons=96 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 21s 570us/sample - loss: 0.3318 - acc: 0.9070 - val_loss: 0.1773 - val_acc: 0.9498\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 19s 510us/sample - loss: 0.1642 - acc: 0.9523 - val_loss: 0.1394 - val_acc: 0.9598\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 17s 460us/sample - loss: 0.1198 - acc: 0.9655 - val_loss: 0.1144 - val_acc: 0.9678\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 17s 452us/sample - loss: 0.0972 - acc: 0.9718 - val_loss: 0.1024 - val_acc: 0.9700\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 18s 492us/sample - loss: 0.0806 - acc: 0.9771 - val_loss: 0.1070 - val_acc: 0.9718\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 17s 457us/sample - loss: 0.0687 - acc: 0.9806 - val_loss: 0.1010 - val_acc: 0.9712\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 17s 471us/sample - loss: 0.0585 - acc: 0.9838 - val_loss: 0.0977 - val_acc: 0.9732\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 17s 454us/sample - loss: 0.0524 - acc: 0.9854 - val_loss: 0.1035 - val_acc: 0.9700\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 17s 457us/sample - loss: 0.0465 - acc: 0.9870 - val_loss: 0.1001 - val_acc: 0.9722\n",
      "18333/18333 [==============================] - 5s 264us/sample - loss: 0.1277 - acc: 0.9686\n",
      "[CV] ..................................... n_neurons=96, total= 2.9min\n",
      "[CV] n_neurons=97 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 24s 663us/sample - loss: 0.3326 - acc: 0.9054 - val_loss: 0.1862 - val_acc: 0.9478\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 16s 447us/sample - loss: 0.1651 - acc: 0.9521 - val_loss: 0.1553 - val_acc: 0.9538\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 13s 361us/sample - loss: 0.1214 - acc: 0.9650 - val_loss: 0.1327 - val_acc: 0.9630\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 13s 364us/sample - loss: 0.0973 - acc: 0.9720 - val_loss: 0.1177 - val_acc: 0.9678\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 16s 435us/sample - loss: 0.0814 - acc: 0.9760 - val_loss: 0.1154 - val_acc: 0.9698\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 17s 462us/sample - loss: 0.0685 - acc: 0.9801 - val_loss: 0.1148 - val_acc: 0.9700\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 16s 438us/sample - loss: 0.0603 - acc: 0.9826 - val_loss: 0.1161 - val_acc: 0.9698\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 16s 450us/sample - loss: 0.0518 - acc: 0.9858 - val_loss: 0.1104 - val_acc: 0.9732\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 16s 433us/sample - loss: 0.0458 - acc: 0.9871 - val_loss: 0.1142 - val_acc: 0.9704\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 17s 470us/sample - loss: 0.0400 - acc: 0.9889 - val_loss: 0.1202 - val_acc: 0.9738\n",
      "18334/18334 [==============================] - 5s 253us/sample - loss: 0.1282 - acc: 0.9692\n",
      "[CV] ..................................... n_neurons=97, total= 3.0min\n",
      "[CV] n_neurons=97 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 20s 548us/sample - loss: 0.3357 - acc: 0.9063 - val_loss: 0.1848 - val_acc: 0.9500\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 13s 362us/sample - loss: 0.1685 - acc: 0.9517 - val_loss: 0.1347 - val_acc: 0.9614\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 13s 367us/sample - loss: 0.1241 - acc: 0.9641 - val_loss: 0.1177 - val_acc: 0.9664\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 14s 382us/sample - loss: 0.0995 - acc: 0.9706 - val_loss: 0.1124 - val_acc: 0.9688\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 14s 369us/sample - loss: 0.0824 - acc: 0.9747 - val_loss: 0.1041 - val_acc: 0.9724\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 14s 383us/sample - loss: 0.0689 - acc: 0.9801 - val_loss: 0.1021 - val_acc: 0.9710\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 14s 372us/sample - loss: 0.0590 - acc: 0.9830 - val_loss: 0.1095 - val_acc: 0.9696\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 13s 367us/sample - loss: 0.0504 - acc: 0.9847 - val_loss: 0.0967 - val_acc: 0.9732\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 14s 393us/sample - loss: 0.0439 - acc: 0.9873 - val_loss: 0.1093 - val_acc: 0.9730\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 14s 388us/sample - loss: 0.0380 - acc: 0.9893 - val_loss: 0.1100 - val_acc: 0.9732\n",
      "18333/18333 [==============================] - 4s 221us/sample - loss: 0.1295 - acc: 0.9697\n",
      "[CV] ..................................... n_neurons=97, total= 2.7min\n",
      "[CV] n_neurons=97 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 20s 541us/sample - loss: 0.3341 - acc: 0.9057 - val_loss: 0.1873 - val_acc: 0.9456\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 15s 399us/sample - loss: 0.1631 - acc: 0.9520 - val_loss: 0.1342 - val_acc: 0.9634\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 15s 405us/sample - loss: 0.1190 - acc: 0.9655 - val_loss: 0.1359 - val_acc: 0.9596\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 18s 482us/sample - loss: 0.0945 - acc: 0.9725 - val_loss: 0.1101 - val_acc: 0.9670\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 18s 496us/sample - loss: 0.0783 - acc: 0.9777 - val_loss: 0.1026 - val_acc: 0.9720\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 15s 404us/sample - loss: 0.0656 - acc: 0.9816 - val_loss: 0.0999 - val_acc: 0.9720\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 17s 470us/sample - loss: 0.0570 - acc: 0.9845 - val_loss: 0.1026 - val_acc: 0.9726\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 17s 462us/sample - loss: 0.0493 - acc: 0.9867 - val_loss: 0.1083 - val_acc: 0.9720\n",
      "18333/18333 [==============================] - 5s 261us/sample - loss: 0.1363 - acc: 0.9663\n",
      "[CV] ..................................... n_neurons=97, total= 2.5min\n",
      "[CV] n_neurons=98 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 24s 663us/sample - loss: 0.3368 - acc: 0.9048 - val_loss: 0.1929 - val_acc: 0.9442\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 15s 399us/sample - loss: 0.1684 - acc: 0.9505 - val_loss: 0.1435 - val_acc: 0.9570\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 15s 408us/sample - loss: 0.1203 - acc: 0.9643 - val_loss: 0.1195 - val_acc: 0.9652\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 15s 411us/sample - loss: 0.0959 - acc: 0.9719 - val_loss: 0.1114 - val_acc: 0.9650\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 15s 415us/sample - loss: 0.0781 - acc: 0.9770 - val_loss: 0.1052 - val_acc: 0.9668\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 19s 508us/sample - loss: 0.0664 - acc: 0.9807 - val_loss: 0.0983 - val_acc: 0.9728\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 17s 465us/sample - loss: 0.0565 - acc: 0.9831 - val_loss: 0.1165 - val_acc: 0.9690\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 15s 420us/sample - loss: 0.0487 - acc: 0.9861 - val_loss: 0.1083 - val_acc: 0.9716\n",
      "18334/18334 [==============================] - 5s 252us/sample - loss: 0.1200 - acc: 0.9697\n",
      "[CV] ..................................... n_neurons=98, total= 2.5min\n",
      "[CV] n_neurons=98 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 21s 580us/sample - loss: 0.3255 - acc: 0.9077 - val_loss: 0.1853 - val_acc: 0.9486\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 15s 397us/sample - loss: 0.1606 - acc: 0.9540 - val_loss: 0.1350 - val_acc: 0.9604\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 14s 383us/sample - loss: 0.1169 - acc: 0.9652 - val_loss: 0.1171 - val_acc: 0.9668\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 14s 388us/sample - loss: 0.0932 - acc: 0.9726 - val_loss: 0.1062 - val_acc: 0.9692\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 14s 391us/sample - loss: 0.0784 - acc: 0.9774 - val_loss: 0.1075 - val_acc: 0.9688\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 15s 396us/sample - loss: 0.0657 - acc: 0.9807 - val_loss: 0.1059 - val_acc: 0.9692\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 15s 398us/sample - loss: 0.0560 - acc: 0.9835 - val_loss: 0.1086 - val_acc: 0.9712\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 15s 398us/sample - loss: 0.0486 - acc: 0.9862 - val_loss: 0.1011 - val_acc: 0.9712\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 14s 392us/sample - loss: 0.0427 - acc: 0.9878 - val_loss: 0.0950 - val_acc: 0.9736\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 14s 393us/sample - loss: 0.0361 - acc: 0.9896 - val_loss: 0.1034 - val_acc: 0.9734\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 14s 391us/sample - loss: 0.0328 - acc: 0.9909 - val_loss: 0.1062 - val_acc: 0.9720\n",
      "18333/18333 [==============================] - 4s 230us/sample - loss: 0.1336 - acc: 0.9699\n",
      "[CV] ..................................... n_neurons=98, total= 3.0min\n",
      "[CV] n_neurons=98 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 22s 602us/sample - loss: 0.3242 - acc: 0.9068 - val_loss: 0.1785 - val_acc: 0.9472\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 14s 390us/sample - loss: 0.1581 - acc: 0.9530 - val_loss: 0.1357 - val_acc: 0.9606\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 14s 392us/sample - loss: 0.1175 - acc: 0.9662 - val_loss: 0.1095 - val_acc: 0.9666\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 15s 396us/sample - loss: 0.0917 - acc: 0.9732 - val_loss: 0.1061 - val_acc: 0.9672\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 14s 390us/sample - loss: 0.0756 - acc: 0.9783 - val_loss: 0.0980 - val_acc: 0.9732\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 15s 399us/sample - loss: 0.0637 - acc: 0.9822 - val_loss: 0.1038 - val_acc: 0.9710\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 14s 384us/sample - loss: 0.0555 - acc: 0.9848 - val_loss: 0.1025 - val_acc: 0.9732\n",
      "18333/18333 [==============================] - 4s 230us/sample - loss: 0.1258 - acc: 0.9680\n",
      "[CV] ..................................... n_neurons=98, total= 2.1min\n",
      "[CV] n_neurons=99 ....................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 22s 599us/sample - loss: 0.3215 - acc: 0.9079 - val_loss: 0.1781 - val_acc: 0.9476\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 15s 412us/sample - loss: 0.1607 - acc: 0.9516 - val_loss: 0.1534 - val_acc: 0.9546\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 15s 406us/sample - loss: 0.1185 - acc: 0.9648 - val_loss: 0.1170 - val_acc: 0.9670\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 15s 403us/sample - loss: 0.0931 - acc: 0.9722 - val_loss: 0.1117 - val_acc: 0.9678\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 15s 396us/sample - loss: 0.0765 - acc: 0.9784 - val_loss: 0.1177 - val_acc: 0.9670\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 14s 392us/sample - loss: 0.0648 - acc: 0.9813 - val_loss: 0.1020 - val_acc: 0.9722\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 14s 394us/sample - loss: 0.0559 - acc: 0.9844 - val_loss: 0.1070 - val_acc: 0.9710\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 14s 392us/sample - loss: 0.0477 - acc: 0.9860 - val_loss: 0.1084 - val_acc: 0.9710\n",
      "18334/18334 [==============================] - 4s 240us/sample - loss: 0.1286 - acc: 0.9667\n",
      "[CV] ..................................... n_neurons=99, total= 2.4min\n",
      "[CV] n_neurons=99 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 22s 612us/sample - loss: 0.3291 - acc: 0.9065 - val_loss: 0.1913 - val_acc: 0.9458\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 14s 395us/sample - loss: 0.1677 - acc: 0.9518 - val_loss: 0.1504 - val_acc: 0.9574\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 14s 393us/sample - loss: 0.1232 - acc: 0.9640 - val_loss: 0.1287 - val_acc: 0.9618\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 15s 402us/sample - loss: 0.0972 - acc: 0.9708 - val_loss: 0.1129 - val_acc: 0.9648\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 15s 397us/sample - loss: 0.0793 - acc: 0.9767 - val_loss: 0.1083 - val_acc: 0.9684\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 14s 393us/sample - loss: 0.0673 - acc: 0.9802 - val_loss: 0.1087 - val_acc: 0.9694\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 15s 398us/sample - loss: 0.0568 - acc: 0.9831 - val_loss: 0.1118 - val_acc: 0.9690\n",
      "18333/18333 [==============================] - 4s 245us/sample - loss: 0.1293 - acc: 0.9666\n",
      "[CV] ..................................... n_neurons=99, total= 2.1min\n",
      "[CV] n_neurons=99 ....................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 23s 617us/sample - loss: 0.3341 - acc: 0.9027 - val_loss: 0.1859 - val_acc: 0.9466\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 14s 395us/sample - loss: 0.1702 - acc: 0.9503 - val_loss: 0.1528 - val_acc: 0.9566\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 15s 404us/sample - loss: 0.1265 - acc: 0.9635 - val_loss: 0.1343 - val_acc: 0.9600\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 15s 405us/sample - loss: 0.1017 - acc: 0.9699 - val_loss: 0.1231 - val_acc: 0.9642\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 15s 401us/sample - loss: 0.0838 - acc: 0.9759 - val_loss: 0.1134 - val_acc: 0.9680\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 15s 399us/sample - loss: 0.0720 - acc: 0.9794 - val_loss: 0.1095 - val_acc: 0.9706\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 15s 398us/sample - loss: 0.0610 - acc: 0.9823 - val_loss: 0.1063 - val_acc: 0.9728\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 14s 395us/sample - loss: 0.0545 - acc: 0.9846 - val_loss: 0.1116 - val_acc: 0.9696\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 15s 397us/sample - loss: 0.0461 - acc: 0.9861 - val_loss: 0.1146 - val_acc: 0.9720\n",
      "18333/18333 [==============================] - 4s 236us/sample - loss: 0.1327 - acc: 0.9667\n",
      "[CV] ..................................... n_neurons=99, total= 2.6min\n",
      "[CV] n_neurons=100 ...................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 22s 608us/sample - loss: 0.3258 - acc: 0.9077 - val_loss: 0.1853 - val_acc: 0.9458\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 15s 396us/sample - loss: 0.1614 - acc: 0.9529 - val_loss: 0.1437 - val_acc: 0.9578\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 15s 396us/sample - loss: 0.1181 - acc: 0.9655 - val_loss: 0.1169 - val_acc: 0.9652\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 14s 392us/sample - loss: 0.0935 - acc: 0.9727 - val_loss: 0.1101 - val_acc: 0.9700\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 14s 394us/sample - loss: 0.0767 - acc: 0.9780 - val_loss: 0.1036 - val_acc: 0.9708\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 15s 398us/sample - loss: 0.0650 - acc: 0.9810 - val_loss: 0.1033 - val_acc: 0.9710\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 15s 399us/sample - loss: 0.0552 - acc: 0.9840 - val_loss: 0.1085 - val_acc: 0.9702\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 14s 394us/sample - loss: 0.0480 - acc: 0.9862 - val_loss: 0.1008 - val_acc: 0.9736\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 15s 397us/sample - loss: 0.0422 - acc: 0.9874 - val_loss: 0.1024 - val_acc: 0.9742\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 14s 391us/sample - loss: 0.0369 - acc: 0.9896 - val_loss: 0.1149 - val_acc: 0.9702\n",
      "18334/18334 [==============================] - 4s 240us/sample - loss: 0.1243 - acc: 0.9681\n",
      "[CV] .................................... n_neurons=100, total= 2.8min\n",
      "[CV] n_neurons=100 ...................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 22s 601us/sample - loss: 0.3247 - acc: 0.9084 - val_loss: 0.1909 - val_acc: 0.9434\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 15s 404us/sample - loss: 0.1604 - acc: 0.9538 - val_loss: 0.1370 - val_acc: 0.9628\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 16s 443us/sample - loss: 0.1185 - acc: 0.9650 - val_loss: 0.1157 - val_acc: 0.9660\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 15s 417us/sample - loss: 0.0944 - acc: 0.9722 - val_loss: 0.1170 - val_acc: 0.9654\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 15s 396us/sample - loss: 0.0780 - acc: 0.9777 - val_loss: 0.1117 - val_acc: 0.9696\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 15s 396us/sample - loss: 0.0672 - acc: 0.9806 - val_loss: 0.1090 - val_acc: 0.9686\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 16s 426us/sample - loss: 0.0567 - acc: 0.9835 - val_loss: 0.0962 - val_acc: 0.9708\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 15s 403us/sample - loss: 0.0493 - acc: 0.9851 - val_loss: 0.0984 - val_acc: 0.9726\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 14s 394us/sample - loss: 0.0425 - acc: 0.9876 - val_loss: 0.1042 - val_acc: 0.9718\n",
      "18333/18333 [==============================] - 4s 242us/sample - loss: 0.1228 - acc: 0.9700\n",
      "[CV] .................................... n_neurons=100, total= 2.7min\n",
      "[CV] n_neurons=100 ...................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 27s 737us/sample - loss: 0.3314 - acc: 0.9054 - val_loss: 0.1877 - val_acc: 0.9472\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 17s 474us/sample - loss: 0.1637 - acc: 0.9519 - val_loss: 0.1320 - val_acc: 0.9628\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 17s 474us/sample - loss: 0.1177 - acc: 0.9663 - val_loss: 0.1267 - val_acc: 0.9654\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 19s 522us/sample - loss: 0.0932 - acc: 0.9725 - val_loss: 0.1186 - val_acc: 0.9642\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 14s 383us/sample - loss: 0.0761 - acc: 0.9775 - val_loss: 0.0963 - val_acc: 0.9726\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 14s 387us/sample - loss: 0.0644 - acc: 0.9821 - val_loss: 0.0935 - val_acc: 0.9742\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 14s 389us/sample - loss: 0.0566 - acc: 0.9841 - val_loss: 0.1061 - val_acc: 0.9698\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 14s 381us/sample - loss: 0.0486 - acc: 0.9870 - val_loss: 0.0936 - val_acc: 0.9750\n",
      "18333/18333 [==============================] - 4s 217us/sample - loss: 0.1198 - acc: 0.9690\n",
      "[CV] .................................... n_neurons=100, total= 2.6min\n",
      "Train on 55000 samples, validate on 5000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed: 548.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 26s 481us/sample - loss: 0.2922 - acc: 0.9157 - val_loss: 0.1623 - val_acc: 0.9516\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 20s 358us/sample - loss: 0.1460 - acc: 0.9571 - val_loss: 0.1262 - val_acc: 0.9622\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 20s 358us/sample - loss: 0.1076 - acc: 0.9688 - val_loss: 0.1018 - val_acc: 0.9700\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 20s 361us/sample - loss: 0.0870 - acc: 0.9750 - val_loss: 0.0972 - val_acc: 0.9722\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 20s 358us/sample - loss: 0.0740 - acc: 0.9791 - val_loss: 0.0872 - val_acc: 0.9736\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 20s 361us/sample - loss: 0.0644 - acc: 0.9822 - val_loss: 0.0910 - val_acc: 0.9760\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 20s 361us/sample - loss: 0.0575 - acc: 0.9843 - val_loss: 0.0918 - val_acc: 0.9756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x147083fd0>,\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'n_neurons': range(1, 101)}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#grid_cv = GridSearchCV(estimator=keras_clf, param_grid=param_grid,cv=3,verbose = 2)\n",
    "#grid_cv.fit(train_images, train_labels, epochs=30,\n",
    "                  #validation_data=(val_images, val_labels),\n",
    "                  #callbacks=[keras.callbacks.EarlyStopping(patience=2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Number of Neurons that produced the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 94}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure of Model 3\n",
    "We will be using the best estimator as our third model. It's architecture is below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_model = grid_cv.best_estimator_.model\n",
    "#keras.utils.plot_model(best_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-7858b9dd0506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'summary' is not defined"
     ]
    }
   ],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(layers.Dense(94, activation='relu', input_shape=(28 * 28,)))\n",
    "model3.add(layers.Dense(10, activation='softmax'))\n",
    "keras.utils.plot_model(model3, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Compiling the model\n",
    "\n",
    "Initially, a network's nodes are assigned weights randomly. Once training data forward propogates through a network and outputs a prediction, the network calculates the error between the predicted value and the real value. Once this cost (or loss) has been calculated, the network uses gradient descent to modify the weights of the nodes to minimize the cost. This process, of adjusting weights iteratively in order to improve the models performance, is called backpropogation.\n",
    "\n",
    "Compiling the model involves specifying the method for back-propagation by choosing an optimizer and specifying the loss function. \n",
    "\n",
    "#### Loss function\n",
    "*sparse_categorical_crossentropy*\n",
    "The loss function is how the models performance to is to be evaluated. \n",
    "Our models use the Sparse Cross-entropy Loss function; this is the default loss function for multi-class classification problems. Cross-entropy scores summarize the average difference between the actual and predicted probability distributions for all classes in the problem. Sparse cross-entropy performs the same cross-entropy calculation of error, without requiring that the target variable be one hot encoded prior to training.\n",
    "\n",
    "#### Optimizer:\n",
    "*rmsprop*\n",
    "The optimizer is the algorithm used by the model to update its weights based on the data it sees and its loss function. \n",
    "Gradient descent is a way to minimize our loss function by updating the model weights in the opposite direction of the slope (gradient) of the loss function. Adagrad is an algorithm for gradient-based optimization that adapts the learning rate to the parameters, performing smaller updates for parameters associated with frequently occurring features, and larger updates for parameters associated with infrequent features. RMSprop is an extension of Adagrad that deals with its radically diminishing learning rates. Our models use the RMSprop Optimizer.\n",
    "\n",
    "#### Metric\n",
    "*accuracy*\n",
    "We also set the performance measure we want to capture when training deep learning models. We are interested in the accuracy of our models (the fraction of the images that were correctly classified). Metric values for the dataset are recorded at the end of each epoch on the training dataset. \n",
    "\n",
    "Our models are compiled so that our networks know to use the *rmsprop* optimizer to adjust weights in such a way that the loss *categorical_crossentropy* is minimized at each iteration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='rmsprop',\n",
    "#                 loss='categorical_crossentropy',\n",
    "                loss='sparse_categorical_crossentropy',              \n",
    "                metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.compile(optimizer='rmsprop',\n",
    "#                 loss='categorical_crossentropy',\n",
    "                loss='sparse_categorical_crossentropy',              \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model3.compile(optimizer='rmsprop',\n",
    "#                 loss='categorical_crossentropy',\n",
    "                loss='sparse_categorical_crossentropy',              \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the model\n",
    "\n",
    "The backpropogation process occurs over multiple iterations, each step slightly improving the model weights. There are two parameters that dictate this iterative learning process.\n",
    "\n",
    "1. The batch size: the number of samples (images) that will be propagated through the network. The higher the batch size, the more memory space you’ll need.\n",
    "2. The Epochs: the number of passes through the network, each pass using a [batch size] number of examples. One epoch means that each sample in the training dataset has had an opportunity to update the internal model parameters. \n",
    "\n",
    "The three models are fit to the input data (train_images) and output values (train_labels) and trained in batches of 12 over 30 epochs. Even though we used only 30 epochs each model took about 10 minutes to train. \n",
    "\n",
    "### Accuracy on Training and Valiation Data \n",
    "Two quantities are displayed during training: the *loss* of the network at each epoch, and the *accuracy* of the network at each epoch. This accuracy measure is evaluating the performance of the network on the same data it trained on- giving us an idea of how well we have modeled the dataset, but no idea of how well the algorithm might perform on new data. We only reach an accuracy of 0.3624 on our training set. This model is a very weak classifier.\n",
    "\n",
    "Our validation set lets us evaluate our classifier on new data. Sometimes there is a gap between training accuracy and validation accuracy with the model outperforming significantly on training data. This is evidence of \"overfitting\" and means that the model is biased by the data it was trained on. \n",
    "\n",
    "##### Model 1\n",
    "Model 1 only reaches an accuracy of 0.3624 on our training set. This model is a very weak classifier. There is no evidence that we have overfit the data, our model actually performed a little better on the new data attaining an accuracy of 0.3678."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 24s 442us/sample - loss: 1.9984 - acc: 0.2176 - val_loss: 1.8654 - val_acc: 0.2356\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 17s 302us/sample - loss: 1.8203 - acc: 0.2665 - val_loss: 1.7599 - val_acc: 0.2854\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 17s 301us/sample - loss: 1.7481 - acc: 0.2923 - val_loss: 1.7156 - val_acc: 0.2974\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 16s 294us/sample - loss: 1.7110 - acc: 0.2962 - val_loss: 1.6778 - val_acc: 0.2908\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 17s 304us/sample - loss: 1.6892 - acc: 0.3035 - val_loss: 1.6642 - val_acc: 0.2978\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 18s 330us/sample - loss: 1.6767 - acc: 0.3133 - val_loss: 1.6664 - val_acc: 0.3246\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 17s 310us/sample - loss: 1.6682 - acc: 0.3238 - val_loss: 1.6479 - val_acc: 0.3246\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 17s 311us/sample - loss: 1.6611 - acc: 0.3261 - val_loss: 1.6468 - val_acc: 0.3192\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 16s 294us/sample - loss: 1.6560 - acc: 0.3320 - val_loss: 1.6372 - val_acc: 0.3288\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 17s 302us/sample - loss: 1.6520 - acc: 0.3349 - val_loss: 1.6350 - val_acc: 0.3392\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 16s 288us/sample - loss: 1.6485 - acc: 0.3394 - val_loss: 1.6309 - val_acc: 0.3382\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 16s 282us/sample - loss: 1.6456 - acc: 0.3412 - val_loss: 1.6279 - val_acc: 0.3560\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 16s 290us/sample - loss: 1.6434 - acc: 0.3493 - val_loss: 1.6259 - val_acc: 0.3476\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 17s 300us/sample - loss: 1.6413 - acc: 0.3508 - val_loss: 1.6256 - val_acc: 0.3510\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 16s 298us/sample - loss: 1.6393 - acc: 0.3555 - val_loss: 1.6280 - val_acc: 0.3560\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 15s 275us/sample - loss: 1.6377 - acc: 0.3545 - val_loss: 1.6214 - val_acc: 0.3594\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 15s 282us/sample - loss: 1.6360 - acc: 0.3584 - val_loss: 1.6237 - val_acc: 0.3482\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 18s 324us/sample - loss: 1.6345 - acc: 0.3617 - val_loss: 1.6195 - val_acc: 0.3660\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 17s 311us/sample - loss: 1.6332 - acc: 0.3619 - val_loss: 1.6160 - val_acc: 0.3652\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 15s 280us/sample - loss: 1.6319 - acc: 0.3654 - val_loss: 1.6104 - val_acc: 0.3678\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 15s 278us/sample - loss: 1.6309 - acc: 0.3637 - val_loss: 1.6145 - val_acc: 0.3628\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 15s 277us/sample - loss: 1.6296 - acc: 0.3642 - val_loss: 1.6096 - val_acc: 0.3680\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 15s 282us/sample - loss: 1.6287 - acc: 0.3666 - val_loss: 1.6096 - val_acc: 0.3714\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 23s 415us/sample - loss: 1.6277 - acc: 0.3637 - val_loss: 1.6258 - val_acc: 0.3644\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 19s 348us/sample - loss: 1.6271 - acc: 0.3647 - val_loss: 1.6065 - val_acc: 0.3638\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 15s 281us/sample - loss: 1.6269 - acc: 0.3634 - val_loss: 1.6144 - val_acc: 0.3692\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 16s 283us/sample - loss: 1.6258 - acc: 0.3642 - val_loss: 1.6103 - val_acc: 0.3714\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 16s 285us/sample - loss: 1.6253 - acc: 0.3659 - val_loss: 1.6061 - val_acc: 0.3466\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 15s 278us/sample - loss: 1.6248 - acc: 0.3609 - val_loss: 1.6018 - val_acc: 0.3738\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 15s 279us/sample - loss: 1.6238 - acc: 0.3624 - val_loss: 1.6005 - val_acc: 0.3678\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, epochs=30,\n",
    "                    validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 2\n",
    "By adding one node to our neural network the accuracy on the training and validation dataset almost doubles to 0.6867 and 0.6840 respectively. Our classifier now guesses the correct more than half the time, while this isnt 'good', it's already a huge improvement over model 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 21s 416us/sample - loss: 0.9995 - acc: 0.6849 - val_loss: 0.9803 - val_acc: 0.6874\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 21s 412us/sample - loss: 0.9995 - acc: 0.6861 - val_loss: 0.9777 - val_acc: 0.6906\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 18s 366us/sample - loss: 0.9987 - acc: 0.6853 - val_loss: 0.9925 - val_acc: 0.6850\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 18s 369us/sample - loss: 0.9982 - acc: 0.6850 - val_loss: 0.9855 - val_acc: 0.6824\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.9975 - acc: 0.6850 - val_loss: 0.9849 - val_acc: 0.6844\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 17s 348us/sample - loss: 0.9977 - acc: 0.6847 - val_loss: 0.9877 - val_acc: 0.6850\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 31s 627us/sample - loss: 0.9966 - acc: 0.6863 - val_loss: 0.9944 - val_acc: 0.6782\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 18s 364us/sample - loss: 0.9965 - acc: 0.6855 - val_loss: 0.9874 - val_acc: 0.6864\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 16s 310us/sample - loss: 0.9965 - acc: 0.6865 - val_loss: 0.9879 - val_acc: 0.6856\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 15s 307us/sample - loss: 0.9962 - acc: 0.6863 - val_loss: 0.9843 - val_acc: 0.6898\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 16s 313us/sample - loss: 0.9961 - acc: 0.6854 - val_loss: 0.9857 - val_acc: 0.6876\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 16s 316us/sample - loss: 0.9960 - acc: 0.6862 - val_loss: 0.9904 - val_acc: 0.6840\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 20s 396us/sample - loss: 0.9962 - acc: 0.6877 - val_loss: 0.9879 - val_acc: 0.6860\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 25s 503us/sample - loss: 0.9960 - acc: 0.6865 - val_loss: 0.9854 - val_acc: 0.6898\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 15s 291us/sample - loss: 0.9954 - acc: 0.6872 - val_loss: 0.9904 - val_acc: 0.6846\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 15s 304us/sample - loss: 0.9965 - acc: 0.6867 - val_loss: 0.9951 - val_acc: 0.6832\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 15s 306us/sample - loss: 0.9950 - acc: 0.6858 - val_loss: 0.9911 - val_acc: 0.6816\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 15s 297us/sample - loss: 0.9948 - acc: 0.6858 - val_loss: 0.9890 - val_acc: 0.6912\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 21s 424us/sample - loss: 0.9948 - acc: 0.6873 - val_loss: 0.9879 - val_acc: 0.6886\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 16s 313us/sample - loss: 0.9948 - acc: 0.6859 - val_loss: 0.9899 - val_acc: 0.6854\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 15s 296us/sample - loss: 0.9950 - acc: 0.6866 - val_loss: 0.9983 - val_acc: 0.6796\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 14s 289us/sample - loss: 0.9954 - acc: 0.6869 - val_loss: 0.9903 - val_acc: 0.6838\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 14s 290us/sample - loss: 0.9951 - acc: 0.6856 - val_loss: 0.9876 - val_acc: 0.6836\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 14s 288us/sample - loss: 0.9951 - acc: 0.6870 - val_loss: 0.9899 - val_acc: 0.6860\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 16s 328us/sample - loss: 0.9943 - acc: 0.6858 - val_loss: 0.9918 - val_acc: 0.6830\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 19s 385us/sample - loss: 0.9942 - acc: 0.6861 - val_loss: 0.9904 - val_acc: 0.6846\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 16s 326us/sample - loss: 0.9939 - acc: 0.6862 - val_loss: 1.0120 - val_acc: 0.6712\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 17s 347us/sample - loss: 0.9942 - acc: 0.6878 - val_loss: 1.0052 - val_acc: 0.6754\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 17s 332us/sample - loss: 0.9945 - acc: 0.6864 - val_loss: 0.9944 - val_acc: 0.6802\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 16s 313us/sample - loss: 0.9945 - acc: 0.6867 - val_loss: 0.9928 - val_acc: 0.6840\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(train_images, train_labels, epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 3\n",
    "With 94 nodes we now have a good classifier. Our model has an accuracy of 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 34s 687us/sample - loss: 0.2849 - acc: 0.9187 - val_loss: 0.1839 - val_acc: 0.9482\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 24s 483us/sample - loss: 0.1390 - acc: 0.9591 - val_loss: 0.1542 - val_acc: 0.9562\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 24s 482us/sample - loss: 0.1028 - acc: 0.9699 - val_loss: 0.1238 - val_acc: 0.9640\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 24s 470us/sample - loss: 0.0843 - acc: 0.9745 - val_loss: 0.1083 - val_acc: 0.9702\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 24s 490us/sample - loss: 0.0722 - acc: 0.9791 - val_loss: 0.1246 - val_acc: 0.9698\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 25s 497us/sample - loss: 0.0612 - acc: 0.9824 - val_loss: 0.1188 - val_acc: 0.9698\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 24s 471us/sample - loss: 0.0538 - acc: 0.9849 - val_loss: 0.1213 - val_acc: 0.9704\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 25s 493us/sample - loss: 0.0488 - acc: 0.9864 - val_loss: 0.1341 - val_acc: 0.9682\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 25s 500us/sample - loss: 0.0437 - acc: 0.9877 - val_loss: 0.1205 - val_acc: 0.9720\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 25s 503us/sample - loss: 0.0394 - acc: 0.9890 - val_loss: 0.1258 - val_acc: 0.9712\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 25s 509us/sample - loss: 0.0354 - acc: 0.9902 - val_loss: 0.1185 - val_acc: 0.9734\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 20s 399us/sample - loss: 0.0314 - acc: 0.9916 - val_loss: 0.1303 - val_acc: 0.9728\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 23s 455us/sample - loss: 0.0286 - acc: 0.9925 - val_loss: 0.1309 - val_acc: 0.9732\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 25s 494us/sample - loss: 0.0254 - acc: 0.9931 - val_loss: 0.1271 - val_acc: 0.9736\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 26s 521us/sample - loss: 0.0236 - acc: 0.9939 - val_loss: 0.1365 - val_acc: 0.9724\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 26s 522us/sample - loss: 0.0219 - acc: 0.9944 - val_loss: 0.1502 - val_acc: 0.9730\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 24s 489us/sample - loss: 0.0197 - acc: 0.9952 - val_loss: 0.1550 - val_acc: 0.9726\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 26s 513us/sample - loss: 0.0176 - acc: 0.9955 - val_loss: 0.1518 - val_acc: 0.9722\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 24s 470us/sample - loss: 0.0155 - acc: 0.9958 - val_loss: 0.1658 - val_acc: 0.9710\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 22s 449us/sample - loss: 0.0144 - acc: 0.9963 - val_loss: 0.1619 - val_acc: 0.9708\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 22s 436us/sample - loss: 0.0132 - acc: 0.9967 - val_loss: 0.1631 - val_acc: 0.9732\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 22s 435us/sample - loss: 0.0113 - acc: 0.9969 - val_loss: 0.1525 - val_acc: 0.9750\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 23s 461us/sample - loss: 0.0110 - acc: 0.9972 - val_loss: 0.1761 - val_acc: 0.9734\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 22s 445us/sample - loss: 0.0097 - acc: 0.9978 - val_loss: 0.1654 - val_acc: 0.9740\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 23s 464us/sample - loss: 0.0090 - acc: 0.9977 - val_loss: 0.1730 - val_acc: 0.9736\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 24s 471us/sample - loss: 0.0082 - acc: 0.9979 - val_loss: 0.1856 - val_acc: 0.9714\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 24s 477us/sample - loss: 0.0074 - acc: 0.9985 - val_loss: 0.1905 - val_acc: 0.9724\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 23s 465us/sample - loss: 0.0067 - acc: 0.9983 - val_loss: 0.1908 - val_acc: 0.9722\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 22s 447us/sample - loss: 0.0068 - acc: 0.9982 - val_loss: 0.1868 - val_acc: 0.9722\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 22s 434us/sample - loss: 0.0062 - acc: 0.9986 - val_loss: 0.1926 - val_acc: 0.9728\n"
     ]
    }
   ],
   "source": [
    "model3.compile(optimizer='rmsprop',\n",
    "#                 loss='categorical_crossentropy',\n",
    "                loss='sparse_categorical_crossentropy',              \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history3 = model3.fit(train_images, train_labels, epochs=30,\n",
    "                    validation_data=(val_images, val_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and Loss Plots\n",
    "Accuracy and Loss can be plotted against epochs to give us an idea of how our model improved over time. Our learning curve plot will help to diagnose whether the model has over learned, under learned, or is suitably fit to the training dataset. \n",
    "\n",
    "Training loss should decrease with every epoch as the training accuracy increases with every epoch. That's what you would expect when running gradient descent optimization -- the cost junction the model is trying to minimize should get lower with every iteration. \n",
    "A good fit is identified by a training and validation loss that decreases to a point of stability with a minimal gap between the two final loss values.\n",
    "\n",
    "Though it doesnt seem to be true of our models, the loss of the model will almost always be lower on the training dataset than the validation dataset. We should expect some gap between the train and validation loss learning curves. \n",
    "\n",
    "A plot of learning curves shows a good fit if:\n",
    "\n",
    "* The plot of training loss decreases to a point of stability.\n",
    "* The plot of validation loss decreases to a point of stability and has a small gap with the training loss.\n",
    "* Continued training of a good fit will likely lead to an overfit.\n",
    "\n",
    "All of our model plots, below demonstrate a case of a good fit.\n",
    "\n",
    "\n",
    "\n",
    "#### Model 1 Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "# val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict2 = history2.history\n",
    "history_dict2.keys()\n",
    "\n",
    "acc = history2.history['acc']\n",
    "val_acc = history2.history['val_acc']\n",
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict2['acc']\n",
    "# val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict3 = history3.history\n",
    "history_dict3.keys()\n",
    "\n",
    "acc = history3.history['acc']\n",
    "val_acc = history3.history['val_acc']\n",
    "loss = history3.history['loss']\n",
    "val_loss = history3.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict3['acc']\n",
    "# val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "### Accuracy \n",
    "The goal of a classifier is to generalize well enough to perform well on unseen data. The primary measure of performance of our models is it's accuracy score on the test sets. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 316us/sample - loss: 1.6241 - acc: 0.3670\n",
      "10000/10000 [==============================] - 2s 236us/sample - loss: 1.0058 - acc: 0.6876\n",
      "10000/10000 [==============================] - 3s 258us/sample - loss: 0.1476 - acc: 0.9763\n",
      "Model 1 Performance on Test Set. accuracy: 0.367000013589859, loss: 1.6240671186447144\n",
      "Model 2 Performance on Test Set. accuracy:  0.6876000165939331, loss: 1.005797060775757\n",
      "Model 3 Performance on Test Set. accuracy:  0.9763000011444092, loss: 0.1476366243132363\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "test_loss2, test_acc2 = model2.evaluate(test_images, test_labels)\n",
    "test_loss3, test_acc3 = model3.evaluate(test_images, test_labels)\n",
    "print(f'Model 1 Performance on Test Set. accuracy: {test_acc}, loss: {test_loss}') \n",
    "print(f'Model 2 Performance on Test Set. accuracy:  {test_acc2}, loss: {test_loss2}') \n",
    "print(f'Model 3 Performance on Test Set. accuracy:  {test_acc3}, loss: {test_loss3}') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "We can gain more insights into our models by looking at the classes that were correctly classified vs misclassified. This information is presented with a confusion matrix. The numbers on the diagonal axis represent the number of correctly classified points, the rest are the misclassified ones. \n",
    "The confusion matrix lets us quickly zero in on:\n",
    "* Which classes are most accurately predicted\n",
    "* Which classes are least accurately predicted\n",
    "* Which misclassifications are most common\n",
    "\n",
    "\n",
    "\n",
    "#### Model 1 Confusion Matrix\n",
    "\n",
    "The confusion matrix does not look good. The model failed to correctly predict 5 and 2 even one time. The model also confused a lot of the numbers: 1&6, 3&7, 7&5.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1631af7f0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Get the predicted classes:\n",
    "pred_classes = model.predict_classes(train_images)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mx = confusion_matrix(train_labels,pred_classes)\n",
    "conf_mx\n",
    "\n",
    "\n",
    "\n",
    "sns.heatmap(conf_mx, annot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 Confusion Matrix \n",
    "Our model is looking better, the diagonal of the matrix is lit up so most of the classifications were done correctly. There are still a few patches of difficulty, the model is confusing 5&8 and 2&3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x164695588>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pred_classes2 = model2.predict_classes(train_images)\n",
    "\n",
    "\n",
    "conf_mx = confusion_matrix(train_labels,pred_classes2)\n",
    "conf_mx\n",
    "\n",
    "sns.heatmap(conf_mx, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 Confusion Matrix \n",
    "Model 3 has a perfect confusion matrix. There are almost no incorrect classifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f9e6d240>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_classes3 = model3.predict_classes(train_images)\n",
    "conf_mx = confusion_matrix(train_labels,pred_classes3)\n",
    "conf_mx\n",
    "\n",
    "sns.heatmap(conf_mx, annot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection on the Node Experiment\n",
    "Dealing with the MNIST data is computationally taxing. The grid search to find the optimal number nodes between 0-101 for one hidden layer took 12 hours. With only 30 epochs our models took an average of 10 minutes to train. The model could have been further optimized had we been able to expore the paramaters of the model and the learning further. That being said, our final \"best\" model performed really well. We did not need more than one hidden layer to achieve near perfect performance.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Looking Inside our Networks\n",
    "We are interested in understanding how our models learned from the training data and what the inner layers of these artificial neural networks look like. The weights of our networks nodes can help us understand what patterns were extracted from the data. \n",
    "\n",
    "\n",
    "### Model 1\n",
    "For all the images in the training dataset we group the activation values by class and visualize them using a boxplot. We expect the overlap between the range of values in the \"boxes\" to be minimal. For the most part the box plots are well contained and seperated though notably there is a lot of overlap between 2,3,5&7 and 8&9. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'dense_2/Relu:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dense_3/Softmax:0' shape=(?, 10) dtype=float32>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "\n",
    "# Extracts the outputs of the 2 layers:\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "\n",
    "# Creates a model that will return these outputs, given the model input:\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "print(f\"There are {len(layer_outputs)} layers\")\n",
    "layer_outputs # description of the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the output of the hidden node for each of the 55000 training images\n",
    "activations = activation_model.predict(train_images)\n",
    "hidden_layer_activation = activations[0]\n",
    "hidden_layer_activation.shape   #  hidden node has one activation value per training imagev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum activation value of the hidden node is 12.021673202514648\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"The maximum activation value of the hidden node is {hidden_layer_activation.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output node has shape (55000, 10)\n",
      "The output for the first image are [0.0043 0.0003 0.1898 0.0959 0.0796 0.1054 0.0092 0.1305 0.1913 0.1937]\n",
      "The sum of the probabilities is (approximately) 0.9999999403953552\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Some stats about the output layer as an aside...\n",
    "np.set_printoptions(suppress = True)  # display probabilities as decimals and NOT in scientific notation\n",
    "ouput_layer_activation = activations[1]\n",
    "print(f\"The output node has shape {ouput_layer_activation.shape}\")\n",
    "print(f\"The output for the first image are {ouput_layer_activation[0].round(4)}\")\n",
    "print(f\"The sum of the probabilities is (approximately) {ouput_layer_activation[0].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_value</th>\n",
       "      <th>pred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.426599</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.480914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.944174</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.152061</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   act_value  pred_class\n",
       "0   2.426599           7\n",
       "1   4.480914           3\n",
       "2   1.944174           9\n",
       "3   1.152061           6\n",
       "4  -0.000000           1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxplot_df = pd.DataFrame({'act_value':hidden_layer_activation.reshape(55000),\n",
    "                           'pred_class':pred_classes})\n",
    "boxplot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x1008 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To see how closely the hidden nodes activation values correlate with the class predictions\n",
    "# Note that there were no 5s detected and that there were outliers for the activation values for the 6s\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "bplot = sns.boxplot(y='act_value', x='pred_class', \n",
    "                 data=boxplot_df, \n",
    "                 width=0.5,\n",
    "                 palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6385\n",
       "0    5975\n",
       "6    5947\n",
       "3    5685\n",
       "4    5640\n",
       "8    5465\n",
       "2    5238\n",
       "9    5041\n",
       "7    4859\n",
       "5    4765\n",
       "Name: pred_class, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxplot_df['pred_class'].value_counts() # Another way to verify what the boxplot is telling us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Model  2:\n",
    "For the images in the training dataset we group the 60,000 activation values by class and visualize them using a scatterplot. We expect the overlap between the range of values in the color coded splatters to be minimal. \n",
    "As expected, each class is very pretty contained and seperated from the others. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'dense_4/Relu:0' shape=(?, 2) dtype=float32>,\n",
       " <tf.Tensor 'dense_5/Softmax:0' shape=(?, 10) dtype=float32>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracts the outputs of the 2 layers:\n",
    "layer_outputs = [layer.output for layer in model2.layers]\n",
    "\n",
    "# Creates a model that will return these outputs, given the model input:\n",
    "activation_model = models.Model(inputs=model2.input, outputs=layer_outputs)\n",
    "\n",
    "print(f\"There are {len(layer_outputs)} layers\")\n",
    "layer_outputs # description of the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum activation value of the first hidden node is 39.74103927612305\n",
      "The maximum activation value of the second hidden node is 35.768863677978516\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get the output of the hidden node for each of the 55000 training images\n",
    "activations = activation_model.predict(train_images)\n",
    "hidden_layer_activation = activations[0]\n",
    "hidden_layer_activation.shape   #  2 hidden node each has one activation value per training image\n",
    "\n",
    "\n",
    "hidden_node1_activation = hidden_layer_activation[:,0] # get activation values of the first hidden node\n",
    "hidden_node2_activation = hidden_layer_activation[:,1] # get activation values of the second hidden node\n",
    "\n",
    "print(f\"The maximum activation value of the first hidden node is {hidden_node1_activation.max()}\")\n",
    "print(f\"The maximum activation value of the second hidden node is {hidden_node2_activation.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output node has shape (55000, 10)\n",
      "The output for the first image are [0.     0.     0.0001 0.0897 0.     0.     0.     0.9066 0.0001 0.0035]\n",
      "The sum of the probabilities is (approximately) 1.0000001192092896\n"
     ]
    }
   ],
   "source": [
    "# Some stats about the output layer as an aside...\n",
    "np.set_printoptions(suppress = True)  # display probabilities as decimals and NOT in scientific notation\n",
    "ouput_layer_activation = activations[1]\n",
    "print(f\"The output node has shape {ouput_layer_activation.shape}\")\n",
    "print(f\"The output for the first image are {ouput_layer_activation[0].round(4)}\")\n",
    "print(f\"The sum of the probabilities is (approximately) {ouput_layer_activation[0].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the scatterplots\n",
    "We combine the activation values of the two hidden nodes together with the corresponding predicted classes into a DataFrame. We use both matplotlib and seaborn to create boxplots from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_value_h1</th>\n",
       "      <th>act_value_h2</th>\n",
       "      <th>pred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.047396</td>\n",
       "      <td>13.143168</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.285686</td>\n",
       "      <td>5.716402</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.620725</td>\n",
       "      <td>4.593265</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.989653</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>5.125006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   act_value_h1  act_value_h2  pred_class\n",
       "0     16.047396     13.143168           7\n",
       "1     11.285686      5.716402           3\n",
       "2      1.620725      4.593265           9\n",
       "3      1.989653     -0.000000           6\n",
       "4     -0.000000      5.125006           1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatterPlot_df =  pd.DataFrame({'act_value_h1':hidden_node1_activation,\n",
    "                                'act_value_h2':hidden_node2_activation,\n",
    "                                'pred_class':pred_classes})\n",
    "scatterPlot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x1008 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groups = scatterPlot_df.groupby('pred_class')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "for name, group in groups:\n",
    "    ax.plot(group.act_value_h1, group.act_value_h2, marker='o', linestyle='', ms=12, label=name)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#https://github.com/djp840/MSDS_458_Public/blob/master/MSDS458_Assignment_01/MSDS458_Assignment_01_Experiment2_20200324.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Models on Compressed Data\n",
    " We discovered that the models train very slowly and we were limited in the paramters we could search because of the computational time any search took. This is because the MNIST database of handwritten digits is a high dimensional dataset with 784 dimensions, a training set of 60,000 examples, and a test set of 10,000 examples. This makes it a good candidate for dimensionality reduction. \n",
    "\n",
    "###  Data Compression through PCA \n",
    "A common way of speeding up a machine learning algorithm is by reducing input dimension using Principal Component Analysis (PCA). Before builing our fourth model we use PCA decomposition to reduce the number of dimensions of our training set. We limit our data's dimension to the principal components containing 95% of the variance (information) in the training images. Our best model from experiment three will be trained on the new lower dimensional data and its performance compared against the performance on the full dataset. \n",
    "\n",
    "#### Data Preparation\n",
    "PCA is effected by scale so StandardScaler is used on the training data standardize the dataset’s features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "scaler.fit(train_images)\n",
    "# Apply transform to both the training set and the test set.\n",
    "train_img = scaler.transform(train_images)\n",
    "test_img = scaler.transform(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compressing the training data \n",
    "We instruct the PCA model to choose principal components such that 95% of the variance in our training set is retained. By setting n_components=0.95 we get the 238 principal components that contain 95% of the variance (information) in the training images. We transform the training and test images to reduce its dimensionality from 784 to 238. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum number of dimensions while retaining 95% of variance: 328\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(.95)\n",
    "#Fit PCA on training set. Note: you are fitting PCA on the training set only.\n",
    "pca.fit(train_img)\n",
    "\n",
    "print(f\"The minimum number of dimensions while retaining 95% of variance: {pca.n_components_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (50000,328) (784,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-f09a488ebb12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Apply the mapping (transform) to both the training set and the test set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of PCA reduced training dataset: {train_img.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mX_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (50000,328) (784,) "
     ]
    }
   ],
   "source": [
    "#Apply the mapping (transform) to both the training set and the test set.\n",
    "train_img = pca.transform(train_img)\n",
    "test_img = pca.transform(test_img)\n",
    "\n",
    "print(f\"Shape of PCA reduced training dataset: {train_img.shape}\")\n",
    "print(f\"Shape of PCA reduced test dataset: {test_img.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fit\n",
    "The best performing model from our previous experiments is fit to our pca reduced training dataset. We update the models architecture to set the input size of our model to 328 nodes reflecting the size of the input data it will receivie. \n",
    "Model 4's architecture is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = models.Sequential()\n",
    "model4.add(layers.Dense(94, activation='relu', input_shape=(328,)))\n",
    "model4.add(layers.Dense(10, activation='softmax'))  \n",
    "\n",
    "model4.compile(optimizer='rmsprop',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "keras.utils.plot_model(model4, show_shapes=True) # plot a graph of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Model Performance\n",
    "Reducing the dimensions from 784 to 328 had no negative impact on the performance of our 'best' model. In fact the performance improved. We expected that by fitting our model to a lower dimensional input data we would see a more effecient training process. This was not our experience, the compressed dataset took just as long to train and our full dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 22s 433us/sample - loss: 0.3494 - acc: 0.9079\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 19s 378us/sample - loss: 0.1458 - acc: 0.9607\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 20s 406us/sample - loss: 0.0953 - acc: 0.9739\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.0687 - acc: 0.9813\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 19s 389us/sample - loss: 0.0499 - acc: 0.9857\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 21s 420us/sample - loss: 0.0386 - acc: 0.9894\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 21s 426us/sample - loss: 0.0298 - acc: 0.9924\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 19s 387us/sample - loss: 0.0228 - acc: 0.9938\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 18s 351us/sample - loss: 0.0191 - acc: 0.9954\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 19s 370us/sample - loss: 0.0150 - acc: 0.9964\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 22s 443us/sample - loss: 0.0115 - acc: 0.9972\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 21s 411us/sample - loss: 0.0100 - acc: 0.9977\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 20s 403us/sample - loss: 0.0092 - acc: 0.9981\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 20s 391us/sample - loss: 0.0064 - acc: 0.9986\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 19s 378us/sample - loss: 0.0057 - acc: 0.9988\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 19s 386us/sample - loss: 0.0048 - acc: 0.9990\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 20s 400us/sample - loss: 0.0029 - acc: 0.9994\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 20s 402us/sample - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 21s 411us/sample - loss: 0.0033 - acc: 0.9994\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 21s 411us/sample - loss: 0.0028 - acc: 0.9995\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 21s 426us/sample - loss: 0.0029 - acc: 0.9995\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 20s 393us/sample - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 20s 396us/sample - loss: 0.0022 - acc: 0.9996\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 21s 420us/sample - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 21s 420us/sample - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 18s 362us/sample - loss: 4.7583e-04 - acc: 0.9999\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 18s 362us/sample - loss: 9.2076e-04 - acc: 0.9999\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 18s 355us/sample - loss: 0.0013 - acc: 0.9998\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 19s 374us/sample - loss: 6.5322e-04 - acc: 0.9998\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 19s 384us/sample - loss: 0.0032 - acc: 0.9998\n"
     ]
    }
   ],
   "source": [
    "history = model4.fit(train_img, train_labels, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'historypca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-2aa7e6db87ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist_dictpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistorypca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhist_dictpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'test acc: {test_acc}, test loss: {test_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'historypca' is not defined"
     ]
    }
   ],
   "source": [
    "hist_dictpca = historypca.history\n",
    "hist_dictpca.keys()\n",
    "\n",
    "test_loss, test_acc = model4.evaluate(test_img, test_labels)\n",
    "print(f'test acc: {test_acc}, test loss: {test_loss}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Feature Selection with Random Forests  \n",
    "An alternative approach to dimensionality reduction is to use random forests to find the most informative subset of features. Random forests are large sets of very shallow trees, with each tree being trained on a small fraction of the total number of attributes. If an attribute is often selected as best split, it is most likely an informative feature to retain. A random forest tells us ‒ relative to the other attributes ‒ which are the most predictive attributes.\n",
    "\n",
    "\n",
    "In EXPERIMENT 5 we use a Random Forest classifier to find the relative importance of the 784 features (pixels) of the 784 dimension images in our training set. We select the 70 most important features (pixels) and train our best network on these features. \n",
    "\n",
    "#### Reducing dimensionality of the data with Random Forests.\n",
    "We create a Random Forrest Classifier with the default 100 trees and use it to find the relative importance of the features in our training set. We get the indices of these top 70 features and compress our training, validation and test images so that they are using just those pixels. The heatmap below shows that the random forest will be in effect trimming the border of the images as all the important information is concentrated in the center. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rnd_clf.fit(train_images,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://github.com/ageron/handson-ml2/blob/master/07_ensemble_learning_and_random_forests.ipynb\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.hot,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plot_digit(rnd_clf.feature_importances_)\n",
    "\n",
    "cbar = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(), rnd_clf.feature_importances_.max()])\n",
    "cbar.ax.set_yticklabels(['Not important', 'Very important'])\n",
    "\n",
    "# plt.savefig(\"mnist_feature_importance_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/6910641/how-do-i-get-indices-of-n-maximum-values-in-a-numpy-array\n",
    "n = 70\n",
    "imp_arr = rnd_clf.feature_importances_\n",
    "idx = (-imp_arr).argsort()[:n]          # get the indices of the 70 \"most important\" features/pixels\n",
    "#len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 70), (5000, 784), (10000, 70))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_sm = train_images[:,idx]\n",
    "val_images_sm = val_images[:,idx]\n",
    "test_images_sm = test_images[:,idx]\n",
    "train_images_sm.shape, val_images.shape, test_images_sm.shape # the reduced images have dimension 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing the 70 pixels¶\n",
    "We convert the array of indexes to ordered pairs and plot them on the second training image. The red circles on the image below are the feature we are training our neural network on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert an index n, 0<= n < 784\n",
    "def pair(n,size):\n",
    "    x = n//size \n",
    "    y = n%size\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x165e3eb38>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[1].reshape(28,28),cmap='binary')\n",
    "x, y = np.array([pair(k,28) for k in idx]).T\n",
    "plt.scatter(x,y,color='red',s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building, training and testing model 5\n",
    "We modify our best model to take in input with dimension (70,) and fit this new model to the training dataset made up of the 70 features we extracted using random forests. Even though our model is training on our smallest dataset yet, training was no faster than with the full dataset. The performance of the this newest model is surprisingly good given the dimensions were reduced 90% there was a small dip in performance but only by a couple percent.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 26s 512us/sample - loss: 0.6053 - acc: 0.8221 - val_loss: 0.4408 - val_acc: 0.8714\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 18s 370us/sample - loss: 0.4059 - acc: 0.8770 - val_loss: 0.3633 - val_acc: 0.8948\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 20s 392us/sample - loss: 0.3391 - acc: 0.8969 - val_loss: 0.3180 - val_acc: 0.9094\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 19s 375us/sample - loss: 0.2977 - acc: 0.9102 - val_loss: 0.3044 - val_acc: 0.9098\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 16s 321us/sample - loss: 0.2698 - acc: 0.9193 - val_loss: 0.2710 - val_acc: 0.9204\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 17s 347us/sample - loss: 0.2497 - acc: 0.9242 - val_loss: 0.2653 - val_acc: 0.9190\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 17s 336us/sample - loss: 0.2353 - acc: 0.9285 - val_loss: 0.2472 - val_acc: 0.9290\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 16s 327us/sample - loss: 0.2231 - acc: 0.9323 - val_loss: 0.2513 - val_acc: 0.9252\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 18s 367us/sample - loss: 0.2144 - acc: 0.9351 - val_loss: 0.2343 - val_acc: 0.9326\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.2073 - acc: 0.9377 - val_loss: 0.2374 - val_acc: 0.9330\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 18s 355us/sample - loss: 0.2003 - acc: 0.9398 - val_loss: 0.2378 - val_acc: 0.9338\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 18s 369us/sample - loss: 0.1951 - acc: 0.9407 - val_loss: 0.2297 - val_acc: 0.9322\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 18s 367us/sample - loss: 0.1895 - acc: 0.9433 - val_loss: 0.2347 - val_acc: 0.9322\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 18s 354us/sample - loss: 0.1862 - acc: 0.9444 - val_loss: 0.2262 - val_acc: 0.9338\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 18s 360us/sample - loss: 0.1823 - acc: 0.9451 - val_loss: 0.2252 - val_acc: 0.9350\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 18s 353us/sample - loss: 0.1787 - acc: 0.9470 - val_loss: 0.2337 - val_acc: 0.9334\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 17s 337us/sample - loss: 0.1765 - acc: 0.9471 - val_loss: 0.2269 - val_acc: 0.9346\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 18s 368us/sample - loss: 0.1728 - acc: 0.9490 - val_loss: 0.2277 - val_acc: 0.9370\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 18s 351us/sample - loss: 0.1710 - acc: 0.9492 - val_loss: 0.2326 - val_acc: 0.9330\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 17s 336us/sample - loss: 0.1680 - acc: 0.9500 - val_loss: 0.2265 - val_acc: 0.9360\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 18s 350us/sample - loss: 0.1661 - acc: 0.9511 - val_loss: 0.2319 - val_acc: 0.9328\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 18s 364us/sample - loss: 0.1643 - acc: 0.9507 - val_loss: 0.2366 - val_acc: 0.9310\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 17s 339us/sample - loss: 0.1618 - acc: 0.9519 - val_loss: 0.2273 - val_acc: 0.9338\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 25s 500us/sample - loss: 0.1610 - acc: 0.9520 - val_loss: 0.2312 - val_acc: 0.9350\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 21s 415us/sample - loss: 0.1589 - acc: 0.9528 - val_loss: 0.2367 - val_acc: 0.9324\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 18s 353us/sample - loss: 0.1569 - acc: 0.9530 - val_loss: 0.2383 - val_acc: 0.9326\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 21s 424us/sample - loss: 0.1559 - acc: 0.9540 - val_loss: 0.2375 - val_acc: 0.9320\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 21s 427us/sample - loss: 0.1540 - acc: 0.9540 - val_loss: 0.2324 - val_acc: 0.9374\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1538 - acc: 0.9550 - val_loss: 0.2398 - val_acc: 0.9314\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 20s 404us/sample - loss: 0.1528 - acc: 0.9551 - val_loss: 0.2325 - val_acc: 0.9320\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model5 = models.Sequential()\n",
    "model5.add(layers.Dense(94, activation='relu', input_shape=(70,)))\n",
    "model5.add(layers.Dense(10, activation='softmax'))  \n",
    "\n",
    "# For use with non-categorical labels\n",
    "model5.compile(optimizer='rmsprop',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "history = model5.fit(train_images_sm, train_labels, epochs=30,\n",
    "                    validation_data=(val_images_sm, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy on training set: 0.9551, model accuracy on validation set: 0.932,\n",
      "model loss on training set: 0.1528, model loss on validation set: 0.2325\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hist_dict = history.history\n",
    "hist_dict.keys()\n",
    "\n",
    "print(f'''model accuracy on training set: {hist_dict['acc'][-1]:.4}, model accuracy on validation set: {hist_dict['val_acc'][-1]:.4},\n",
    "model loss on training set: {hist_dict['loss'][-1]:.4}, model loss on validation set: {hist_dict['val_loss'][-1]:.4}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 291us/sample - loss: 0.2231 - acc: 0.9388\n",
      "model accuracy on test set: 0.9387999773025513, model loss on test set: 0.22308162953183056\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model5.evaluate(test_images_sm, test_labels)\n",
    "print(f'model accuracy on test set: {test_acc}, model loss on test set: {test_loss}')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection on Dimensionality Reduction \n",
    "Even though we fit our model to a dataset that was reduced by 90% of its original size, training time did not improve at all from model 3 to model 4. It could be that computational speed was affected by record size rather than dimension size. It was also surprising that performance was not affected at all by using a fraction of the image's pixels to train, it was interesting to see how those pixels translated to actual area on the image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
